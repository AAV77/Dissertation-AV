d.Chainalysis <- read.xlsx(path)
replacement2020 <- 143 # choose what goes to among lowest fo
d.Chainalysis <- d.Chainalysis %>%
select(-Country) %>%
rename(Country = Country.Code) %>%
mutate(X2020 = if_else(as.character(X2020) == "Among lowest",
as.character(replacement2020),
as.character(X2020))) %>%
mutate(X2020 = as.numeric(X2020))
impute_row_mean <- function(df) {
numeric_cols <- sapply(df, is.numeric)
total_imputes <- 0
possible_imputes <- sum(is.na(df[ , numeric_cols]))
for (i in 1:nrow(df)) {
row <- df[i, ]
numeric_row <- row[ , numeric_cols]
na_cols <- names(numeric_row)[is.na(numeric_row)]
if (length(na_cols) > 0 && !all(is.na(numeric_row))) {
row_mean <- mean(unlist(numeric_row), na.rm = TRUE)
df[i, na_cols] <- row_mean
cat("Imputed", length(na_cols), "missing value(s) for Country:", row$Country,
"| Columns:", paste(na_cols, collapse = ", "), "\n")
total_imputes <- total_imputes + length(na_cols)
}
}
total_possible <- nrow(df) * sum(numeric_cols)
cat("Total missing values imputed:", total_imputes, "\n")
cat("Total possible imputes (if all numeric values were missing):", total_possible, "\n")
return(df)
}
d.Chainalysis <- impute_row_mean(d.Chainalysis)
d_Chainalysis_long <- d.Chainalysis %>%
pivot_longer(
cols = starts_with("X"),         # All year columns like X2020, X2021,
names_to = "Year",               # New column name for years
names_prefix = "X",              # Remove the 'X' prefix
values_to = "Chainalysis_Adoption" # New column for the actual values
)
v.sanity_country_codes <- unique(d.Chainalysis$Country)
#Currency Stability
path <- "Data/d.Inflation/API_FP.CPI.TOTL.ZG_DS2_en_csv_v2_3401965.csv"
d.Inflation_s <- read.csv(path, header = T, skip = 4)
# Cleaning Data d.Inflation
d.Inflation_s <- d.Inflation_s %>%
filter(Country.Code %in% v.sanity_country_codes) %>%
select(Country.Code, X2019:X2023)
# Rename first column to "Country"
colnames(d.Inflation_s)[1] <- "Country"
# Remove 'X' prefix from year columns
colnames(d.Inflation_s) <- gsub("^X", "", colnames(d.Inflation_s))
#Investment
path <- "Data/d.Savings/API_NY.GDS.TOTL.ZS_DS2_en_csv_v2_1988.csv"
d.GDS_s <- read.csv(path, header = T, skip = 4)
# Cleaning Data d.GDS
d.GDS_s <- d.GDS_s %>%
filter(Country.Code %in% v.sanity_country_codes) %>%
select(Country.Code, X2019:X2023)  # Removed Indicator.Code
# Rename first column to "Country"
colnames(d.GDS_s)[1] <- "Country"
# Remove 'X' prefix from year columns
colnames(d.GDS_s) <- gsub("^X", "", colnames(d.GDS_s))
# Wealth
path <- "Data/d.GDP/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_3401556.csv"
d.GDP_s <- read.csv(path, header = T, skip = 4)
# Cleaning Data d.GDP
d.GDP_s <- d.GDP_s %>%
filter(Country.Code %in% v.sanity_country_codes) %>%
select(Country.Code, X2019:X2023)  # Removed Indicator.Code
# Rename first column to "Country"
colnames(d.GDP_s)[1] <- "Country"
# Remove 'X' prefix from year columns
colnames(d.GDP_s) <- gsub("^X", "", colnames(d.GDP_s))
#Remittances
path <- "Data/d.RemittancesGDP/API_BX.TRF.PWKR.DT.GD.ZS_DS2_en_csv_v2_3426.csv"
d.RR_s <- read.csv(path, header = T, skip = 4)
# Cleaning Data d.RR
d.RR_s <- d.RR_s %>%
filter(Country.Code %in% v.sanity_country_codes) %>%
select(Country.Code, X2019:X2023)  # Removed Indicator.Code
# Rename first column to "Country"
colnames(d.RR_s)[1] <- "Country"
# Remove 'X' prefix from year columns
colnames(d.RR_s) <- gsub("^X", "", colnames(d.RR_s))
devtools::install_github("vdeminstitute/vdemdata")
library(vdemdata)
d.Corruption_s <- vdem[, c("country_name", "year", "v2x_corr")] # relevant variables
d.Corruption_s <- d.Corruption_s %>%
filter(year %in% c(2019: 2024)) # relevant years
d.Corruption_s$Country <- countrycode(d.Corruption_s$country_name, "country.name", "iso3c")
d.Corruption_s <- d.Corruption_s %>%
filter(!is.na(Country)) %>%
select(-country_name) %>%
rename(
Corruption = v2x_corr,
Year = year
) %>%
select(Country, Year, Corruption) %>%
filter(Country %in% v.sanity_country_codes)
d.Corruption_s <- d.Corruption_s %>%
pivot_wider(names_from = Year, values_from = Corruption) %>%
select(-'2024')
path <- "Data/d.CC/IMF (2024).xlsx"
d.CC_s <- read.xlsx(path)
colnames(d.CC_s)[(ncol(d.CC_s)-4):ncol(d.CC_s)] <- c("A", "B", "C", "D", "E")
# Compute Index dynamically based on available (non-NA) values
d.CC_s$IndexCC <- rowSums(d.CC_s[, c("A", "B", "C", "D", "E")] == d.CC_s[11,4], na.rm = TRUE) /
rowSums(!is.na(d.CC_s[, c("A", "B", "C", "D", "E")]), na.rm = TRUE)
d.CC_s$IndexCC[is.nan(d.CC_s$IndexCC)] <- NA # #converting 0 data point to NA
d.CC_s$Country <- countrycode(d.CC_s$Country, "country.name", "iso3c")
d.CC_s <- na.omit(d.CC_s, cols = "Country")
# Above Warnings Countries are not found in the Adoption set, can be safely removed
d.CC_s <- d.CC_s %>% select(Country, Year, IndexCC) # rearrannging and removing rows
d.CC_s <- d.CC_s %>%
pivot_wider(names_from = Year, values_from = IndexCC) %>%  # make wide format
mutate(`2023` = NA) %>%
filter(Country %in% v.sanity_country_codes)
# Working with External Debt (% of GDP) ->
# Source: https://www.focus-economics.com/economic-indicator/external-debt/
path <- "Data/d.External_Debt_GDP/d.External_Debt_GDP_s.xlsx"
# Loading Raw Data
d.ED_s <- read.xlsx(path)
# Adding World Bank Codes
d.ED_s$Country <- countrycode(d.ED_s$Country, "country.name", "iso3c")
# warning about unconnected code can be safely ignored since the dataset d.Adoption does not contain the two unmatched countries (Ivory Coast, Kosovo) anyways.
#for some reason, column 2,3 did not save as numeric
d.ED_s$'2019' <- as.numeric(d.ED_s$'2019')
d.ED_s$'2020' <- as.numeric(d.ED_s$'2020')
NGA_GDS <- c("2019" = 19.83, "2020" = 27.38, "2021" = 32.73, "2022" = NA, "2023" = NA)#, "2024" = NA)
NGA_row <- which(d.GDS_s$Country == "NGA")
d.GDS_s[NGA_row, 2:ncol(d.GDS_s)] <- NGA_GDS  # Assuming the first column is "Country"
Arg_Inf <- c("2019" = 53.55, "2020" = 42.02, "2021" = 48.41,
"2022" = 72.43, "2023" = 133.49)#, "2024" = NA)
arg_row <- which(d.Inflation_s$Country == "ARG")
d.Inflation_s[arg_row, 2:ncol(d.Inflation_s)] <- Arg_Inf  # Assuming the first column is "Country"
new_countries_External_Debt <- tibble(
Country = c("BEL", "CAN", "FRA", "IRL", "ESP"),
`2019` = c(257.579, 134.234, 235.061, 742.138, 169.725),
`2020` = c(268.416, 149.077, 265.191, 702.699, 200.181),
`2021` = c(260.193, 143.214, 258.592, 677.751, 193.562),
`2022` = c(237.91, 134.904, 244.258, 577.158, 172.805),
`2023` = c(237.68, 143.661, 245.047, 563.897, 165.481)#,
#  #`2024` = c(NA, NA, NA, NA, NA)
)
# Add only missing countries
existing_countries <- d.ED_s$Country
missing_countries <- new_countries_External_Debt %>% filter(!Country %in% existing_countries)
# Append missing countries to d.GDS
d.ED_s <- bind_rows(d.ED_s, missing_countries)
v.Chainalysis_country <- d.Chainalysis$Country
# Inflation (1)
d.Inflation_s_162 <- tibble(Country = v.Chainalysis_country) %>%
left_join(d.Inflation_s, by = "Country")
# Investment (2)
d.GDS_s_162 <- tibble(Country = v.Chainalysis_country) %>%
left_join(d.GDS_s, by = "Country")
# Wealth (3)
d.GDP_s_162 <- tibble(Country = v.Chainalysis_country) %>%
left_join(d.GDP_s, by = "Country")
#Corruption (4)
d.Corruption_s_162 <- tibble(Country = v.Chainalysis_country) %>%
left_join(d.Corruption_s, by = "Country")
#Remittances (5)
d.RR_s_162 <- tibble(Country = v.Chainalysis_country) %>%
left_join(d.RR_s, by = "Country")
#Capital Controls (6)
d.CC_s_162 <- tibble(Country = v.Chainalysis_country) %>%
left_join(d.CC_s, by = "Country")
# External Deficit (7)
d.ED_s_162<- tibble(Country = v.Chainalysis_country) %>%
left_join(d.ED_s, by = "Country")
dfs <- list(
d.Inflation_s_162 = d.Inflation_s_162,
d.GDS_s_162 = d.GDS_s_162,
d.GDP_s_162 = d.GDP_s_162,
d.Corruption_s_162 = d.Corruption_s_162,
d.RR_s_162 = d.RR_s_162,
d.CC_s_162 = d.CC_s_162,
d.ED_s_162= d.ED_s_162
)
# Function to get countries fully missing in a dataset
get_fully_missing_countries <- function(df, dataset_name) {
df %>%
filter(if_all(2:6, is.na)) %>%
pull(Country)
}
# Get a named list of missing countries from each dataset
missing_lists <- Map(get_fully_missing_countries, dfs, names(dfs))
# Combine into one vector
all_missing <- unlist(missing_lists)
# Count how many times each country is missing fully
country_missing_counts <- as.data.frame(table(all_missing))
colnames(country_missing_counts) <- c("Country", "Missing_Count")
# Show the result sorted by count
country_missing_counts <- country_missing_counts %>%
arrange(desc(Missing_Count))
#print(country_missing_counts)
v.unique_missing_countries162 <- unique(all_missing)
print(v.unique_missing_countries162)
v.imputable_c <- setdiff(v.Chainalysis_country, v.unique_missing_countries162)
d.Inflation_s_128  <- d.Inflation_s_162  %>% filter(Country %in% v.imputable_c)
d.GDS_s_128        <- d.GDS_s_162        %>% filter(Country %in% v.imputable_c)
d.GDP_s_128        <- d.GDP_s_162        %>% filter(Country %in% v.imputable_c)
d.Corruption_s_128 <- d.Corruption_s_162 %>% filter(Country %in% v.imputable_c)
d.RR_s_128         <- d.RR_s_162         %>% filter(Country %in% v.imputable_c)
d.CC_s_128         <- d.CC_s_162         %>% filter(Country %in% v.imputable_c)
d.ED_s_128         <- d.ED_s_162         %>% filter(Country %in% v.imputable_c)
d.Chainalysis      <- d.Chainalysis       %>% filter(Country %in% v.imputable_c)
#change all NA coltype
d.CC_s_128$"2023" <- d.CC_s_128$`2022Â `
print("Inflation")
d.Inflation_s_128  <- impute_row_mean(d.Inflation_s_128)
print("GDS")
d.GDS_s_128        <- impute_row_mean(d.GDS_s_128)
print("GDP")
d.GDP_s_128        <- impute_row_mean(d.GDP_s_128)
print("Corrupption")
d.Corruption_s_128 <- impute_row_mean(d.Corruption_s_128)
print("RR")
d.RR_s_128         <- impute_row_mean(d.RR_s_128)
print("CC")
d.CC_s_128         <- impute_row_mean(d.CC_s_128)
print("ED")
d.ED_s_128         <- impute_row_mean(d.ED_s_128)
# List your datasets (adjust names if needed)
datasets <- list(
d.Inflation_s_128,
d.GDS_s_128,
d.GDP_s_128,
d.Corruption_s_128,
d.RR_s_128,
d.CC_s_128,
d.ED_s_128
)
names(datasets) <- c("Inflation", "GDS", "GDP", "Corruption", "RR", "CC", "ED")
# 1. Check for NAs in each dataset
na_check <- sapply(datasets, function(df) any(is.na(df)))
print("Datasets containing NAs:")
print(na_check)
# 2. Check that Country columns are identical across all datasets
# Use the first dataset as the reference
ref_countries <- d.Chainalysis$Country
country_check <- sapply(datasets, function(df) identical(df$Country, ref_countries))
print("Country columns identical to reference:")
print(country_check)
colnames(d.Chainalysis) <- c("Country","2020","2021","2022","2023","2024")
colnames(d.CC_s_128) <- c("Country","2019","2020","2021","2022","2023")
#as.numeric(d.CC$'2023')
# List of indicator datasets (excluding Chainalysis)
datasets <- list(
Chainalysis = d.Chainalysis,
Inflation  = d.Inflation_s_128,
GDS        = d.GDS_s_128,
GDP        = d.GDP_s_128,
Corruption = d.Corruption_s_128,
RR         = d.RR_s_128,
CC         = d.CC_s_128,
ED         = d.ED_s_128
)
# Pivot each dataset to long format: Country, Year, Indicator_Value
long_indicators <- lapply(names(datasets), function(name) {
datasets[[name]] %>%
pivot_longer(-Country, names_to = "Year", values_to = name)
})
# Join them all together on Country and Year
df_long <- reduce(long_indicators, full_join, by = c("Country", "Year"))
# Make sure Year is numeric
d.panel_sanity <- df_long %>% mutate(Year = as.numeric(Year))
#Removing Year 2024, no Data for any DV, and 2019, no Data for IV
d.panel_sanity <- d.panel_sanity %>%
filter(Year != 2024) %>%
filter(Year != 2019)
# View result
head(d.panel_sanity)
# here could flip the scale if so inclined
#m.4<- lm(Chainalysis ~as.factor(Year)+Inflation+GDS+Corruption+RR+CC+ED, data = d.panel_sanity)
m.4 <- plm(
Chainalysis ~ Inflation + GDS + Corruption + RR + CC + ED,
data = d.panel_sanity,
index = c("Country", "Year"),
model = "within"
)
# deliberatley take out GDP as this is already controlled for in the adoption data
# Format the model summary
s.4 <- tidy(m.4) %>%
mutate(
term = gsub("_", "\\\\_", term),  # Escape underscores for LaTeX
estimate = sprintf("%.4f", estimate),  # 2 decimal places
std.error = sprintf("%.4f", std.error),  # 2 decimal places
statistic = sprintf("%.4f", statistic),  # 2 decimal places
p.value = sprintf("%.4f", p.value),  # 4 decimal places
signif = case_when(  # Significance stars
as.numeric(p.value) < 0.001 ~ "***",
as.numeric(p.value) < 0.01 ~ "**",
as.numeric(p.value) < 0.05 ~ "*",
as.numeric(p.value) < 0.1 ~ ".",
TRUE ~ ""
)
) %>%
rename(coefficient = term) %>%
rename(t.statistic = statistic)
#Clean Factor Term
s.4 <- clean_factor_terms_in_table(s.4)
colnames(s.4) <- c("Term","Coefficient Estimate","Standard-Error","T-Statistic","P-Value","Significance")
# Create LaTeX table
kable(s.4,
caption = "Model 4 (Robustness Check) Coefficients",
format = "latex",
booktabs = TRUE,
escape = FALSE) %>%
kable_styling(latex_options = c("hold_position", "booktabs")) %>%
column_spec(2, width = "3cm")  # Adjust column width if needed
summary_stats <- summary(m.4)
#helloback
# Extract residuals
residuals_summary <- summary(m.4$residuals)
# Create a dataframe for model fit statistics
model_summary <- data.frame(
Metric = c(#"Residual Standard Error",
"Multiple R-squared",
"Adjusted R-squared",
"F-statistic",
"Degrees of Freedom (Model)",
"Degrees of Freedom (Residuals)",
"P-Value",
"Residual Min",
"Residual Q1",
"Residual Median",
"Residual Q3",
"Residual Max"),
Value = c(#sprintf("%.2f", summary_stats$sigma), #1
sprintf("%.4f", summary_stats$r.squared[1]), #2
sprintf("%.4f", summary_stats$r.squared[2]), #3
sprintf("%.2f", summary_stats$fstatistic$statistic), #4
summary_stats$df[1], #5
summary_stats$df[2], #6
sprintf("%.4f", summary_stats$fstatistic$p.value), #7
sprintf("%.4f", -90.4145),
sprintf("%.4f",-8.098),
sprintf("%.4f",0.3052),
sprintf("%.4f",9.2541 ),
sprintf("%.4f",71.8774 )
))  # Sum of Sq #8
# Create a formatted LaTeX table using kable
kable(model_summary, caption = "Model 4 (Robustness Check) Fit Summary", format = "latex", booktabs = TRUE, escape = FALSE) %>%
kable_styling(latex_options = c("hold_position", "booktabs"))
# Create a data frame with predictions and residuals
df <- data.frame(
Predicted = predict(m.4),
Residuals = residuals(m.4)
)
# Generate the ggplot
ggplot(df, aes(x = Predicted, y = Residuals)) +
geom_point(color = "grey30", size = 0.5) +  # Scatter plot
geom_hline(yintercept = 0, linetype = "dashed", color = "#4A9FD8", size = 0.5) +  # Horizontal line at 0
ylim(-95,95)+
labs(x = "Predicted Values", y = "Residuals")# +
#theme_minimal()
m.4_residuals <- data.frame(residuals = m.4$residuals)
ggplot(m.4_residuals, aes(x = residuals)) +
geom_histogram(bins = 50, fill = "#4A9FD8", alpha = 0.6) +
labs(x = "Residuals", y = "Count") +
#theme_minimal() +
theme(
strip.text = element_text(size = 12, face = "bold"),
plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
)
significance_legend <- data.frame(
Symbol = c("***", "**", "*", ".", " "),
`P-value Threshold` = c(
"$\\mathrm{p} < 0.001$",
"$0.001 \\leq \\mathrm{p} < 0.01$",
"$0.01 \\leq \\mathrm{p} < 0.05$",
"$0.05 \\leq \\mathrm{p} < 0.1$",
"$\\mathrm{p} \\geq 0.1$"
)
,
Interpretation = c(
"Very strong evidence against $H_0$",
"Strong evidence against $H_0$",
"Moderate evidence against $H_0$",
"Weak evidence against $H_0$",
"Not statistically significant"
)
)
# Generate table for PDF output
kable(significance_legend, booktabs = TRUE, escape = FALSE, align = "l", format = "latex",
col.names = c("Symbol", "P-value Threshold", "Interpretation"),
caption = "Significance Legend for Model Coefficients Tables") %>%
kable_styling(latex_options = c( "hold_position", "scale_down"))
library(broom)
library(dplyr)
library(tidyr)
library(purrr)
# List of models
models <- list(LinReg = m.1, LinRegYJ = m.2, FixedEffect = m3.fixed, SanityCheck = m.4)
# Tidy and tag model summaries
model_summaries <- imap_dfr(models, ~ tidy(.x) %>%
mutate(model = .y), .id = "id")
# Create summary: coefficient (3 sig digits) + significance stars
model_summaries <- model_summaries %>%
mutate(
significance = case_when(
p.value < 0.001 ~ "***",
p.value < 0.01  ~ "**",
p.value < 0.05  ~ "*",
p.value < 0.1   ~ ".",
TRUE            ~ ""
),
summary = case_when(
p.value < 0.1 ~ paste0(signif(estimate, 3), significance),
TRUE          ~ ""
)
) %>%
select(term, model, summary)
# Get full set of all terms and all models
all_terms <- unique(model_summaries$term)
all_models <- names(models)
full_grid <- expand.grid(term = all_terms, model = all_models, stringsAsFactors = FALSE)
# Merge and fill missing/empty values with "NA"
summary_table <- full_grid %>%
left_join(model_summaries, by = c("term", "model")) %>%
mutate(summary = ifelse(summary == "" | is.na(summary), "-", summary)) %>%
pivot_wider(names_from = model, values_from = summary) %>%
arrange(term)
# Clean column names for LaTeX (escape underscores)
colnames(summary_table) <- gsub("_", "\\\\_", colnames(summary_table))
summary_table[5,5]<-"variable not included" # GDP was not included as a predictor variable in the Robustness Check
summary_table[1,4] <- "intercept dropped" # no intercept in FE model
summary_table[1,5] <- "intercept dropped"
summary_table[9,4] <- "not in data"
summary_table[10,4] <- "not estimated"
summary_table[11,4] <- "not estimated"
summary_table[12,4] <- "not estimated"
summary_table[9,5] <- "not in data"
summary_table[10,5] <- "not estimated"
summary_table[11,5] <- "not estimated"
summary_table[12,5] <- "not estimated"
colnames(summary_table) <- c(
"Term",
"\\makecell{Model 1:\\\\Linear Regression}",
"\\makecell{Model 2:\\\\Linear Regression\\\\Yeo-Johnson}",
"\\makecell{Model 3:\\\\Fixed Effects}",
"\\makecell{Model 4:\\\\Robustness Check\\\\(Fixed\\\\Effects)}"
)
#Clean Factor Term
summary_table <- clean_factor_terms_in_table(summary_table,"Term")
# LaTeX table with styling
kable(summary_table,
caption = "Model Comparison: Significant Coefficients",
format = "latex",
booktabs = TRUE,
escape = FALSE,
align = "lllll") %>%
kable_styling(latex_options = c("hold_position", "booktabs")) %>%
column_spec(1, bold = FALSE, width = "2cm")# %>%
#row_spec(0, bold = TRUE)
cat("
\\begin{table}[ht]
\\centering
\\caption{Visual Summary Currency Substitution Literature}
\\includegraphics[width=0.86\\linewidth]{Knit_Files/review_CS.png}
\\label{tab:litreviewCS}
\\end{table}
")
cat("
\\begin{table}[ht]
\\centering
\\caption{Visual Summary Cryptocurrency Adoption Literature}
\\includegraphics[width=0.83\\linewidth]{Knit_Files/review_Adoption.png}
\\label{tab:litreviewCA}
\\end{table}
")
md.pattern(d.Adoption_UNimp[,-1])
md.pattern(d.GDS_UNimp[,-1])
md.pattern(d.GDP_UNimp[,-1])
md.pattern(d.Corruption_UNimp[,-1])
md.pattern(d.RR_UNimp[,-1])
md.pattern(d.ED_UNimp[,-1])
# Summary statistics excluding 'Year' and 'Country'
summary_stats <- d.panel %>%
select(-Year, -Country) %>%
summarise(across(where(is.numeric), list(
Mean = mean,
Median = median,
SD = sd,
Min = min,
Max = max
), na.rm = TRUE)) %>%
pivot_longer(cols = everything(),
names_to = c("Variable", "Statistic"),
names_sep = "_") %>%
pivot_wider(names_from = Statistic, values_from = value)
# Display summary in a nice table
kable(summary_stats, caption = "Summary Statistics for Data Used With Statista Set", booktabs = TRUE)%>%
kable_styling(latex_options = "HOLD_position")
# Summary statistics excluding 'Year' and 'Country'
summary_stats <- d.panel_sanity %>%
select(-Year, -Country) %>%
summarise(across(where(is.numeric), list(
Mean = mean,
Median = median,
SD = sd,
Min = min,
Max = max
), na.rm = TRUE)) %>%
pivot_longer(cols = everything(),
names_to = c("Variable", "Statistic"),
names_sep = "_") %>%
pivot_wider(names_from = Statistic, values_from = value)
# Display summary in a nice table
kable(summary_stats, caption = "Summary Statistics for Data Used With Chainalysis Set", booktabs = TRUE)%>%
kable_styling(latex_options = "HOLD_position")
