---
output:
  bookdown::pdf_document2:
    toc: no
    toc_depth: 2 
    number_sections: yes
  pdf_document:
    toc: yes
    toc_depth: 2
    number_sections: yes
  bookdown::html_document2:
    toc: yes
    toc_depth: 2
  '': default
header-includes:
  - \input{Knit_Files/preamble.tex}
  - \newcommand{\smallskipline}{\\[0.01em]}
  - \usepackage{ragged2e}
bibliography: Knit_Files/references.bib
csl: Knit_Files/apa.csl
link-citations: yes
nocite: |
  @worldbank2024_GDP, @worldbank2024, @worldbank2024_Inflation, @worldbank2024_RemittReceived, @focuseconomics2024, @imf2024, @statistaCryptoMarketCap, @statista2025, @worldbank2025
cache: yes
---

```{=tex}
\pagenumbering{gobble} % Completely disable numbering on title page
\thispagestyle{empty} % Ensure first page has no header/footer
\centering
\LARGE
```
\vspace{4cm}

\LARGE \textbf{Opting Out: Cryptocurrency Under Consideration of Currency Substitution}

\Large

Degree Dissertation

\Large

Alec Vayloyan

\includegraphics[width=4.5in]{Knit_Files/cover.png} \Large

Degree Dissertation submitted as part of the requirements for the MSc in Applied Information and Data Science at the School of Business, Lucerne University of Applied Sciences and Arts

Spring Semester 2025 \vspace{3.5cm}

```{=tex}
\begin{flushleft}

\includegraphics[width=2.5in]{Knit_Files/hslu_logo.png}

\end{flushleft}
\pagenumbering{roman}
\pagestyle{roman}
\newpage
\thispagestyle{empty} % Ensure first page has no header/footer
```
\vspace{4cm}

\LARGE \textbf{Opting Out: Cryptocurrency Under Consideration of Currency Substitution}

\Large

Degree Dissertation \vspace{1cm}

```{=tex}
\begin{flushleft}

\Large

\textbf{Author:} Alec Vayloyan, MSc Student Applied Information and Data Science \smallskipline E-mail: vayloyanalec49@gmail.com
\smallskipline Matriculation Number: 23-576-119 

\Large

\textbf{Supervisor:} Dr. Denis Bieri \smallskipline Location: Room 6.03, Suurstoffi 1, 6343 Rotkreuz \smallskipline E-mail: denis.bieri@hslu.ch

\textbf{Co-Supervisor:} Prof. Dr. Thomas Ankenbrand \smallskipline Location: Room 6.01, Suurstoffi 1, 6343 Rotkreuz \smallskipline E-mail: thomas.ankenbrand@hslu.ch

\end{flushleft}
\vspace{1cm}
```
Degree Dissertation submitted as part of the requirements for the MSc in Applied Information and Data Science at the School of Business, Lucerne University of Applied Sciences and Arts

Spring Semester 2025 \vspace{1.6cm}

```{=tex}
\begin{flushleft}

\includegraphics[width=2.5in]{Knit_Files/hslu_logo.png}

\end{flushleft}
```
\newpage

\LARGE

\justifying

```{=tex}
\begin{center}

\Large

\textbf{Abstract}

\end{center}
```
\normalsize

This study investigates the drivers of cryptocurrency adoption using the framework of currency substitution theory, motivated by the theoretical overlap in use cases between foreign fiat currencies and cryptocurrency. Drawing on panel data for cryptocurrency adoption from both Statista (2019--2023) and Chainalysis (robustness check, 2020-2023), the analysis evaluates the influence of currency stability, investment, wealth, illicit activities ("sins"), remittances, capital controls and sovereign default risk on cryptocurrency adoption across countries. The inclusion of sovereign default risk is a novel approach in the literature on cryptocurrency adoption. Four econometric models - including both untransformed and transformed linear regressions, as well as fixed effects - are applied. While no predictor exhibited consistent statistical significance, sovereign default risk exhibits the strongest evidence for an underlying relationship, being the only predictor statistically significant with the same direction of effect across two models using different measures of cryptocurrency adoption. Remittances, investment and sins show a consistent direction of effect statistically significant in two models, both using the same measure of cryptocurrency adoption. The findings for these predictors align with the literature, except for remittances, which exhibit a negative relationship with adoption.Â  The proxies for currency stability yielded inconclusive results, while capital controls were statistically insignificant in all models. The findings suggest that cryptocurrency adoption is influenced by additional factors not included in this paper but do encourage further research in cryptocurrencies use as currency substitution. The study contributes both to the cryptocurrency and currency substitution literature by integrating currency substitution theory into the analysis of cryptocurrency adoption.

\vspace{8cm}

\raggedright

\textit{Keywords:} Cryptocurrency, Currency Substitution, Dollarization 2.0, Remittances

\newpage

\setcounter{tocdepth}{2}

\tableofcontents

\newpage

\listoffigures

\clearpage

\listoftables

\newpage

```{=tex}
\section*{List of Abbreviations}
\vspace{1em}
```
The following abbreviations were used to enable easier reading:

**AI**: Artificial Intelligence

**CC**: Capital Controls

**CHF:** Swiss Franc

**ED**: External Debt

**GDS**: Gross Domestic Savings

**GDP**: Gross Domestic Product

**K:** thousand

**KYC:** Know Your Customer

**M:** million

**MCAR:** Missing Completely at Random

**NAI**: Nearest Average Imputation

**RR**: Remittances Received

**USD:** United States Dollar

\newpage

```{=tex}
\section*{Preface}
\vspace{1em}
```
\justifying

I would like to express my sincerest gratitude to Dr. Denis Bieri and Prof. Dr. Thomas Ankenbrand for allowing me to write this project under their guidance and for the opportunity to benefit from their vast knowledge and experience in the field of (decentralized) finance.

Secondly, I would like to thank Dr. Kristin Makszin for initially suggesting the currency substitution mechanism and encouraging me to further pursue the idea in a research design course over five years ago. She is remembered fondly by students - even years after graduation - for the time and effort she was willing to put into students and their projects.

Finally, I would not be here without the love and support of my parents, Carmen and Arthur, as well as my *Omi*, Luise. I am truly privileged to have such an amazing family.

A reflection on the use of Artificial Intelligence (AI) is included at the end of this paper. It also provides credit for the cover image used (see Appendix 5).

\newpage

```{=tex}
\pagenumbering{arabic}
\pagestyle{arabic}
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r getting libraries, include = F, warning = F}
library(dplyr)
library(rvest)
library(xml2)
library(httr)     # OpenAI Access
library(jsonlite) # OpenAI Access
library(mice)     # Evaluating Missings
library(tidyr)
library(tibble)
library(openxlsx)
library(kableExtra)
library(knitr)
library(bookdown)
library(openxlsx)
library(ggplot2)
library(lubridate)
library(countrycode)
library(tidyverse)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggridges)
library(reshape2)
library(gt)
library(broom)
library(caret) #YJ Transformation
```

```{r setting working directory, include = F,}
setwd("C:/Users/vaylo/OneDrive/Desktop/Masters Thesis/Working Directory/Data")
```

```{r, include=F}
library(showtext)

font_add(family = "times", regular = "/usr/share/fonts/truetype/msttcorefonts/times.ttf")  # adjust path as needed
showtext_auto()

theme_set(theme_minimal(base_family = "times"))  
```

```{r d.Country_Codes, include = F, eval = F }
# Loading World Bank country codes from a website
url <- "https://irows.ucr.edu/research/tsmstudy/wbcountrycodes.htm" 
html_content <- read_html(url)

d.Country_Codes <- html_content %>%
  html_node("table") %>%  
  html_table()

#Cleaning Up
d.Country_Codes <- d.Country_Codes %>% 
  rename(Country.Name = X1, Country.Code = X2) %>% 
  slice(-(1:2)) %>% 
  filter(!row_number() %in% c(4, 9, 21, 62, 66, 72, 74, 76, 77, 79, 118,     131, 132))


v.Country_Codes <- d.Country_Codes$Country.Code
remove(url,html_content)

# New country codes to add - some were missing
new_country_codes <- c("SRB", "ROU", "SGP", "ARE")  # Add as many as needed

# Append new codes to the existing vector
v.Country_Codes <- unique(c(v.Country_Codes, new_country_codes))  # Ensure uniqueness
```

```{r d.Country_Codes_new, include = F}
# Had to use an excel sheet since the HTTP stopped working 14.05.2025
library(readxl)
path <- "Data/d.Country_Code/d.Country_Codes.xlsx"
d.Country_Codes <- read_excel(path)
v.Country_Codes <- d.Country_Codes$Code
new_country_codes <- c("SRB", "ROU", "SGP", "ARE")  # Add as many as needed
v.Country_Codes <- unique(c(v.Country_Codes, new_country_codes))  # Ensure uniqueness
# source URL: "https://irows.ucr.edu/research/tsmstudy/wbcountrycodes.htm" 

```

```{r indicator list, include = F}
d.Indicators <- data.frame(
  Indicator = character(),
  Indicator_Code = character()
)

unique_combinations <- function(df, col1_name, col2_name) {
  # Get the unique values of both specified columns
  col1_values <- unique(df[[col1_name]])
  col2_values <- unique(df[[col2_name]])
  
  # Create a data frame with all unique combinations of the two columns
  combinations_df <- expand.grid(Col1 = col1_values, Col2 = col2_values)
  
  return(combinations_df)
}
```

```{r d.Inflation, include = F}
# Working with Inflation -> 
# Source: https://data.worldbank.org/indicator/FP.CPI.TOTL.ZG

path <- "Data/d.Inflation/API_FP.CPI.TOTL.ZG_DS2_en_csv_v2_3401965.csv"
d.Inflation <- read.csv(path, header = T, skip = 4) 

# Extracting indicators and putting them in a separate running tally 
indicators <- unique_combinations(d.Inflation, "Indicator.Name", "Indicator.Code")
colnames(indicators) <- colnames(d.Indicators)
d.Indicators <- rbind(d.Indicators, indicators)
remove(indicators)

# Cleaning Data d.Inflation
d.Inflation <- d.Inflation %>%
  filter(Country.Code %in% v.Country_Codes) %>%
  select(Country.Code, X2019:X2023)  # Removed Indicator.Code

# Rename first column to "Country"
colnames(d.Inflation)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.Inflation) <- gsub("^X", "", colnames(d.Inflation))

d.Inflation <- d.Inflation # %>%
  #mutate(`2024` = NA)
```

```{r, d.GDP, include = F}
# Working with GDP per Capita -> 
# Source: https://data.worldbank.org/indicator/NY.GDP.PCAP.CD

path <- "Data/d.GDP/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_3401556.csv"
d.GDP <- read.csv(path, header = T, skip = 4) 

# Extracting indicators and putting them in a separate running tally 
indicators <- unique_combinations(d.GDP, "Indicator.Name", "Indicator.Code")
colnames(indicators) <- colnames(d.Indicators)
d.Indicators <- rbind(d.Indicators, indicators)
remove(indicators)

# Cleaning Data d.GDP
d.GDP <- d.GDP %>%
  filter(Country.Code %in% v.Country_Codes) %>%
  select(Country.Code, X2019:X2023)  # Removed Indicator.Code

# Rename first column to "Country"
colnames(d.GDP)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.GDP) <- gsub("^X", "", colnames(d.GDP))

d.GDP <- d.GDP #%>%
  #mutate(`2024` = NA)
```

```{r d.GDS, include = F}
# Working with Gross Domestic Savings (% of GDP) -> 
# Source: https://data.worldbank.org/indicator/NY.GDS.TOTL.ZS

path <- "Data/d.Savings/API_NY.GDS.TOTL.ZS_DS2_en_csv_v2_1988.csv"
d.GDS <- read.csv(path, header = T, skip = 4) 

# Extracting indicators and putting them in a separate running tally 
indicators <- unique_combinations(d.GDS, "Indicator.Name", "Indicator.Code")
colnames(indicators) <- colnames(d.Indicators)
d.Indicators <- rbind(d.Indicators, indicators)
remove(indicators)

# Cleaning Data d.GDS
d.GDS <- d.GDS %>%
  filter(Country.Code %in% v.Country_Codes) %>%
  select(Country.Code, X2019:X2023)  # Removed Indicator.Code

# Rename first column to "Country"
colnames(d.GDS)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.GDS) <- gsub("^X", "", colnames(d.GDS))

#d.GDS <- d.GDS #%>%
  #mutate(`2024` = NA)
```

```{r d.RR, include = F}
# Working with Personal Remittances Received (% of GDP) -> 
# Source: https://data.worldbank.org/indicator/BX.TRF.PWKR.DT.GD.ZS

path <- "Data/d.RemittancesGDP/API_BX.TRF.PWKR.DT.GD.ZS_DS2_en_csv_v2_3426.csv"
d.RR <- read.csv(path, header = T, skip = 4) 

# Extracting indicators and putting them in a separate running tally 
indicators <- unique_combinations(d.RR, "Indicator.Name", "Indicator.Code")
colnames(indicators) <- colnames(d.Indicators)
d.Indicators <- rbind(d.Indicators, indicators)
remove(indicators)

# Cleaning Data d.RR
d.RR <- d.RR %>%
  filter(Country.Code %in% v.Country_Codes) %>%
  select(Country.Code, X2019:X2023)  # Removed Indicator.Code

# Rename first column to "Country"
colnames(d.RR)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.RR) <- gsub("^X", "", colnames(d.RR))

d.RR <- d.RR #%>%
  #mutate(`2024` = NA)
```

```{r, d.External_Debt, include = F, warning = F}
# Working with External Debt (% of GDP) -> 
# Source: https://www.focus-economics.com/economic-indicator/external-debt/ 

path <- "Data/d.External_Debt_GDP/d.External_Debt_GDP.xlsx"

# Loading Raw Data
d.ED <- read.xlsx(path)

# Adding World Bank Codes

d.ED$Country <- countrycode(d.ED$Country, "country.name", "iso3c")
# warning about unconnected code can be safely ignored since the dataset d.Adoption does not contain the two unmatched countries (Ivory Coast, Kosovo) anyways.

#for some reason, column 2,3 did not save as numeric
d.ED$'2019' <- as.numeric(d.ED$'2019')
d.ED$'2020' <- as.numeric(d.ED$'2020')

d.ED <- d.ED #%>%
  #mutate(`2024` = NA)
```

```{r AdoptionLoad, echo = F}
path <- "Data/d.Adoption/Statista2024.xlsx"
d.Adoption <- read.xlsx(path, sheet = "Data")

# Convert country names to ISO3 codes
d.Adoption$Country <- countrycode(d.Adoption$Country, "country.name", "iso3c")
```

# Introduction and Topic Definition

The development of cryptocurrencies, spawned alongside blockchain technology, has challenged traditional monetary systems and economic structures. Since their inception in the wake of the Global Financial Crisis, cryptocurrencies have been championed by advocates for their decentralized nature, security, and potential as a replacement for fiat currencies. Cryptocurrencies are often viewed in the public narrative as a solution for individuals and nations where conventional financial systems are dysfunctional or highly volatile, providing an alternative currency that is not controlled by the same rules as a potentially sub optimal financial system. The use of alternative currencies is not a new phenomenon. There is a large body of research devoted to understanding why people choose to use foreign fiat currencies. Due to the overlap in both potential use-cases and underlying conditions stimulating the use of both foreign fiat currencies and cryptocurrencies, this paper integrates the theory on the use of foreign fiat currencies into a model of cryptocurrency adoption.

Using four econometric models across two measures of cryptocurrency adoption, the analysis evaluates the influence of currency stability, investment, wealth, illicit activities ("sins"), remittances, capital controls and sovereign default risk on cryptocurrency adoption across a wide range of countries. The inclusion of sovereign default risks is novel in the cryptocurrency adoption research and is motivated by this factor's relevance in the currency substitution literature. No underlying factor showed consistent statistical significance and direction of effect. The strongest evidence for an underlying relationship was in relation to the sovereign default risk. This was the only factor with a consistent and statistically significant direction of effect across both measures of cryptocurrency adoption. Remittances, investment and sins showed a consistent statistically significant effect across two models using the same measure of cryptocurrency adoption. For investment and sins, the direction of effect aligns with previous findings in the literature. The findings suggest a negative relationship between remittances and cryptocurrency adoption, contrary to what the existing literature suggests. The findings in relation to currency stability were inconclusive. Capital controls were statistically insignificant across all models evaluated. The findings suggest additional factors not included in this paper play a role in the adoption of cryptocurrency, while also motivating more research into cryptocurrency's use as an alternative currency. This paper contributes both to the cryptocurrency adoption literature and the currency substitution literature by integrating the fields in joint econometric models.

The remainder of this section focuses on defining and elaborating on the two most important concepts of this paper: cryptocurrencies and currency substitution. It then discusses the gap in the literature that this paper attempts to fill and the research question used to that effect. At the end of this section, a short roadmap is provided.

As mentioned, a definition of cryptocurrencies is required. @arslanian2022 provides a taxonomy of digital assets which is used by this paper. This paper defines cryptocurrencies as any digital asset falling into the bracket of being *fungible* and in the sub-bracket *payment token*. Fungibility refers to individual tokens being functionally equivalent - there is no reason to prefer one token of a certain digital asset over another. This is similar to how no one pays attention to the serial number of a fiat bill. Within the fungible category, there are 3 categories, of which only the payment token is relevant for this paper. These are those fungible crypto assets designed to fulfill the functions of money (medium of exchange, store of value, unit of account). These tokens share the following general characteristics: time and location independent availability, (theoretical) security, speed, low-fee transactions, irreversible transactions, (pseudo) anonymity. Three distinct sub-categories of these tokens are now discussed.

## "Traditional" Cryptocurrencies

In contrast to fiat currencies, which derive their value from governmental decree and are backed by legal frameworks, traditional cryptocurrencies operate on a decentralized network of peer-to-peer transactions that do not rely on a central authority. This decentralized nature means that transactions are recorded on a distributed ledger known as blockchain, rather than by a trusted intermediary like a bank. Some cryptocurrencies, most notably Bitcoin, have a function which reduces and eventually ceases the issuance of new coins through network design. This deflationary programming is in stark contrast to fiat currencies, where the authorities usually target an inflation rate of around 2% annually [@ammous2018; @centralbanknews2025]. The slow(ing) growth in supply of some cryptocurrencies, again notably Bitcoin, relative to the existing supply of coins is what leads to the idea that these cryptocurrencies are as stable in value as gold. This is because the stability in value of gold is attributable to the phenomenon of large existing stocks with slow growth in supply [@ammousBTCstd]. Practically, Bitcoin's deflationary programming has worked so far, with average yearly price increases against major fiat currencies of around 100% since 2011, depending against which currency the price is measured [@curvo2025]. Other major cryptocurrencies like Ripple and Binance Coin use a similar system of a practically limited supply, even if the way the supply is limited is different from Bitcoin [@arslanian2022; @coinmarketcap]. Despite the fact that demand also influences the price of cryptocurrencies, the lack of control by a single entity and slow growth have spawned the belief that cryptocurrencies are immune to inflationary pressures, government control, and political instability, which can all negatively affect those using fiat currencies in the *status quo* financial system.

## Stablecoins

An important subset of payment tokens in relation to this topic are stablecoins. These are cryptocurrencies which have prices linked to reference assets. They are different from traditional cryptocurrencies in that the price is driven by factors other than the initial programming and the collective actions of the users. @catalini2022 identify the main ways stability can be achieved:

1.  Backing of the stablecoins by one or more fiat currencies. This is the most common way stablecoins attempt to achieve price stability.

2.  Backing of the stablecoin by one or more cryptocurrencies, not issued by the same entity as the stablecoin.

3.  Backing of the stablecoin by one or more cryptocurrency issued by the same entity as the stablecoin, which can be used to alter the price of the stablecoin, with the goal of maintaining a desired peg. This is also known as an *algorithmic* stablecoin.

4.  A suggested market mechanism for stability has also been found in the research. Some papers argue that the increased purchase of stablecoins during market downturns, rather than traditional cryptocurrencies acts as an additional stabilizing force for stablecoins' prices, beyond the currency architecture [@baur2021; @lyons2020].

Stablecoins have the potential to combine the stability benefits of well managed fiat currencies with the settlement speed advantages of payment tokens [@catalini2022]. There is evidence that these tokens are already being used precisely for this. For example, a local Brazilian crypto expert spoke to Chainalysis on the large transaction volumes on Brazilian exchanges, stating "many of Brazil's exchanges and fintech brokerages offer USD-pegged stablecoins to their customers\...but at this stage, it appears that the main use cases for stablecoins are on the B2B[^1] cross-border payments side" [Aaron Stanley as cited in @chainalysis2024, p. 33]. While the consensus is that stablecoins are more stable than traditional cryptocurrencies, they have not managed to maintain the desired pegs to fiat currencies consistently [@baughman2022; @kosse2023]. Despite these issues, the interest in stablecoins has increased from June 2023 - June 2024 (albeit less strongly compared to traditional cryptocurrencies) among institutions making transactions under USD 10M, with the share of stablecoin inflows on exchanges outside the US increasing [@chainalysis2024]. All of this is an indication that the stablecoin subset of cryptocurrencies will continue to be relevant in the future, particularly as a means of transaction.

[^1]: B2B: Business-to-Business (not in original quote)

## Central Bank Digital Currencies

Central Bank Digital Currencies are "a new form of digitized sovereign currency, generally conceived to be equal to physical cash or reserves held at the central bank" [@arslanian2022, p. 171]. While the interest in such technologies is increasing drastically, with most central banks (including every Group of 20 country's) exploring the issue, no major economy has created and fully launched one - at the time of writing just the Bahamas, Jamaica and Nigeria have done so. Other countries have advanced pilot programs which already had transactions [@atlanticcouncil2025]. Central Bank Digital Currencies have many theoretical advantages as well as risks [@arslanian2022; @genc2024]. An extensive discussion of these is beyond the scope of this paper, particularly due to this application of cryptocurrency technology being in its infancy in terms of practical use and therefore of limited relevance to the data in this paper. The same governmental involvement in a digital asset that can bring substantial benefits also introduces a level of control by a small group of policymakers. This control carries the risk of misuse, whether deliberate or unintentional, and potentially against the public interest.

## Adoption of Cryptocurrencies

Cryptocurrency adoption has not been uniform. As Figure \@ref(fig:AdoptionMap) shows, for those countries with available data, the number of survey respondents who said they use cryptocurrency was as low as 6% and as high as 47% in 2023. Factors driving cryptocurrency adoption vary across countries and are heavily debated among academics (see \@ref(adoption-of-cryptocurrency)). Understanding the global drivers of cryptocurrency adoption, particularly in the context of factors that are more relevant for emerging markets with less developed financial systems provides a valuable insight into cryptocurrency's potential future size and role in the global economy. This is especially important as recent years have seen substantial growth in the cryptocurrency interest coming from countries outside the high-income bracket [@chainalysis2024].

\FloatBarrier

```{r AdoptionMap, echo = F, fig.cap="Map Showing Cryptocurrency Adoption Percentage for 2023 (Statista, 2024b)",fig.width=6, fig.height=1.9, fig.pos = 'H'}
selected_year <- "2023"  # Changeable variable
# Rename columns for compatibility
d.Adoption_long <- d.Adoption %>%
  rename(iso_a3 = Country) %>%
  select(iso_a3, all_of(selected_year))

# Load world map data
world <- ne_countries(scale = "medium", returnclass = "sf")

# Merge dataset with world map
world_data <- left_join(world, d.Adoption_long, by = "iso_a3")

# Plot world map
ggplot(data = world_data) +
  geom_sf(aes(fill = get(selected_year))) +
  scale_fill_gradientn(colors = c("#ffffff", "blue"), na.value = "grey") +
  labs(#title = paste("Adoption Data for Year", selected_year),
       fill = "Adoption (% of Population)") +
  #theme_minimal(base_family = "")+
   theme(legend.title = element_text(size = 10, family = "times"))  # Adjust legend title text size here
  
```

\FloatBarrier

## Decentralized Alternatives

Two key factors have led to the idea that cryptocurrencies can be used as an alternative to fiat currencies. These two factors are the **internet-based nature** and the **relative price stability** of cryptocurrencies, depending on the inflationary context. Firstly, the internet-based nature means that most people with a smartphone and internet can access the necessary infrastructure to buy, sell and own cryptocurrencies. This extends beyond political borders. There is nothing intrinsically hindering people or institutions in different jurisdictions from exchanging with each other. This is different to fiat currencies, where the ability of people to exchange currency with one another can be limited by the regulations applying to financial services companies and a lack of physical proximity, in the case of cash.

Secondly, depending on the context, the price of cryptocurrencies can be relatively stable, or at least volatile with a desirable upward trend in price, from the perspective of somebody owning the cryptocurrencies. Stability of local currency is usually measured either using inflation or the exchange rate to major currencies. As mentioned earlier, evidence shows stablecoins may not match the stability of major currencies they normally track. However, stablecoins can be more stable than fiat currencies in economies experiencing higher levels of currency depreciation [@baughman2022; @kosse2023]. As can be seen in Figure \@ref(fig:fig-usdt), the world's most popular stablecoin, by market capitalization, USD Tether has been stable against the USD.[^2] The highest average monthly drop from the USD peg was less than 15%, which was an extreme event in the infancy of the coin. Particularly since January 2018, the price has experienced only small fluctuations [@coinmarketcap]. The relative price stability of USD Tether becomes evident when looking at the depreciation of certain currencies against the USD. Table \@ref(tab:depreciation-USD) shows the number of countries' currencies where the depreciation exceeded certain thresholds. 74 country's currencies lost more than 25% of their value against the USD, while 29 lost more than 100% of their value against the USD in the time period 2014 - 2023. The true number of countries in these cases is likely higher, as some countries were unable to be evaluated due to lacking data. The point is that a stablecoin like USD Tether has the potential to outperform certain country's fiat currencies, when taking the metric of depreciation against a major currency like the USD. Meaning, there is a possibility for such stablecoins to act as a store of value.

[^2]: In Figure \@ref(fig:fig-usdt) the y-axis shows only values above 500. This is done so changes can be visually assessed easier - visually this choice increases the deviations in value from the USD compared to using the full scale. The true scale begins at 0.

When looking at traditional cryptocurrencies and their potential for acting as a value storage, the evidence suggests something else. For the sake of simplicity, Bitcoin will be taken as the sole example here, as it is the largest by market capitalization [@coinmarketcap]. Bitcoin has an average yearly growth rate in value of around 100% since 2011, when measured against major currencies [@curvo2025]. This far outpaces the global average inflation rate of 3.2% since 2011, and many country's individual inflation rates [@worldbank2024_Inflation]. Volatility of the coin means investors need a long time horizon to reliably capitalize on these gains in value, and even then, due to cryptocurrencies only existing since 2008, there is limited long term evidence for its value maintenance [@coinmarketcap]. To my knowledge, no specific research exists tracking the performance of multiple cryptocurrencies against multiple fiat currencies, either using inflation or depreciation. This is why some illustrative examples using the stablecoins and traditional cryptocurrencies with the most market capitalization are used here. The point illustrated is that both stablecoins and traditional cryptocurrencies have the potential to maintain, if not increase, their value when compared against various fiat currencies. They therefore could provide an alternative to fiat currencies.

\FloatBarrier

```{r fig-usdt, fig.cap="Value of 1000 USD Tether in USD (Statista, 2025b)", echo=FALSE, warning= F, fig.width=6, fig.height=3, fig.pos = 'H'}

# Tether Price -> 
# Source: https://www.statista.com/statistics/1269281/tether-price-index/
path <- "Data/d.USDT/Statista_2025b.xlsx"
d.Tether <- read.xlsx(path,sheet = "Data")

d.Tether$Date <- as.Date(parse_date_time(d.Tether$Date, orders = "b Y"))

ggplot(d.Tether, aes(x = Date, y = Price)) +
  geom_line(color = "#4A9FD8", size = 0.5) +
  scale_x_date(
    date_labels = "%b %Y",
    date_breaks = "3 months",
    expand = c(0, 0)
  ) +
  scale_y_continuous(
    limits = c(500, NA)  # This sets the lower bound to 500 and keeps the upper bound dynamic
  ) +
  labs(x = "Time", y = "Price in USD") +
  #theme_minimal() +
  theme(
  axis.text.x = element_text(angle = 90, hjust = 1, size = 8),
  axis.text.y = element_text(size = 8),
  axis.title.x = element_text(size = 10),  # X-axis label size
  axis.title.y = element_text(size = 10),  # Y-axis label size
  panel.grid.major = element_line(size = 0.2, linetype = "solid", color = "gray80"),
  panel.grid.minor = element_blank()
  )

```

\vspace{0.25cm}

```{r depreciation-USD, echo = F, warning=F}
library(readxl)


# Load depreciation data
path <- "Data/d.Depreciation/LCU_WorldBank2025.xls"
d.Depreciation <- read_excel(path, sheet = "Data", skip = 3)

# Filter to include only valid countries (using an external list `d.Country_Codes`)
d.Depreciation <- d.Depreciation %>%
  filter(`Country Code` %in% d.Country_Codes$Country.Code) %>%
  select(`Country Name`, `Country Code`, `Indicator Name`, `Indicator Code`, `2008`:`2024`)

# Calculate percentage depreciation between 2014 and 2023
d.Depreciation <- d.Depreciation %>%
  mutate(drop_value_2014_2023 = (`2023` - `2014`) / `2014` * 100)

# Summarize how many countries exceed each threshold
depreciation_summary <- d.Depreciation %>%
  summarise(
    `> 100` = sum(drop_value_2014_2023 > 100, na.rm = TRUE),
    `> 50`  = sum(drop_value_2014_2023 > 50,  na.rm = TRUE),
    `> 25`  = sum(drop_value_2014_2023 > 25,  na.rm = TRUE)
  )

# Transpose to make thresholds rows instead of columns
depreciation_summary_t <- data.frame(
  `Depreciation Threshold` = names(depreciation_summary),
  `Number of Countries` = as.numeric(depreciation_summary[1, ])
)

# Display the styled table
kable(depreciation_summary_t,
      col.names = c("Depreciation against USD (%)", "Number of Countries"),
      caption = "Number of Countries with Currency Depreciation Against the USD Exceeding Certain Percentages in the Period 2014â2023 (World Bank, 2025)",
      booktabs = TRUE) %>%
  kable_styling(full_width = FALSE, latex_options = "hold_position")



#d.depreciation_over_100<-d.Depreciation %>% 
#  filter(drop_value_2014_2023 >100)

#d.depreciation_over_50<-d.Depreciation %>% 
#  filter(drop_value_2014_2023 >50)

#d.depreciation_over_25<-d.Depreciation %>% 
#  filter(drop_value_2014_2023 >25)

```

\FloatBarrier

## Currency Substitution

The use of alternative currencies by people is not new, there is an entire body of research devoted to understanding this practice, known as *currency substitution*. Currency substitution is defined by @calvo2002 as the highly prevalent use of foreign fiat currencies to fulfill any of the three functions of money (store of value, means of exchange, unit of account). Note, there is also something known as official currency substitution, which is when a government officially adopts a foreign currency as a legal tender in their own country. However, this paper refers to the personal and unofficial use by individuals. Inflation and unstable economic climates are key drivers when it comes to the use of foreign currencies (see \@ref(currency-substitution-1), for a more detailed analysis). As such, the reasons that people may adopt foreign currencies are similar to the proposed benefits of cryptocurrencies. This leads to the idea that people could use cryptocurrencies, rather than foreign currencies to fulfill their need of an alternative currency - this concept is known as *Dollarization 2.0* [@peprah2018]*.* Please note, although the term contains the word of the USD, it does not imply that cryptocurrency replaces fiat currencies only in areas that have traditionally used the USD as an alternative. It implies the use of cryptocurrencies as an alternative to both domestic and foreign fiat currencies in countries which have traditionally used foreign currencies as an alternative to their own domestic fiat currency.

There are both theoretical and practical examples showing that the advancement of technology can facilitate the use of foreign currencies. @guidotti1993 uses a theoretical model arguing that a reduction in transaction costs spurred by financial innovation can promote foreign currency use as the cost to using foreign currencies is reduced by the new technology. A practical study of Nigeria by @ujunwa2021 find that markers of technology, such as internet banking transactions are strong predictors of foreign currency use. It is therefore reasonable to argue that a new technology like cryptocurrency could promote the use of alternative currencies, even if it involves the use of a cryptocurrency, rather than a foreign currency. This argument holds true as long as the use of the new technology and currency reduce the costs for those using said technology and currency.

This research paper draws upon the well-established theories of currency substitution to explore the factors driving cryptocurrency adoption. By examining the similarities between currency substitution and cryptocurrency adoption, this study aims to determine whether the predictors of currency substitution can be built into models of cryptocurrency adoption to improve the explanatory power.

## Literature Gap and Relevance

The research is relevant for both academics and policymakers. The potential contribution to the academic literature is twofold. Firstly, existing models cannot fully explain the differences in adoption seen across countries. Secondly and more innovatively, the paper provides an analysis (usually done on foreign currencies) for cryptocurrency through the lens of currency substitution. As will be seen in the subsection: [Dependent Variable: Cryptocurrency Adoption], this research paper makes use of a new panel dataset of cryptocurrency adoption that will be able to capture the most recent trends in this area.

In terms of policymakers, it is important for them to understand how changes in underlying economic conditions may influence the use of cryptocurrency, as this will have policy implications. It is likely that questions around cryptocurrency will increase in importance in the future due to the increased interest and usage of cryptocurrencies globally, both from private individuals and governments looking to capitalize on the technology in various ways. Figure \@ref(fig:fig-btc) shows the trend in cryptocurrency's market capitalization in USD from 2010 - 2025. This growth in market capitalization is evidence of increased interest in the technology among market players.

In addition to the increased market capitalization, policymakers have begun to carve out a space for blockchain technology in their economies in different ways. Likely the most famous example is El Salvador legislating Bitcoin as a legal tender in their country in 2021 [@bbc2021]. However, there are also other examples such as the canton of Zug in Switzerland allowing residents to pay taxes up to CHF (Swiss Franc) 1.5M with certain cryptocurrencies [@chainalysis2024; @kantonzug]. Other countries have taken non-accommodative stances towards certain cryptocurrencies, including bans on use and transactions. The only major economy to outright ban a cryptocurrency is China. Regulations tend to focus only on Bitcoin, rather than all cryptocurrencies, and no research exists tracking the exact nature of regulations [@nessi2025; @newhedge]. In summary, research aiming to understand drivers of cryptocurrency usage is likely to remain relevant or even increase in importance in the foreseeable future. This is particularily true for policymakers aiming to achieve regulatory goals.

\FloatBarrier

```{r fig-btc, fig.cap="Cryptocurrency Market Capitalization 2010-2025 (Statista, 2025a)", echo=FALSE, warning= F, fig.width=6, fig.height=3, fig.pos = 'H'}

# Working Bitcoin Adoption-> 
# Source: https://www.statista.com/statistics/730876/cryptocurrency-maket-value/
path <- "Data/d.Market_Cap_BTC/Statista_Crypto_Market_Cap.xlsx"
d.Market_Cap <- read.xlsx(path,sheet = "Data") 
d.Market_Cap$Date <- as.Date(d.Market_Cap$Date, format="%b %d, %Y")

ggplot(d.Market_Cap, aes(x = Date, y = Capitalization)) +
  geom_line(color = "#4A9FD8", size = 0.5) +   # Line plot
  scale_x_date(date_labels = "%b %Y", date_breaks = "3 months",
               limits = c(min(d.Market_Cap$Date), max(d.Market_Cap$Date)),
               expand = c(0, 0)) +  # Prevents ggplot from adding extra space
  labs(
       x = "Time",
       y = "Market Capitalization\n(in Billion U.S. Dollars)") +
  #theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8),  # Adjust x-axis text
    axis.text.y = element_text(size = 8),
    axis.title.x = element_text(size = 10),  # X-axis label size
    axis.title.y = element_text(size = 10),  # Y-axis label size
    panel.grid.major = element_line(size = 0.2, linetype = "solid", color = "gray80"),  # Reduce major gridline thickness
    panel.grid.minor = element_blank()  # Completely remove minor gridlines
  )
```

\FloatBarrier

```{r, echo = F}
# Remove Taiwan (TWN)
d.Adoption <- d.Adoption %>% filter(Country != "TWN")
```

## Research Question

Due to the similarity in reasons for the adoption of foreign currencies and cryptocurrencies, this paper evaluates a model considering not only the predictors of cryptocurrency usage (currency stability, investment, wealth, sins, remittances, capital controls), but also the additional factor coming from the currency substitution literature (sovereign default risk) to see if including this can build an improved model of cryptocurrency adoption. These factors will be discussed in the next section, \@ref(literature-review). Technology is not explicitly included as a predictor, despite its discovery in the literature since this is assumed to be fully covered by the introduction of cryptocurrency, itself, a new technology.

The research question can be summarized as: *Do currency stability, investment, wealth, sins, remittances, capital controls and sovereign default risk affect the adoption of cryptocurrency?*

### Roadmap {.unnumbered .unnumbered .unlisted}

For the definition of the research topic, two questions/fields are of interest: "What drives currency substitution?" and "What drives the adoption of cryptocurrencies?" An overview on the research on the topics is provided next, separated into the sections on currency substitution and cryptocurrency adoption. From these reviews the research question seen above was developed. Next, the methods, data and data transformation used to answer the research question will be discussed and visualized. Finally, the empirical results are shown, discussed and placed in the academic context to provide conclusions for researchers and policymakers interested in what factors can drive the adoption of cryptocurrency.

\newpage

# Literature Review

This section discusses the literature on both currency substitution and drivers of cryptocurrency adoption. The point of this section is to understand which socioeconomic factors should be included in a study of cryptocurrency adoption aiming to consider, in addition, the theory on currency substitution. First, the currency substitution literature is discussed and then the cryptocurrency adoption literature.

## Currency Substitution

There is a body of academic literature evaluating why individuals use foreign currencies, discussed in this section. Currency stability and the risk of sovereign default are identified as reasons that people may use foreign currencies. Those interested in a succinct visual overview of the currency substitution literature should visit Table \@ref(tab:litreviewCS) in Appendix 1.

### Currency Stability

The stability of local currencies as a driver for foreign currency adoption is a debated issue in the academic literature. There are two main ways of looking at currency stability: inflation and exchange rate. These two ways of measuring currency stability are now discussed in the context of currency substitution.

#### Inflation {.unnumbered .unnumbered .unlisted}

Both perceived and real economic problems are identified in the literature as reasons for people to engage in currency substitution. The primary economic issue here is inflation. There are quantitative studies, such as those by @vieira2012 and @rennhack2006, finding that inflation is a key predictor of currency substitution. Another quantitative paper @honig2009 argues that lack of trust in the stability of the local currency leads people to use foreign currencies. Finally, an implicit argument for the viewpoint that inflation leads to currency substitution is made by @kokenyne2010 who argue that countries wishing to stop currency substitution from happening in their domestic economies should focus their efforts on taming excess inflation. This claim is backed up by a practical study of the Turkish economy by @tasseven2015 who argues that foreign currencies were used precisely due to the high inflation in the 1990s and then began falling out of favor as price stability increased. @levy2021 makes a similar conclusion when he credits inflation first among a number of factors for the success of many Latin American countries to reduce currency substitution, oftentimes seen as negative by policymakers. Although a considerable number of studies credit inflation as positively related to currency substitution, one study focusing on Croatia, Slovenia and Slovakia by @stix2011 did not find inflation to be a contributing factor to currency substitution.

#### Exchange Rate {.unnumbered .unnumbered .unlisted}

Another measure of currency stability - the volatility of the exchange rate to major currencies - is also oftentimes found to be important in relation to individuals using a foreign currency. Using a Threshold Autoregressive Conditional Heteroskedasticity model on 28 countries and an Autoregressive Distributed Lag model of Nigeria, @ju and @ajibola2021, respectively, find that there is a correlation between the foreign exchange rate volatility and the use of foreign currencies. Contrary to these findings, the already mentioned study by @stix2011 did not find exchange rate volatility to be a contributing factor to currency substitution.

### Risk of Sovereign Default

The risk of sovereign default also appears in the literature on currency substitution, although less prominently than inflation. @vieira2012 find this to be a stronger predictor of currency substitution than inflation in their quantitative study on 79 economies at different levels of development. To the best of my knowledge, no other studies have evaluated this convincingly. Although @vieira2012 did cite a number of papers as foundations for evaluating the risk of sovereign default in their review, many of these do not clearly claim the logic applied by @vieira2012. Other studies in the area tend to focus on official currency substitution and the effect that this choice has on the risk of sovereign default [@berg2000; @sims2001]. Little consideration is given to the choice of individuals to use a foreign currency and how this choice is influenced by the risk of sovereign default. However, the study by @vieira2012 clearly shows its importance, and therefore this factor should be included in any comprehensive study examining the underlying factors behind currency substitution and their role in driving cryptocurrency adoption.

## Adoption of Cryptocurrency

In parallel to the currency substitution literature, there is a wide body of literature studying the usage of cryptocurrency. The literature finds inflation, investment, wealth, illicit activities ("sins"), remittances and capital controls as factors connected to the adoption of cryptocurrency. Many of these studies focus on Bitcoin specifically rather than cryptocurrencies as a whole. However, since Bitcoin is the largest cryptocurrency by market capitalization, Bitcoin can serve as an analytic proxy for cryptocurrency as a whole. Those interested in a succinct visual overview should visit Table \@ref(tab:litreviewCA) in Appendix 1.

### Inflation

There are a number of studies that have evaluated the relationship between cryptocurrency and inflation. @choi2022, @conlon2021 and @gaies2024 study time series data on Bitcoin prices and find that they are correlated positively to inflation or inflation expectations. Mixed evidence is presented by @phochanachan2022, who find the inflation hedge is only present in the short term. @chainalysis2024 evaluated Argentine stablecoin trading data on the leading local exchange Bitso and found that with each devaluation against the USD (associated with an increase in Argentine inflation), the monthly stablecoin trading volume on Bitso increased. This indicates trading volume increases in response to the Argentine peso losing value and associated inflation. Similar results but evaluated for Bitcoin instead of stablecoins exist in Venezuela [@chainalysis2024]. Academic case studies of countries using cryptocurrency in response to inflation are limited; only @taskinsoy comes up. He argues that the relative instability of the Turkish Lira is what drives many in the country to use Bitcoin instead of the local currency.

Studies similar in methodology to those mentioned at the beginning of this section study time series data of inflation and the price of Bitcoin; these, however, find no significant correlations [@basher2022; @smales2024]. In studying country economies using cross-sectional data, both @parino and @ricci2020 find that there is a negative correlation between inflation and the price of the cryptocurrency Bitcoin. However, it should be noted that the former focused on data from before 2015, which may have been too early to see adoption in developing countries. The latter only evaluated already developed economies, which have seen lower levels of inflation compared to developing countries.

### Investment

Investment is found as a key use case for the purchase of cryptocurrencies. @voskobojnikov2020 conduct interviews among North American respondents and find investment is one of the main intended uses of cryptocurrency among non-users. Quantitative studies support this idea. @glaser2014 find that the pattern of trading on the now defunct Mt. Gox cryptocurrency trading platform imply that users were investing, not using the currency for payments. The authors argued that while the value of currencies on individual accounts did change, the total value on the exchange did not change significantly. To the authors, this suggested that users were shuffling funds between each other but not using the cryptocurrencies for payments. In the case of payments, funds would have had to leave the exchange because it is unlikely the sellers of most goods and services would have been on the exchange. Therefore, in a payment use case, the overall value of coins on the exchange would have had to change, but this did not happen.

### Wealth

Wealth is a well-established factor connected to cryptocurrency in academia, studied through various methods. @lammer2019 studied German bank accounts and found wealthier people were more likely to own Bitcoin. This conclusion is supported, on a national scale, by @parino who found Gross Domestic Product (GDP) per capita to be positively correlated to Bitcoin ownership. Further survey-based evidence on the average cryptocurrency user is provided by @gemini2021 who find the average American cryptocurrency investor has a household income of USD 110K, more than 1.5 times the national average for that year. It should be noted that the survey was not representative and explicitly only included those with a household income above USD 40K, meaning the real average household income of the average investor is likely lower. While these sources do not aim to understand the reasons to why wealthier people are more likely to own cryptocurrencies, a possibility is that generally volatile cryptocurrencies may only be bought by those who can afford to take temporary losses when the price of the asset decreases.

### Illici Uses ("Sins")

The use of cryptocurrencies in areas that are illegal or considered immoral is also a driver of their usage in many cases. Due to the diversity of illicit use cases, only some illustrative examples will be presented here. It ranges from using Bitcoin to pay for illicit goods and services, such as was possible on the now defunct Silk Road dark-web sites [@saurabh2017]. Research has also found that in countries with larger shadow economies, the Bitcoin trading volume is much more strongly responsive to shocks to the shadow market (raids, seizures), indicating the cryptocurrency Bitcoin is used for illicit transactions [@marmora2021].

Cryptocurrencies may also be used by sanctioned countries to settle international debts. Iranian academics have evaluated the possibility of using cryptocurrencies to settle debts for their resource exports, which is difficult to do in the current international settlement architecture given the punitive international sanctions placed on the country [@sarvi2020]. Venezuela developed the *Petro*, a cryptocurrency with value tied to the country's oil reserves. It was meant to serve as a means of settling international payments for the sanctioned country. The project was discontinued in 2024 [@macfarlane2021; @rfi2024].

Sanctions on individuals also seem to drive the adoption of cryptocurrencies. According to an analysis by @chainalysis2020 75% of all cryptocurrency transactions on a randomly selected Venezuelan exchange were over USD 1K. Given the relatively low wages in the country, it is likely that this represents sanctioned individuals who have profited from the regime, attempting to move funds out of the country. Similarly, Russian language cryptocurrency exchanges without Know Your Customer (KYC) regulations have tripled since the start of the war in Ukraine and the following sanctions on both individuals connected to the Kremlin and ordinary Russians. The idea that this growth is connected to the sanctions is supported by the absence of growth in Russian-speaking exchanges that do conduct KYC checks and presumably comply with international sanctions [@chainalysis2024]. Further evidence is provided by @alnasaa2022, who see higher adoption of Bitcoin in more corrupt countries, which will have more individuals sanctioned by the international community.

### Remittances

Another potential reason for the adoption of cryptocurrency is for remittance payments. This has not been studied extensively academically, but the economic fundamentals and some practical examples show the potential. Fees for remittance payments can be very expensive, between 6.9-20% according to @ruehmann2020. Simultaneously, blockchain technology can have incredibly low fees, typically between 0-1% according to @dyhrberg2018. This low cost has led some academics like @folkinshteyn2015 to argue cryptocurrencies like Bitcoin could form an important aspect of lowering remittance costs. This cost advantage was the official reason behind El Salvador making Bitcoin legal tender in 2021 [@bbc2021]. Data from other areas and cryptocurrencies supports the cost idea as well. @chainalysis2024's data suggests 60% lower costs for a USD 200 payment from sub-Saharan Africa when using a transfer system based on stablecoins compared to a traditional fiat based system. In addition, there was at one point a concerted effort by the Libra Association (led by Meta) to release a stablecoin that was to be integrated with existing and widely used communications platforms such as WhatsApp. Through this integration, it had the potential to provide basic banking services to the 1.1 Billion people globally who have a mobile phone, but no bank account [@worldbank2018]. While challenges like internet access and user identity verification would have remained, the potential of this stablecoin integrated in existing communication services for remittances was hard to deny [@ruchti]. Ultimately, the project ended due to regulatory opposition from the United States [@mcnickel2024]. All of that is to say that the potential for cryptocurrencies or the blockchain architecture to increase financial inclusion is not only supported by economic fundamentals but has been explored by serious market players. It is therefore worth including a proxy for remittances in an analysis on cryptocurrency adoption.

### Capital Controls

There exists research that claims capital controls are relevant to the adoption of cryptocurrency. @carlson2016 conducts expert interviews on Argentina and finds that capital controls can and are being circumvented using Bitcoin. @hu2021 studied Chinese Bitcoin transactions and concluded that 25% of the transaction volume represents capital flight out of the country. @viglione2015 find a similar result in a quantitative analysis of multiple economies. They see a premium being paid for Bitcoin in these countries, which they interpret as "extra demand" [@viglione2015, p. 6]. Additional evidence for the importance of capital controls is provided by @alnasaa2022, who ran a cross-country analysis including capital controls as a predictor and find the capital controls to be a statistically significant predictor of cryptocurrency usage. The study of capital controls as a predictor in any field is limited by the diversity of potential measures to restrict capital flow and the lack of a standardized metric.[^3]

[^3]: Note: An index such as the one produced in this paper from regularly published IMF Data could form the basis for a consistent and replicable study of capital controls. See Section \@ref(predictors-independent-variables).

\newpage

# Methodology

This section discusses the quantitative methods to answer the research question. It is organized as follows: firstly, common terms among the models are introduced, then the formulas defining the fitted input-output relationship between the independent and dependent variables are described, with additional terms being defined where necessary. Next, the hypothesis and significance level are discussed. Finally, benefits and drawbacks are discussed in relation to how well the methodology can answer the research question. Please note that in addition to these 3 models, an additional robustness check using a different dependent variable is performed. However, for this the description is done separately in the section \@ref(model-4-robustness-check-using-chainalysis-data) as it is addressed in less detail.

## Common Terms

The models have a number of common terms. These are listed and explained below.

$\beta_{1,2...7}$: Coefficients for each independent variable. The exact interpretation of these depends on the input-output relationship specified in the models. They all describe a certain change in the dependent variable connected to a change in the respective input variable.

$i$: Denotes the cross-sectional unit (country) in the panel data.

$t$: Denotes the time unit (year) in the panel data.

$\varepsilon$: The error term, capturing unobserved factors.

## Model 1: Linear Regression - No Transformation

The first model is a linear regression with the temporal aspect modeled as a categorical variable. A statistically significant term for the year dummy will have no effect on answering the research question. The formula can be seen below. The results for this model can be seen in the section \@ref(model-1-linear-regression-no-transformation).

```{=tex}
\begin{align*} 
\text{Cryptocurrency Adoption}_{i,t} &= \beta_0 + \sum_{t=2020}^{2023} \beta_t \cdot D_{t}\\ &+ (\beta_1 \cdot \text{Currency Stability}_{i,t}) \\ 
&+ (\beta_2 \cdot \text{Investment}_{i,t}) \\ 
&+ (\beta_3 \cdot \text{Wealth}_{i,t}) \\
&+ (\beta_4 \cdot \text{Sins}_{i,t}) \\
&+ (\beta_5 \cdot \text{Remittances}_{i,t}) \\
&+ (\beta_6 \cdot \text{Capital Controls}_{i,t}) \\
&+ (\beta_7 \cdot \text{Sovereign Default Risk}_{i,t}) + \varepsilon_{i,t} 
\end{align*}
```
The group of terms $\sum_{t=2020}^{2023} \beta_t \cdot D_{t}$ represent the categorical variables of each year, with the first year as the baseline. The dummy $D_t$ is 1 when the corresponding year is "present" and 0 otherwise. It ensures that for each year only the relevant shift in year is performed as only the one relevant year's term will be counted towards the summation. The summation starts at the year 2020, instead of the first year 2019 in the dataset, because 2019 is the baseline. $\beta_t$ specifically is the linear offset in dependent variable for the specific years.

$\beta_0$: The intercept, representing the baseline level of cryptocurrency adoption when all continuous predictors are equal to zero and the year is at the 2019 baseline [@utts; @vandervaart2019].

The terms $\beta_{1,2...7}$ represent the response in dependent variable as a result of increasing the corresponding variable by 1 while holding all of the other variables constant. In the case of fixed effects models, the terms represent the change after controlling for unchanging country characteristics due to the demeaning associated with the fixed effects [@dougherty2011; @utts; @zicha2020].

## Model 2: Linear Regression - Transformation

The second model extends the previous model by explicitly transforming variables. All dependent variables except for the categorical years are transformed. This is done to better meet the assumptions of a linear regression, which requires normally distributed variables and residuals. As will be seen in the section \@ref(descriptive-statistics), not all of the variables clearly meet this assumption. It is therefore worth running a model with transformations applied. The interpretation of the coefficients will become different as a result of the transformations. The Yeo-Johnson transformation will be used. This is an extension of the Box-Cox transformation allowing both negative and zero values, which are present in the data studied [@weisberg2001]. The results of this model can be seen in section \@ref(model-2-linear-regression-transformations).

The Yeo-Johnson transformation makes the following transformation by estimating a $\lambda$ value from the data [@weisberg2001]. The exact values for $\lambda$ used for the variables can be seen in Table \@ref(tab:YJ-lambda-tbl) in section \@ref(data-preparation).

```{=tex}
\begin{align*}   
\psi(X, \lambda) =
\begin{cases} 
\frac{(X + 1)^\lambda - 1}{\lambda} & \text{if } \lambda \neq 0, X \geq 0 \\[10pt]
\log(X + 1) & \text{if } \lambda = 0, X \geq 0 \\[10pt]
\frac{- \left[(-X + 1)^{2 - \lambda} - 1\right]}{2 - \lambda} & \text{if } \lambda \neq 2, X < 0 \\[10pt]
-\log(-X + 1) & \text{if } \lambda = 2, X < 0
\end{cases}
\end{align*}
```
This means that the formula for the transformed linear regression becomes the following:

```{=tex}
\begin{align*} 
\text{Cryptocurrency Adoption}_{i,t} &= \beta_0 + \sum_{t=2020}^{2023} \beta_t \cdot D_{t} \\
&\quad + \beta_1 \cdot \psi (\text{Currency Stability}_{i,t}, \lambda) \\ 
&\quad + \beta_2 \cdot \psi (\text{Investment}_{i,t}, \lambda) \\ 
&\quad + \beta_3 \cdot \psi (\text{Wealth}_{i,t}, \lambda) \\
&\quad + \beta_4 \cdot \psi (\text{Sins}_{i,t}, \lambda) \\
&\quad + \beta_5 \cdot \psi (\text{Remittances}_{i,t}, \lambda) \\
&\quad + \beta_6 \cdot \psi (\text{Capital Controls}_{i,t}, \lambda) \\
&\quad + \beta_7 \cdot \psi (\text{Sovereign Default Risk}_{i,t}, \lambda) + \varepsilon_{i,t}
\end{align*}
```
The group of terms $\sum_{t=2020}^{2023} \beta_t \cdot D_{t}$ has the same interpretation as in Model 1. It is a linear offset for individual years, relative to the baseline year, 2019.

## Model 3: Fixed Effects

Panel data gives the choice between fixed or random effects to account for omitted variable bias. In practical applications, the choice between fixed or random effect is decided using the Hausman Test [@dougherty2011]. The results of this test can be seen in Table \@ref(tab:ht-tbl) in section \@ref(hausman-test). The Hausman Test indicates that a fixed effects model should be used.

Fixed effects control for time invariant-differences between countries. It allows accounting for unobserved factors (like culture or policies) that do not change over time and therefore isolating the changes in the dependent variable associated with changes in the independent variable [@torres-reyna2007]. Explicitly including the year as a predictor is not done as it is unlikely that the time effects influenced the cryptocurrency adoption in countries in the same way. This is mainly due to the different policy responses to Covid-19 and associated socioeconomic consequences, which were vastly different globally. The formula for the fixed effect model can be seen below. The results of Model 3 can be seen in section \@ref(model-3-fixed-effects-1).

```{=tex}
\begin{align*}  
Adoption_{it} = \beta_1 \cdot \text{Currency Stability}_{it} 
+ \beta_2 \cdot Investment_{it} 
+ \beta_3 \cdot Wealth_{it} 
+ \beta_4 \cdot Sins_{it} \\ 
+ \beta_5 \cdot Remittances_{it} 
+ \beta_6 \cdot \text{Capital Controls}_{it} 
+ \beta_7 \cdot \text{Sovereign Default Risk}_{it} + \alpha_i + \varepsilon_{it}
\end{align*}
```
The term $\varepsilon_{i,t}$ represents the error term for each country and time.

The term $\alpha_i$ represents country specific, time invariant effects. It can be understood as the effect of being country $i$ on the response variable. It is a linear offset in response variable which does not vary with time or any input variable [@dougherty2011].

Notice the loss of the intercept $\beta_0$. The global intercept is replaced by country specific intercepts [@dougherty2011].

## Hypothesis

Formally, the null and alternative hypothesis, for all models, in words and mathematically are seen below.

**Null Hypothesis**

$H_0$: Currency stability, investment, wealth, sins, remittances, capital controls and\newline sovereign default risk have no statistically significant effect on \newline cryptocurrency adoption.\newline\smallskipline$H_0:\beta_1=\beta_2=\beta_3=\beta_4=\beta_5=\beta_6=\beta_7=0$

**Alternative Hypothesis**

$H_1$: At least one independent variable has a statistically significant effect\newline on cryptocurrency adoption.\newline\smallskipline $H_1: \exists \beta_j \neq 0, \quad \text{for at least one } j \in \{1,2,3,4,5,6,7\}$

**Direction of Effect**

The alternative hypothesis does not specify a direction of effect due to the exploratory nature of this paper, which is testing the integration of a proxy. Furthermore, much of the research into cryptocurrency adoption is conflicting. This makes not using a specific direction of effect in the alternative hypothesis an appropriate choice.

**Significance Level**

Due to the limited data size and therefore statistical power of this paper (see [Underlying Data]) a significance level at the upper end of the normal range ($\alpha=0.1$) will be used.

## Generalizability

Due to the broad range of countries included in this study, the generalizability of the results should be sufficient to account for most countries in the world. Figure \@ref(fig:fig-worldmap-selected) shows the countries available in the @statista_adoption dataset and being studied explicitly in this paper. It is clear that a diversity of countries are represented by the data, in different socioeconomic aspects, such as those found to be relevant in the literature review for both currency substitution and cryptocurrency adoption. The main criticism in terms of generalizability would likely be the under-inclusion of African countries, with just 4 out of the 54 countries on the continent represented. Nevertheless, the argument can be made that this research will be applicable to most countries whose economic data falls within the range of the independent variables. Extreme political and economic outliers such as North Korea will not fall within this scope, but that is typical of almost any national level panel data analysis.

In the case of Model 3 (and Model 4, defined later), generalizability is limited by the model design since coefficient $a_i$ in the model is calculated only for countries in the sample. The other models do not explicitly model the country as an input variable used to make predictions on unseen countries, meaning their generalizability is better relative to Model 3 and Model 4.

\FloatBarrier

```{r fig-worldmap-selected, echo = F, fig.width=6, fig.height=1.9, fig.pos = 'H', fig.cap= "Map Showing Countries With Available Cryptocurrency Adoption Data (Statista, 2024b)"}

world <- ne_countries(scale = "medium", returnclass = "sf")
display_country_codes <- d.Adoption$Country
world <- world %>%
  mutate(highlight = ifelse(iso_a3 %in% display_country_codes, "Yes", "No"))


world <- ne_countries(scale = "medium", returnclass = "sf")
display_country_codes <- d.Adoption$Country
world <- world %>%
  mutate(highlight = ifelse(iso_a3 %in% display_country_codes, "Yes", "No"))
ggplot(data = world) +
  geom_sf(aes(fill = highlight), color = "black", size = 0.01) +
  scale_fill_manual(values = c("Yes" = "#4A9FD8", "No" = "lightgray")) +
  #theme_minimal() +
  #theme(plot.margin = unit(c(0, 0, 0, 0), "cm"))+
  labs(fill = "Data Availability?") +
    theme(legend.title = element_text(size = 10))  # Adjust legend title text size here
  
```

\FloatBarrier

\newpage

# Underlying Data

This section discusses the underlying data used for this research paper. For some of the data presented here, the country variable is already altered before the presentation in this paper using the library {countrycode}, which can take different versions of country names and obtain the relevant three-letter code. For those cases, it means that in the data source there was a country name rather than a country code. All data, as well as the .Rmd file associated with this paper can be found by visiting the GitHub page linked in Appendix 4. The section proceeds by first discussing the dependent variable data, followed by the data used for the independent variables.

## Dependent Variable: Cryptocurrency Adoption

Cryptocurrency adoption is measured using a 2024 dataset by @statista_adoption. The dataset is the result of multiple surveys where respondents were asked if they had used cryptocurrency in a given year. The data's first six rows can be seen in Table \@ref(tab:Adoption). Due to the unavailability of data for the other variables for the year 2024, only data up to 2023 will be used in the statistical analysis. The data is available for 56 countries of different levels of economic development.

The data quality is sufficient given practical constraints. While the survey was not representative of the respective country's population and voluntary, opening the data quality up to self-selection issues, the only feasible improvement could have been a mandatory national census, conducted across countries. However, the effort in standardizing questions and timings across countries is prohibitive in practice. The authors describe their approach to data collection. It is clear and professional: sample sizes of at least 2K people per country, checks for bots, checks for speed racers and the survey was performed in the official languages of the country [@statista2020]. Overall, the quality of this variable is sufficient for the purposes of this research.

```{r Adoption, echo = F }
# Display table
d.Adoption %>%
  head() %>%
  kable(col.names = c("Country", "2019", "2020", "2021", "2022", "2023", "2024"), 
        caption = "Percentage of Respondents Who Reported Using Cryptocurrency in Select Years (Statista, 2024b)", booktabs = TRUE) %>%
  kable_styling(full_width = FALSE, latex_options = "hold_position")
```

## Predictors: Independent Variables

Table \@ref(tab:datatable) shows an overview of the indicators used as proxies for concepts discovered in the literature review and their sources. The indicators for wealth, remittances and risk of sovereign default are self-explanatory and of sufficient quality. Those indicators are sourced primarily from the World Bank, a standard data source for country-level economic data. In the case of missing individual data points, additional sources were used to augment the data where possible. The details of those manual imputations are discussed in \@ref(manually-adding-missing-data).

```{r, datatbl, echo = F, results = "asis"}
# Create the data frame with citations and special characters handled
lit_data_sources <- data.frame(
  Indicator = c( "Inflation, consumer prices (annual % change)",
                 "Gross domestic savings (GDS) (% of GDP)", 
                 "GDP per capita (current USD)",
                 "Personal remittances received (RR) (% of GDP)",
                 "External Debt (ED) (% of GDP)",
                 "Political Corruption Index",
                 "Bespoke Capital Controls Index"
                 #"Mobile Access (%)",
                 ),
  Proxy_for = c("Currency Stability", 
                "Investment", 
                "Wealth",
                "Remittances",
                "Risk of Sovereign Default",
                "Sins",
                "Capital Controls"
                #"Technology",
                ),
  Source = c("World Bank (2024c)",
             "World Bank (2024b)",
             "World Bank (2024a)",
             "World Bank (2024d)",
             "Focus Economics (2024)",
             "V-Dem (2024)",
             "IMF (2024)"
             #"World Bank",
             
  )
)

# Generate the table using kable
lit_data_sources %>%
  kable(col.names = c("Indicator", "Proxy for", "(Primary) Source"), caption = "Overview of Data Sources for Independent Variables (\\#tab:datatable)", booktabs = TRUE) %>%
  kable_styling(full_width = F, latex_options = "hold_position")


```

The following proxies must be discussed in further detail: currency stability, investment, sins, capital controls.

**Currency Stability**

The literature review showed currency stability, through exchange rate and inflation, to be an important determinant of both currency substitution and cryptocurrency adoption. However, this paper will use only the inflation rate as a proxy for currency stability as a whole. This choice is made for three reasons. Firstly, inflation and exchange rate are related and move together under normal circumstances, as shown in several research articles [@asari2011; @fetai2016; @sek2012]. This means the inflation rate can be used as an effective proxy for the exchange rate. Secondly, since they move together, there could be the issue of multicollinearity if both of them were included [@statisticssolutions]. Thirdly, as already mentioned, due to the limited data quantity, the inclusion of more predictors would have an adverse effect on statistical power, which is not a worthwhile trade-off given the two previously mentioned points.

**Investment**

Investment is closely related to savings in national accounting, though the strength of this relationship varies across economic models. In the classical model of a closed economy without government spending, savings are equal to planned investment [@mitchell2019]. This makes GDS as a percentage of GDP a reasonable proxy for the funds available for investment. This indicator is used as a proxy for the investment use case of cryptocurrency discovered in the literature review.

**Sins**

A single indicator is used to encompass all the sinful uses of cryptocurrencies identified in section: \@ref(illici-uses-sins). The two primary sinful uses are criminality and the circumvention of sanctions. Since the international community routinely sanctions individuals and not the countries themselves based on corruption, human rights abuses and other serious accusations, it makes sense to use corruption as a proxy for individual sanctions that people may attempt to circumvent using cryptocurrency [@u.s.departmentofthetreasury2022]. Using corruption as a proxy for crime is also a possible approach, as the link between corruption and (in particular organized) crime has been shown across several regions and studies [@buscaglia2003; @centerforthestudyofdemocracy2010; @mazzitelli2007].

The political corruption index, published by @politica2024, is used in an attempt to cover both crime and corruption. The index is made up of several subsets of corruption. In a study with more data quantity available, it would be appropriate to use specific types of corruption from this index combined with other indicators for criminality, such as the murder rate. However, due to the already limited data size, the trade-off of including several variables for the sinning attributes identified in the literature would be too adverse on the statistical power. Therefore, the aggregated corruption index is used, rather than a specific corruption indicator combined with a separate criminality proxy [@olin]. The @politica2024 data can be downloaded directly via library {vdemdata} in R-Studio after connecting to GitHub. The data is available only up to and including 2023. This index ranges between 0 (lowest possible corruption) and 1 (highest possible corruption).

```{r, warning = F, warning = F, message = F, echo = F }
# install.packages("devtools")
# uncomment above lines when running for the first time
devtools::install_github("vdeminstitute/vdemdata")
library(vdemdata)
d.Corruption <- vdem[, c("country_name", "year", "v2x_corr")] # relevant variables
d.Corruption <- d.Corruption %>%
  filter(year %in% c(2019: 2024)) # relevant years
d.Corruption$Country <- countrycode(d.Corruption$country_name, "country.name", "iso3c")
# above: world bank / ISO 3 code added
```

```{r, echo = F}
# Renaming, dropping and re-arranging column
d.Corruption <- d.Corruption %>%
  rename(Corruption = last_col(offset = 1)) %>%
  select(Country, everything(), -country_name) 

# Dropping Gaza / Westbank / NA (represents Kosovo, Somaliland and Zanzibar: These are causing aggregation issues and are not in the depdendent variable so can be safely removed
d.Corruption <- d.Corruption %>%
  filter(!Country %in% c("PSE", NA))


# Converting to Wide Format Panel Data
d.Corruption <- d.Corruption %>%
 pivot_wider(names_from = year, values_from = Corruption)  #%>% 
 # mutate(`2024` = NA)
```

**Capital Controls**

Since capital controls have been identified as important in literature review on cryptocurrency adoption, they must be accounted for in a model attempting to explain cryptocurrency adoption; a bespoke index is created to do that. There is a lack of structured and recent data around capital controls. Outdated structured data does exist [@fernandez2016]. The source used here will be from the online query tool of @imf2024 which allows the recovering of information contained in the annually published Report on Exchange Arrangements and Exchange Restrictions, specifically the 5 indicators: Controls on Personal Payments, Prior Approval, Quantitative Limits, Indicative Limits / Bona Fide Test and Controls on Personal Capital Transactions. The key limitation of this dataset is that the data is only available up to and including 2022. Techniques to deal with missing data will be used to make this dataset usable. The first six rows of the raw data can be seen in Table \@ref(tab:d).

```{r, d, echo = F}
path <- "Data/d.CC/IMF (2024).xlsx"
d.CC <- read.xlsx(path)
d.CC %>%
  head() %>%
  kable(
    col.names = c("Year", "IFS Code", "Country", 
                  "Controls Personal \\ Payments",  
                  "Prior \\ Approval",
                  "Quantitative \\ Limits",
                  "Indicative Limits / \\ Bona Fide Test",
                  "Controls on Personal \\ Capital Transactions"),
    escape = FALSE,  # Allows LaTeX commands like \\ to be used
    caption = "Head of IMF (2024) Capital Controls Dummy Data",
    format = "latex", booktabs = TRUE
  ) %>%
  kable_styling(full_width = F, latex_options = c("scale_down","H")) %>%
  column_spec(1, width = "0.7cm") %>%  # Custom width for Year
  column_spec(2, width = "1.5cm") %>%    # Custom width for IFS Code
  column_spec(3, width = "1.7cm") %>%    # Custom width for Country
  column_spec(4, width = "2.2cm") %>%    # Custom width for Controls Personal Payments
  column_spec(5, width = "2.0cm") %>%  # Custom width for Prior Approval
  column_spec(6, width = "2.3cm") %>%  # Custom width for Quantitative Limits
  column_spec(7, width = "3.3cm") %>%  # Custom width for Indicative Limits / Bona Fide Test
  column_spec(8, width = "3.5cm")      # Custom width for Controls on Personal Capital Transactions
```

In order to create a quantitative variable encompassing all capital controls as a whole, these variables will be turned into a bespoke index from 0 - 1 by assigning a value of 1 for each "Yes" and 0 for each "No" and then dividing the result by the number of available data points for that country in that year. Conceptually, this means that an index score calculated with just one available data point looks identical to one with all data points available. By using an equally weighted index generating method, the assumption is made that each of these types of restrictions is equally important in the types of capital controls that influence the adoption of cryptocurrency. In the case that a country has no data point (only the case once in the data), a NA is assigned to this value. Table \@ref(tab:tbl-ind-head-CC) shows the top six rows of the resulting data frame containing the index.

```{r d.CC-index-generation, echo = F,warning = F}
# Rename the last 5 columns to A, B, C, D, E
colnames(d.CC)[(ncol(d.CC)-4):ncol(d.CC)] <- c("A", "B", "C", "D", "E")

# Compute Index dynamically based on available (non-NA) values
d.CC$IndexCC <- rowSums(d.CC[, c("A", "B", "C", "D", "E")] == d.CC[11,4], na.rm = TRUE) / 
                 rowSums(!is.na(d.CC[, c("A", "B", "C", "D", "E")]), na.rm = TRUE)

d.CC$IndexCC[is.nan(d.CC$IndexCC)] <- NA # #converting 0 data point to NA

d.CC$Country <- countrycode(d.CC$Country, "country.name", "iso3c")

d.CC <- na.omit(d.CC, cols = "Country")
# Above Warnings Countries are not found in the Adoption set, can be safely removed

d.CC <- d.CC %>% select(Country, Year, IndexCC) # rearrannging and removing rows


d.CC <- d.CC %>%
  pivot_wider(names_from = Year, values_from = IndexCC) %>%  # make wide format
  mutate(`2023` = NA)#, `2024` = NA)
```

```{r tbl-ind-head-CC, echo = F}
kable(head(d.CC), caption = "Head of Table with Bespoke Capital Controls Index",
      row.names = F, booktabs = TRUE)
```

## Data Preparation

This section discusses how the data is treated to prepare it for analysis. The procedures are outlined in the subsections below. A list of country codes was used at various points throughout the analysis to combine datasets, sourced from @instituteforresearchonworldssystems .

### Removing Countries without Cryptocurrency Adoption Data {.unnumbered .unnumbered .unlisted}

Countries without a dependent variable are removed in this step, since without a dependent variable little insight can be gained, even if all the dependent variables are there. Due to lacking independent variable data, the value for Taiwan is also removed.

```{r removing-irrelevant-countries, echo = F, message = F, warning = F, include = F }
# Extract unique country names from d.Adoption
relevant_countries <- unique(d.Adoption$Country)

# List of original dataframes
IV_data <- list(
  d.CC = d.CC, 
  d.Corruption = d.Corruption, 
  d.ED = d.ED, 
  d.GDP = d.GDP, 
  d.GDS = d.GDS, 
  d.Inflation = d.Inflation, 
  d.RR = d.RR
)

# Find missing countries for each dataset
IV_countries <- lapply(IV_data, function(df) unique(df$Country))
missing_countries <- lapply(IV_countries, function(countries) setdiff(relevant_countries, countries))

# Print missing countries for each dataset
for (name in names(missing_countries)) {
  cat("\nMissing countries in", name, ":\n")
  print(missing_countries[[name]])
}

# Find countries that are missing in **any** dataset
all_missing_countries <- unique(unlist(missing_countries))

cat("\nCountries in d.Adoption but missing in at least one dataset:\n")
print(all_missing_countries)

# Apply filtering and overwrite original dataset names
filtered_datasets <- lapply(IV_data, function(df) {
  df[df$Country %in% relevant_countries, , drop = FALSE]
})

# Assign filtered datasets back to their original names in the environment
list2env(filtered_datasets, envir = .GlobalEnv)
```

### Removing Year 2024 from Cryptocurrency Adoption Data {.unnumbered .unnumbered .unlisted}

Since there is no data for any of the other indicators for the year 2024 in a structured and accessible format, the year 2024 is removed from the data on cryptocurrency adoption.

```{r removing 2024, echo = F}
d.Adoption <- d.Adoption %>% select(-'2024')
```

### Manually Adding Missing Data {.unnumbered .unnumbered .unlisted}

Due to the already small data size, where possible, missing independent variables are filled in manually. While this approach limits practical replicability, it offers the benefit of retaining slightly increased data quantity, which is a worthwhile tradeoff given the already low data quantity. The following information was added in this manner:

-   Argentina inflation rate 2018-2022 [@statistaArgentinaInflation]

-   Nigeria GDS (% of GDP) 2018-2021 [@nigeria]

-   Belgium, Canada, France, Ireland, Spain ED (% of GDP) 2018-2023 [@ceicdata2025]

```{r manual-impute-argentina, echo = F}
NGA_GDS <- c("2019" = 19.83, "2020" = 27.38, "2021" = 32.73, "2022" = NA, "2023" = NA)#, "2024" = NA)

NGA_row <- which(d.GDS$Country == "NGA")
d.GDS[NGA_row, 2:ncol(d.GDS)] <- NGA_GDS  # Assuming the first column is "Country"

Arg_Inf <- c("2019" = 53.55, "2020" = 42.02, "2021" = 48.41, 
             "2022" = 72.43, "2023" = 133.49)#, "2024" = NA)

arg_row <- which(d.Inflation$Country == "ARG")
d.Inflation[arg_row, 2:ncol(d.Inflation)] <- Arg_Inf  # Assuming the first column is "Country"

new_countries_External_Debt <- tibble(
  Country = c("BEL", "CAN", "FRA", "IRL", "ESP"),
  `2019` = c(257.579, 134.234, 235.061, 742.138, 169.725),
  `2020` = c(268.416, 149.077, 265.191, 702.699, 200.181),
  `2021` = c(260.193, 143.214, 258.592, 677.751, 193.562),
  `2022` = c(237.91, 134.904, 244.258, 577.158, 172.805),
  `2023` = c(237.68, 143.661, 245.047, 563.897, 165.481)#,
  #`2024` = c(NA, NA, NA, NA, NA)
)

# Add only missing countries
existing_countries <- d.ED$Country
missing_countries <- new_countries_External_Debt %>% filter(!Country %in% existing_countries)

# Append missing countries to d.GDS
d.ED <- bind_rows(d.ED, missing_countries)
```

### Missing Data Structure {.unnumbered .unnumbered .unlisted}

Since not all data can be added manually due to lacking reliable and consistent data sources, alternative techniques must be employed to deal with missing data. The way that missing values are dealt with depends on the quantity and structure of missing data. A standard approach is to say that any dataset having less than 5% missing can be treated with univariate imputation, such as adding the mean of a row or column for a missing piece of data. However, when more than 5% of the data is missing, the structure of the missing data begins being more important, and univariate imputation may not be appropriate. A Missing Completely at Random (MCAR) test can be used to check if univariate imputation is suitable for data with more than 5% missing. This is performed and the results can be seen in Table \@ref(tab:tblMCAR) [@schwarz2024]. The results indicate that univariate imputation can be used for all variables because the hypothesis that the data is not MCAR is either rejected at the 5% level or the number of missing values is less than 5%. The percentage missing column in the table applies only to the numeric columns, so the inclusion of country names in the data frame does not downward skew the proportion of missing numbers.

```{r fig-MCAR-fun, echo = F, message = F, warning=F}
library(dplyr)
library(naniar)
library(knitr)
library(kableExtra)

run_mcar_tests1 <- function(...) {
  dfs <- list(...)
  df_names <- sapply(substitute(list(...))[-1], deparse)  # Get dataframe names
  
  results <- data.frame(
    `Dataset` = character(),
    `Test Statistic` = character(),  # More descriptive header
    `Degrees of Freedom` = character(),
    `P-Value` = character(),  # Improved readability
    `Missing Patterns` = character(),
    `Missing Percent` = character(),  # More readable title
    `Significance Level` = character(),  # Full description
    stringsAsFactors = FALSE
  )

  for (i in seq_along(dfs)) {
    df <- dfs[[i]]
    df_name <- df_names[i]

    # Calculate missing percentage only for numeric fields
    numeric_cols <- df[, sapply(df, is.numeric), drop = FALSE]  # Select numeric columns
    total_numeric_values <- length(numeric_cols) * nrow(df)  # Total numeric data points
    total_missing_values <- sum(is.na(numeric_cols))  # Count missing values in numeric columns
    missing_percent <- round((total_missing_values / total_numeric_values) * 100, 2)

    # Check for missing values
    if (sum(is.na(df)) == 0) {
      results <- rbind(results, data.frame(
        `Dataset` = df_name,
        `Test Statistic` = "-",
        `Degrees of Freedom` = "-\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0No",
        `P-Value` = "Missing",
        `Missing Patterns` = "Values",
        `Missing Percent` = "0.00",  # No missing values
        `Significance Level` = "-"
      ))
    } else {
      test_result <- naniar::mcar_test(df)
      test_result <- as.data.frame(test_result)
      p_value <- test_result$p.value[1]

      # Determine significance level
      significance <- case_when(
        p_value < 0.01  ~ "Highly Significant",
        p_value < 0.05  ~ "Significant",
        TRUE            ~ "Not significant"
      )
      
      results <- rbind(results, data.frame(
        `Dataset` = df_name,
        `Test Statistic` = round(test_result$statistic[1], 2),
        `Degrees of Freedom` = test_result$df[1],
        `P-Value` = round(p_value, 4),
        `Missing Patterns` = test_result$missing.patterns[1],
        `Missing Percent` = paste0(missing_percent),
        `Significance Level` = significance
      ))
    }
  }
  
  # Rename columns for better readability
  colnames(results) <- c("Dataset", "Test Statistic", "Degrees of Freedom", 
                         "P-Value", "Missing Patterns", "Proportion Missing (%)", 
                         "Significance Level")

  # Print results using kable with column width adjustments
  kable(results, caption = "MCAR Test Results", digits = 4, format = "latex", booktabs = TRUE) %>%
  kable_styling(full_width = FALSE, latex_options = c("hold_position", "scale_down")) %>%
  column_spec(6, width = "4cm") %>%  # Slightly reduce "Proportion Missing (%)"
  column_spec(7, width = "5cm")  # Keep "Significance Level" but not too large
}



run_mcar_tests2 <- function(...) {
  dfs <- list(...)
  df_names <- sapply(substitute(list(...))[-1], deparse)

  results <- data.frame(
    `Dataset` = character(),
    `Test Statistic` = character(),
    `Degrees of Freedom` = character(),
    `P-Value` = character(),
    `Nr. Missing Patterns` = character(),
    `Missing Percent` = character(),
    `Significance Level` = character(),
    stringsAsFactors = FALSE
  )

  for (i in seq_along(dfs)) {
    df <- dfs[[i]]
    df_name <- gsub("^d\\.", "", df_names[i])  # Remove "d." prefix

    numeric_cols <- df[, sapply(df, is.numeric), drop = FALSE]
    total_numeric_values <- length(numeric_cols) * nrow(df)
    total_missing_values <- sum(is.na(numeric_cols))
    missing_percent <- round((total_missing_values / total_numeric_values) * 100, 2)

    if (sum(is.na(df)) == 0) {
      results <- rbind(results, data.frame(
        `Dataset` = df_name,
        `Test Statistic` = "-",
        `Degrees of Freedom` = "-\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0\u00A0No",
        `P-Value` = "Missing",
        `Nr. Missing Patterns` = "Values",
        `Missing Percent` = "0.00",
        `Significance Level` = "-"
      ))
    } else {
      test_result <- naniar::mcar_test(df)
      test_result <- as.data.frame(test_result)
      p_value <- test_result$p.value[1]

      significance <- case_when(
        p_value < 0.01  ~ "Highly Significant",
        p_value < 0.05  ~ "Significant",
        TRUE            ~ "Not significant"
      )

      results <- rbind(results, data.frame(
        `Dataset` = df_name,
        `Test Statistic` = round(test_result$statistic[1], 2),
        `Degrees of Freedom` = test_result$df[1],
        `P-Value` = round(p_value, 4),
        `Nr. Missing Patterns` = test_result$missing.patterns[1],
        `Missing Percent` = paste0(missing_percent),
        `Significance Level` = significance
      ))
    }
  }

  colnames(results) <- c("Dataset", "Test Statistic", "Degrees of Freedom", 
                         "P-Value", "Nr. Missing Patterns", "Proportion Missing (%)", 
                         "Significance Level")

  kable(results, caption = "MCAR Test Results", digits = 4, format = "latex", booktabs = TRUE) %>%
    kable_styling(full_width = FALSE, latex_options = c("hold_position", "scale_down")) %>%
    column_spec(6, width = "4cm") %>%
    column_spec(7, width = "5cm")
}


```

```{r tblMCAR, echo = F, fig.cap= "MCAR Test on Datasets (excluding d.CC)", warning=F}
run_mcar_tests2(d.Adoption, d.Inflation, d.GDS, d.GDP, d.RR, d.ED,d.Corruption)
```

The MCAR test could not be performed for the capital controls data as there is an entire column missing, as can be seen in Figure \@ref(fig:md-dCC). Such a structure is incompatible with the algorithm of the MCAR test. Therefore, in the interest of maintaining the highest reasonable data quantity, the 2022 (most recent) value will be imputed as the 2023 value. The logic behind this imputation is twofold. Firstly, it is unlikely for capital controls to significantly change in a single year, as it would require a policy shift. Secondly, this type of imputation should be applied here since mostly complete data is available for the other indicators for 2023. Removing another year in the whole analysis would further compound the data quantity issue. For a detailed guide on the interpretation of the Missing Data Pattern figure, please see subsection \@ref(interpretation-of-missing-data-pattern-figure).

```{r md-dCC, echo = F, fig.cap = "Missing Pattern of Bespoke Capital Controls Index based on IMF (2024)", fig.width=5, fig.height=1.8, message= F,  results="hide"}
md.pattern(d.CC[,-1])
```

```{r imputing dcc, echo = F, message= F, fig.width=5, fig.height=2,  results="hide"}
d.CC[[ncol(d.CC)]] <- d.CC[[ncol(d.CC) - 1]]
remove(filtered_datasets,IV_countries,IV_data,lit_data_sources,world,new_countries_External_Debt)
```

### Imputing Missing Data {.unnumbered .unnumbered .unlisted}

Since the missing data for all variables is of a structure that can use univariate imputation, as shown by the MCAR tests, this is done. The assumption behind the way that the imputations are done is that the country in which an observation happens is more important than the year in which it happens. Thus, it is preferred to impute using the country's available data for an indicator over the year's available data for an indicator. Due to this dataset taking place during the Covid-19 pandemic, it would not be suitable to just take a mean of all available years for a country. Instead, the average of the year before and after the missing data is used. If a data point is missing in the last year, only the previous available year's data from that country is used. If a data point is missing in the first year, only the first available year's data point of that country is used to impute. As can be seen in Figures \@ref(fig:md-Adoption) through \@ref(fig:md-ED-GDP) in Appendix 2, there are cases where the missing pattern is not in between available data points and the algorithm will rely on a single number for imputation. For the sake of brevity, this process is referred to as Nearest Average Imputation (NAI).

To be exact, the following imputations are performed:

-   Adoption data completed using NAI.

-   Inflation data completed using NAI.

-   GDS data completed using NAI.

-   No imputations are required for GDS data (complete data).

-   No imputations are required for Corruption data (complete data).

-   Average for all observations, separated by year, imputed for 1 country in the remittances data, as there were no values for any year for that country (United Arab Emirates). No other imputations had to be applied.

-   No imputations are required for Capital Controls data beyond the year 2023, which was imputed using the 2022 data as previously mentioned.

-   No imputations are required for the ED data (complete data).

With those changes, the data is ready for analysis. Note that all datasets are ran through the algorithm to perform the NAI to increase practical replicability of the underlying script.

```{r imputation-fun, echo = F}
fill_na_with_nearest_avg <- function(df) {
  # Compute column means (excluding 'Country' column), ignoring NA values
  col_means <- colMeans(df[, -1], na.rm = TRUE)

  for (i in 1:nrow(df)) {
    row_values <- df[i, 2:ncol(df)]  # Extract numeric part of the row (excluding country column)

    if (all(is.na(row_values))) {
      # If all values are NA, replace with column means
      df[i, 2:ncol(df)] <- col_means
    } else {
      for (j in 2:ncol(df)) { # Start from 2nd column to avoid modifying 'Country'
        if (is.na(df[i, j])) {
          prev_value <- NA
          next_value <- NA
          
          # Find previous non-NA value safely
          if (j > 2) {
            prev_values <- na.omit(as.numeric(df[i, 2:(j-1)]))  # Convert to numeric vector
            if (length(prev_values) > 0) {
              prev_value <- prev_values[length(prev_values)]  # Last previous value
            }
          }
          
          # Find next non-NA value safely
          if (j < ncol(df)) {
            next_values <- na.omit(as.numeric(df[i, (j+1):ncol(df)]))  # Convert to numeric vector
            if (length(next_values) > 0) {
              next_value <- next_values[1]  # First next value
            }
          }

          # Ensure `prev_value` and `next_value` are single numeric values
          prev_exists <- !is.na(prev_value) && is.numeric(prev_value)
          next_exists <- !is.na(next_value) && is.numeric(next_value)

          # Fill NA using the nearest available values
          if (prev_exists && next_exists) {
            df[i, j] <- (prev_value + next_value) / 2  # Average of both nearest values
          } else if (prev_exists) {
            df[i, j] <- prev_value  # Use only the previous value
          } else if (next_exists) {
            df[i, j] <- next_value  # Use only the next value
          }
        }
      }
    }
  }
  return(df)
}

# Example usage:
# df <- fill_na_with_nearest_avg(df)

```

```{r performing impuations, echo = F}
# For repeatability, all datasets are still run through the algorithm
d.Adoption_imp <- fill_na_with_nearest_avg(d.Adoption)
d.Inflation_imp <- fill_na_with_nearest_avg(d.Inflation)
d.GDS_imp <- fill_na_with_nearest_avg(d.GDS)
d.GDP_imp <- fill_na_with_nearest_avg(d.GDP)
d.Corruption_imp <- fill_na_with_nearest_avg(d.Corruption)
d.RR_imp<-fill_na_with_nearest_avg(d.RR)
d.CC_imp<-fill_na_with_nearest_avg(d.CC)
d.ED_imp <- fill_na_with_nearest_avg(d.ED)

# Save as _UNimp the unimputed sets
d.Adoption_UNimp <- d.Adoption
d.Inflation_UNimp <- d.Inflation
d.GDS_UNimp <- d.GDS
d.GDP_UNimp <- d.GDP
d.Corruption_UNimp <- d.Corruption
d.RR_UNimp <- d.RR
d.CC_UNimp <- d.CC
d.ED_UNimp <- d.ED

```

### Interpretation of Missing Data Pattern Figure {.unnumbered .unnumbered .unlisted}

This guide is relevant for Figures \@ref(fig:md-dCC) and Figures \@ref(fig:md-Adoption) through \@ref(fig:md-ED-GDP). The figures consist of horizontal bars, one for each of the configurations of missing data. Blue represents a present year and red an absent year. The top headings represent the row headings. The number to the left of each bar represents the number of times a configuration of missing data is represented in the dataset. The number on the right represents the number of missing data points in a single observation, for a particular configuration of missing data. The numbers in the footer represent the number of times a particular feature is missing across the dataset. The number at the bottom right represents the total number of missing variables for each dataset.

```{r creating-long-func, echo = F}
convert_to_long <- function(datasets) {
  for (dataset_name in datasets) {
    if (exists(dataset_name, envir = .GlobalEnv)) {
      dataset <- get(dataset_name, envir = .GlobalEnv)
      
      # Extract the part of the dataset name after "d." and before "_imp"
      value_name <- gsub("^d\\.|_imp$", "", dataset_name)
      
      long_name <- paste0(dataset_name, "_long")
      
      long_data <- dataset %>% 
        pivot_longer(cols = -Country,  
                     names_to = "Year", 
                     values_to = value_name) %>%  
        mutate(Year = trimws(Year)) %>%  # Remove leading/trailing spaces
        mutate(Year = gsub("[^0-9]", "", Year)) %>%  # Remove non-numeric characters
        mutate(Year = as.integer(Year))  # Convert cleaned Year to integer

      assign(long_name, long_data, envir = .GlobalEnv)
    } else {
      message(paste("Dataset", dataset_name, "does not exist in the environment."))
    }
  }
}
```

```{r, applying-long-func, echo = F}
dataset_imp_list <- c( "d.CC_imp","d.Corruption_imp","d.ED_imp", "d.GDP_imp", "d.GDS_imp", "d.Inflation_imp","d.RR_imp", "d.Adoption_imp")
convert_to_long(dataset_imp_list)
```

```{r left-join, echo = F}
d.panel <- d.Adoption_imp_long
d.panel<-d.panel %>% 
  left_join(d.Inflation_imp_long, by= c( "Country","Year")) %>% 
  left_join(d.GDS_imp_long, by= c( "Country","Year")) %>% 
  left_join(d.GDP_imp_long, by= c( "Country","Year")) %>% 
  left_join(d.Corruption_imp_long, by= c( "Country","Year")) %>% 
  left_join(d.RR_imp_long, by= c( "Country","Year")) %>% 
  left_join(d.CC_imp_long, by= c( "Country","Year")) %>% 
  left_join(d.ED_imp_long, by= c( "Country","Year")) 

# I performed "Stichproben" for these to check the aggregation is in line with the original data.

```

### Yeo-Johnson Transformation {.unnumbered .unnumbered .unlisted}

The Yeo-Johnson transformation was applied using the package {caret}. First, a function is used to estimate the lambda parameters of transformable predictor variables. Table \@ref(tab:YJ-lambda-tbl) shows these estimates. It should be noted that the Country Name variable was not transformed because it is not numeric. The Year variable will be treated as categorical and is therefore also not transformed. The data on CC initially exhibited insufficient variability to permit the Yeo-Johnson transformation. To address this, small perturbations were introduced, drawn from a distribution with a mean equal to 0 and a standard deviation equal to 6% of the range of the original CC variable. This was the smallest level of adjustment that enabled a successful transformation.

```{r YJ, echo = F}
set.seed(42)
num_cols <- d.panel[,!names(d.panel) %in% c("Adoption","Country","Year")] # selecting the numeric columns only, and also excluding the Adoption (Y variable should not be transformed)
num_cols$CC <- num_cols$CC + rnorm(nrow(num_cols), mean = 0,sd= 0.06) # adding  perturbations

preProcess_model <- preProcess(num_cols, method = "YeoJohnson", center = FALSE, scale = FALSE)
d.panel_YJ <- predict(preProcess_model, num_cols)
d.panel_YJ$Year <-d.panel$Year
d.panel_YJ$Country <-d.panel$Country
d.panel_YJ$Adoption <- d.panel$Adoption

#d.panel_YJ$CC <-d.panel$CC

d.panel_YJ <- d.panel_YJ %>% 
  select(Country,Year,Adoption, everything())#,CC)

```

\vspace{0.25cm}

```{r YJ-lambda-tbl, echo = F}
# Convert lambda values to a dataframe and add variable names
lambda_YJ <- data.frame(
  Variable = colnames(num_cols),  # Get variable names from num_cols
  Lambda = preProcess_model$yj  # Extract lambda values
)

# Round the lambda values to 4 decimal places
lambda_YJ$Lambda <- round(lambda_YJ$Lambda, 4)

# Rename the column
colnames(lambda_YJ) <- c("Variable", "Lambda Estimate")


kable(lambda_YJ, caption = "Yeo-Johnson Transformations Lambda Estimates", format = "latex", booktabs = TRUE, escape = FALSE, row.names = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs"))
  #column_spec(2, width = "3cm")  # Adjust column width for alignment

```

\newpage

# Empirical Findings

This section discusses the empirical findings. It first looks at descriptive statistics of the data, including histograms and a correlation matrix. This is done to assess if the data fits model assumptions. As part of the descriptive statistics, a Hausman test is done to determine the choice between a fixed and random effects panel data model. Next, the results of the models are discussed, primarily in terms of the predictor variable's coefficient estimates and model quality. The fixed effect model is determined as the best. Finally, a robustness check using a different proxy for the adoption of cryptocurrency is conducted in an additional model (Model 4).

## Descriptive Statistics

This section shows the exploratory analysis of the data to prepare for inferential statistics by checking if assumptions for certain models are met. Please note that this entire description of data from here on out is performed on the imputed data. In the case of the CC data that was Yeo-Johnson transformed, the data seen from here on out reflects the values including the perturbations added to enable the transformation. Readers interested in the summary statistics of the data should visit Table \@ref(tab:summary-stats-m123) in Appendix 3.

### Distribution: Histograms

Histograms are a common way to visually assess the distribution of a list of values. In applied settings, a distribution that approaches a normal one is an underlying assumption of many models, and therefore it is crucial to assess this. Histograms plot the frequency (y-axis) at which values occur between certain ranges (x-axis). Ideally there is a single range in which the most values occur, and then the frequency of values in ranges reduces the further away the ranges move away from the most populated range, in both the positive and negative direction.

```{r hist_fun, echo = F}
plot_side_by_side_histogram <- function(datasets, var_name, labels, bins = 30) {
  # Check if the number of datasets matches the number of labels
  if (length(datasets) != length(labels)) {
    stop("Number of datasets must match number of labels.")
  }
  
  # Compute Shapiro-Wilk normality test p-values
  normality_results <- sapply(datasets, function(df) {
    p_value <- shapiro.test(df[[var_name]])$p.value
    if (p_value < 0.001) {
      return("< 0.001")  # Avoids scientific notation
    } else {
      return(sprintf("%.3f", p_value))  # Round to 3 decimals
    }
  })
  
  # Combine datasets into a long format dataframe
  combined_data <- bind_rows(
    lapply(seq_along(datasets), function(i) {
      datasets[[i]] %>%
        select(all_of(var_name)) %>%
        mutate(Transformation = paste0(labels[i], "\nShapiro-Wilk p ", normality_results[i]))
    }),
    .id = "Source"
  )
  
  # Plot the histograms side by side
  ggplot(combined_data, aes_string(x = var_name)) +
    geom_histogram(fill = "#4A9FD8", alpha = 0.6, bins = bins) +
    facet_wrap(~Transformation, scales = "free") +  # Facet by transformation (with normality p-value)
    labs(x = var_name, y = "Count") +
    #theme_minimal() +
    theme(strip.text = element_text(size = 9))
}

```

\newpage

\FloatBarrier

Figure \@ref(fig:hist-Adoption) shows the distribution of the cryptocurrency adoption data in both transformations. Please note that since the Yeo-Johnson transformation was applied only to the independent variables, both distributions are identical. Both histograms are shown for completeness only. The distribution of adoption values is right-skewed, with the majority of observations concentrated between 5 and 20. A sharp peak occurs around 10 - 12, followed by a gradual decline and a long tail extending toward higher values. The Shapiro-Wilk Test confirms a significant deviation from normality (p \< 0.001), indicating a non-normal distribution.

```{r hist-Adoption, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for Adoption of Cryptocurrency Measured by Statista (2024b)", warning=F}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "Adoption",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 30)
```

\FloatBarrier

Figure \@ref(fig:hist-inf) shows the histograms for the inflation data, the proxy for currency stability. The histogram on the left shows the untransformed inflation data, which is highly right-skewed, with a strong concentration of values near zero and extreme outliers extending beyond 100. Despite a Yeo-Johnson transformation (right panel), the distribution remains non-normal (Shapiro-Wilk p \< 0.001), though it appears more symmetric and compact, with reduced skewness and a clearer central tendency.

\FloatBarrier

```{r hist-inf, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for Inflation (% Annual Change in Consumer Prices)"}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "Inflation",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 30)
```

\FloatBarrier

Figure \@ref(fig:hist-GDS) shows the histograms for GDS, the proxy for investment. The untransformed GDS data (left panel) exhibits a quasi-normal distribution with a slight right skew and a concentration of values between 20 and 35 and several high-value outliers above 50. After applying the Yeo-Johnson transformation (right panel), the distribution becomes more symmetric and bell-shaped, though the Shapiro-Wilk test still indicates a significant deviation from normality (p \< 0.001). The transformation reduces skewness and improves the distribution's overall symmetry, although the original distribution was already sufficient for an applied setting, being quasi-normal.

\FloatBarrier

```{r hist-GDS, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for GDS (% of GDP)"}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "GDS",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 30)
```

\FloatBarrier

Figure \@ref(fig:hist-GDP) shows the histograms for GDP, the proxy for wealth. The untransformed GDP data (left panel) shows a combination of a bimodal pattern and a right skew. The two peaks are around the 10K and 50K ranges. There are also outliers above the 75K range. The distribution is not visually improved by the Yeo-Johnson transformation (right panel). The statistically significant Shapiro-Wilks test confirms the non-normality.

\FloatBarrier

```{r hist-GDP, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for GDP (Current USD, per Capita)"}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "GDP",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 30)

```

\FloatBarrier

Figure \@ref(fig:hist-Corruption) shows the histogram for the Political Corruption Index; this is the proxy for sins. The untransformed sins data (left panel) is right-skewed, with most values clustered near zero and a wide spread across the rest of the scale as it moves away from zero in the positive direction. After applying a Yeo-Johnson transformation (right panel), the distribution is not visually improved and becomes bimodal with peaks around the 0 and 0.35 ranges (transformed scale). The Shapiro-Wilk test (p \< 0.001) confirms non-normality in both cases.

\FloatBarrier

```{r hist-Corruption, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for Political Corruption Index"}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "Corruption",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 30)
```

\FloatBarrier

Figure \@ref(fig:hist-RR) shows the histograms for RR as a percentage of GDP; this is the proxy for remittances. The untransformed remittances data (left panel) is right-skewed, with a large spike near zero and a long tail extending beyond 10. The Yeo-Johnson transformation does not improve normality visually. A bimodal peak is created by the transformation. The Shapiro-Wilk test confirms non-normality (p \< 0.001) in both cases.

\FloatBarrier

```{r hist-RR, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for RR (Personal, % of GDP)"}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "RR",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 30)
```

\FloatBarrier

Figure \@ref(fig:hist-CC) shows the histograms for the bespoke CC index; this is the proxy for CC. The untransformed CC data (left panel) is right-skewed, with the majority of observations concentrated near zero and a steep drop-off in frequency as values increase. After applying the Yeo-Johnson transformation (right panel), the distribution becomes more compressed and slightly more symmetric but remains non-normal (Shapiro p \< 0.001). The transformation reduces skewness but does not fully normalize the data. Please note that there are values below 0 on the transformed scale due to the small perturbations added to the data to make it compatible with the algorithm conducting the Yeo-Johnson transformation.

\FloatBarrier

```{r hist-CC, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for Bespoke Capital Controls Index based on IMF (2024)"}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "CC",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 5)
```

\FloatBarrier

Figure \@ref(fig:hist-ED-GDP) shows the distribution for ED to GDP, the proxy for the risk of sovereign default. The untransformed ED data (left panel) is right-skewed, with a strong concentration of values near zero and a long tail extending beyond 1K. After applying the Yeo-Johnson transformation (right panel), the distribution becomes more symmetric and bell-shaped. The Shapiro-Wilk test shows a weaker deviation from normality (p = 0.030), suggesting the transformation improves normality, though non-normality remains.

\FloatBarrier

```{r hist-ED-GDP, echo = F, message = F, fig.width=6, fig.height=2.5, fig.cap="Histograms for ED (% of GDP)"}
plot_side_by_side_histogram(datasets = list(d.panel,d.panel_YJ),var_name = "ED",labels = c("No Transformation", "Yeo-Johnson Transformation"), bin = 30)
```

\FloatBarrier

### Overview Distribution

Table \@ref(tab:overview-skew-no-transformations) shows an overview of the distributions of both the untransformed and Yeo-Johnson transformed variables.

```{r overview-skew-no-transformations, echo = F, results = "asis"}
# Create the data frame
distribution_table <- data.frame(
  Variable = c("Adoption", "Inflation", "GDS", "GDP","Sins", "RR","CC", "ED"),
  No_Transformation = c(
    "right skew", 
    "right skew", 
    "quasi-normal", 
    "bi-modal and right skew", 
    "right skew", 
    "right skew", 
    "right skew",
    "right skew"
  ),
  YJ_Transformation = c(
    "not transformed",
    "improved, but non-normal",
    "improved, but non-normal",
    "not improved",
    "bimodal, not improved",
    "bimodal, not improved",
    "improved, but not-normal",
    "improved, but non-normal "
  )
)

# Print the table and ensure it holds position
colnames(distribution_table) <- c("Variable", "No Transformation", "YeoâJohnson Transformation")

# Create the kable
kable(distribution_table, 
      caption = "Overview of Distributions (With and Without YeoâJohnson Transformation)", 
      booktabs = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")

```

### Correlation Matrix

```{r corr-heatmap-create, echo = F}
d.panel_numeric <- subset(d.panel, select = -c(Country, Adoption))
corr_matrix <- cor(d.panel_numeric)
melted_corr<-melt(corr_matrix)

#ggplot(melted_corr, aes(x=Var1, y=Var2, fill=value)) +
#  geom_tile() +
#  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, 
#                       limits = c(-1, 1)) +  # Set limits to force full color range
#  theme_minimal() +
#  labs(title="Correlation Heatmap", fill="Correlation") +
#  theme(axis.text.x = element_text(angle = 45, hjust = 1))


# Create the heatmap with correlation values
corr_heatmap<-ggplot(melted_corr, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile() +  # Heatmap tiles
  geom_text(aes(label = round(value, 2)), color = "black", size = 3, family = "times") +  # Add correlation values
  scale_fill_gradient2(low = "#C75A7A", mid = "#4A9FD8", high = "#C75A7A", midpoint = 0, 
                       limits = c(-1, 1)) +  # Ensure color scale is -1 to 1
  #theme_minimal() +
  labs(fill="Pearson\nCorrrelation") +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title.x = element_text(size = 8),  # Reduce X-axis label size
    axis.title.y = element_text(size = 8)   # Reduce Y-axis label size
  )

melted_corr_wo1 <- melted_corr[melted_corr$value != 1, ]
med_corr <- round(median(abs(melted_corr_wo1$value)),2)
max_corr <- round(max(abs(melted_corr_wo1$value)),2)
```

A correlation matrix visually displays the relationship between two continuous variables. It is important to evaluate this, since an assumption behind the statistical models used in this paper is that there is no multicollinearity, which are correlations between independent variables [@statisticssolutions]. Figure \@ref(fig:corr-heatmap-show) shows a correlation matrix for independent variables. The numbers inside the cells (as well as their coloring) show the Pearson correlation coefficient between two independent variables in the datasets. The variables associated with each correlation can be identified by looking at the row and column of that cell. Please note that the coloring considers only the absolute values of the correlation since if a correlation is positive or negative is irrelevant for the purpose of assessing multicollinearity. The plot shows that most correlations are weak to moderate, with a median absolute value of correlations equal to `r med_corr` and a maximum Pearson correlation equal to `r max_corr`.[^4] This indicates that multicollinearity will not be a problem since even the largest absolute value is below the 0.8 threshold specified in @statisticssolutions. The diagonal values of 1 represent the correlation of each variable with itself, which is not relevant for assessing multicollinearity. Please note that each correlation is represented twice (one with a given variable on the x-axis and once on the y-axis).

[^4]: The summary statistics present here were calculated without the correlation of variables with themselves (diagonal 1s in Figure \@ref(fig:corr-heatmap-show))

\FloatBarrier

```{r corr-heatmap-show, echo = F, fig.cap="Correlation Heatmap of Independent Variables", fig.pos="h", fig.height=3, fig.width=6}
corr_heatmap
```

\FloatBarrier

### Hausman Test

\FloatBarrier

To determine whether a fixed or random effects model will be used, the Hausman Test can be used, provided that the observations are randomly drawn from the population [@dougherty2011; @qin2023]. The authors of the @statista_adoption dataset do not disclose the methodology for selecting the countries. Since the survey was part of the Global Consumer Survey, it can be assumed that the authors made an effort to include a diversity of countries from an economic and political standpoint, due to the title indicating a global focus [@statista2020]. While looking at the map of countries included in the survey (Figure \@ref(fig:fig-worldmap-selected)), no immediate category of country is apparent on factors like geographical region, political system or development level. The assumption of random country selection can therefore be considered fulfilled.

```{r, echo = F, warning=F, message = F}
library(plm)
m3.fixed <- plm(Adoption~Inflation+GDS+GDP+Corruption+RR+CC+ED, data = d.panel, index=c("Country","Year"), model = "within")
m3.random <- plm(Adoption~Inflation+GDS+GDP+Corruption+RR+CC+ED, data = d.panel, index=c("Country","Year"), model = "random")

```

```{r ht-tbl, echo = F, warning = F, message = F }
ht <- phtest(m3.fixed,m3.random)

ht_df <- data.frame(
  `Chi-Squared` = formatC(as.numeric(ht$statistic), format = "f", digits = 3),
  `P-Value` = formatC(ht$p.value, format = "e", digits = 3)  # scientific notation with 3 decimal places
)

colnames(ht_df) <- c("Chi-Squared","P-Value")

kable(ht_df, format = "latex", booktabs = TRUE, caption = "Results of Hausman Test Fixed vs. Random Effects") %>%
  kable_styling(latex_options = c("hold_position"))

```

Table \@ref(tab:ht-tbl) shows the result of the Hausman test, indicating that the $H_0$ should be rejected at the p-value of `r ht$p.value` and that a fixed effect model is preferred over a random effects model [@dougherty2011; @qin2023].

The paper will now present the statistical results of running these 3 models, as well as a robustness check using a different dependent variable. To determine model quality between Model 1 and 2, both linear regressions, the adjusted $R^2$ is used. To determine the better model between the best linear regression and the fixed effect model, an F test for individual and / or time effects is used [@qin2023].

\FloatBarrier

## Results

```{r, echo = F}
res2var <- function(df) {
  for (i in 1:nrow(df)) {
    coefficient <- gsub("[()]", "", df$coefficient[i])  # Remove special characters like parentheses
    coefficient <- gsub(" ", "_", coefficient)  # Replace spaces with underscores
    
    assign(paste0("s.1.", coefficient, ".estimate"), df$estimate[i], envir = .GlobalEnv)
    assign(paste0("s.1.", coefficient, ".std.error"), df$std.error[i], envir = .GlobalEnv)
    assign(paste0("s.1.", coefficient, "t.statistic"), df$t.statistic[i], envir = .GlobalEnv)
    assign(paste0("s.1.", coefficient, ".p.value"), df$p.value[i], envir = .GlobalEnv)
  }}

#Function to clean factor terms as.factor(Year) ->  Year XXXX (factor)
clean_factor_terms_in_table <- function(df, term_col = "coefficient") {
  df[[term_col]] <- gsub("as\\.factor\\(Year\\)(\\d{4})", "Year \\1", df[[term_col]])
  return(df)
}
```

This section discussed the statistical results of the models. The overviews are presented as tables and figures. For a detailed description of what these tables and figures represent (without interpretations specifically relating to the results), please visit \@ref(interpretation-guide-tables-and-figures-for-results-section). Readers familiar with statistical methods should be able to understand the results without consulting that section. The next four subsections present the most important results relevant to the research question, focusing on statistically significant coefficients and indications of model quality.

### Model 1: Linear Regression No Transformation

This subsection presents the results of Model 1. Table \@ref(tab:model1-presentation-coefficients) shows the coefficients of the model. It indicates that the proxy for currency stability, investment and corruption are positively related to the adoption of cryptocurrency, as they have a statistically significant positive estimate at the 10% level. The proxy for remittances is negatively related to adoption and also statistically significant at the 10% level. The estimates for the other proxies: wealth, CC and sovereign default risk are statistically insignificant at the 10% level.

When considering the scale of the independent variables, the sizes of the statistically significant estimates are low, considering the usual yearly changes a country might see in these economic markers. Inflation's estimate is 0.13; this is low considering most countries' inflation rates are unlikely to change by more than two to three percentage points per year. Similarly, the GDS or RR as a percentage of GDP, with their coefficients of 0.12 and -0.41, respectively, are unlikely to see large movements in cryptocurrency adoption associated with normal changes in the underlying economic conditions. The coefficient for sins is 15.49, however the underlying dependent variable is on a scale from 0 - 1. This means for a 15.49 percentage point increase in adoption (in the model, no causation implied), a country would have to go from the lowest possible sins value to the highest possible sins value. Under consideration of the range of the underlying independent variable, this effect size is therefore also small. The statistically significant estimates for the linear offsets of the years all imply that, relative to the base year, adoption increases by the coefficient estimates' value.

\FloatBarrier

```{r, echo = F}
m.1 <- lm(Adoption~as.factor(Year)+Inflation+GDS+GDP+Corruption+RR+CC+ED, data = d.panel)
```

```{r model1-presentation-coefficients, echo = F, warning=F}
library(knitr) #gotta see if runs without loading here
library(kableExtra)
library(broom)
library(dplyr)

# Format the model summary
s.1 <- tidy(m.1) %>%
  mutate(
    term = gsub("_", "\\\\_", term),  # Escape underscores for LaTeX
    estimate = sprintf("%.4f", estimate),  # 2 decimal places
    std.error = sprintf("%.4f", std.error),  # 2 decimal places
    statistic = sprintf("%.4f", statistic),  # 2 decimal places
    p.value = sprintf("%.4f", p.value),  # 4 decimal places
    signif = case_when(  # Significance stars
      as.numeric(p.value) < 0.001 ~ "***",
      as.numeric(p.value) < 0.01 ~ "**",
      as.numeric(p.value) < 0.05 ~ "*",
      as.numeric(p.value) < 0.1 ~ ".",
      TRUE ~ ""
    )
  ) %>% 
  rename(coefficient = term) %>% 
  rename(t.statistic = statistic)

#Clean Factor Term
s.1 <- clean_factor_terms_in_table(s.1)

colnames(s.1) <- c("Term","Coefficient Estimate","Standard-Error","T-Statistic","P-Value","Significance")

# Create LaTeX table
kable(s.1, caption = "Model 1 Coefficients", format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs")) %>%
  column_spec(2, width = "3cm")  # Adjust column width for alignment


res2var(s.1)

```

Table \@ref(tab:model1-presentation-summary) shows the model's summary statistics. The model has an adjusted $R^2$ of 0.48 - the highest among the two linear regression models tested. Figure \@ref(fig:model1predres) indicates heteroscedasticity due to the divergence of residuals as the predicted values increase and therefore issues in the model quality. The distribution of the residuals, as seen in Figure \@ref(fig:model1residualhistograms) is fairly normal, with slightly more residuals at the positive end.

```{r model1-presentation-summary, echo = F}
summary_stats <- summary(m.1)

# Extract residuals
residuals_summary <- summary(m.1$residuals)

# Create a dataframe for model fit statistics
model_summary <- data.frame(
  Metric = c("Residual Standard Error", 
             "Multiple R-squared", 
             "Adjusted R-squared", 
             "F-statistic", 
             "Degrees of Freedom (Model)", 
             "Degrees of Freedom (Residuals)",
             "P-Value",
             "Residual Min",
             "Residual Q1",
             "Residual Median",
             "Residual Q3",
             "Residual Max"),
  Value = c(sprintf("%.2f", summary_stats$sigma),
            sprintf("%.4f", summary_stats$r.squared),
            sprintf("%.4f", summary_stats$adj.r.squared),
            sprintf("%.2f", summary_stats$fstatistic[1]),
            summary_stats$df[1],
            summary_stats$df[2],
            sprintf("%.4f", pf(summary_stats$fstatistic[1], 
                               summary_stats$fstatistic[2], 
                               summary_stats$fstatistic[3], 
                               lower.tail = FALSE)),
            sprintf("%.2f", residuals_summary[1]),  # Min
            sprintf("%.2f", residuals_summary[2]),  # Q1
            sprintf("%.2f", residuals_summary[3]),  # Median
            sprintf("%.2f", residuals_summary[5]),  # Q3
            sprintf("%.2f", residuals_summary[6]))  # Max
)

# Create a formatted LaTeX table using kable
kable(model_summary, caption = "Model 1 Fit Summary", format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs"))
```

```{r model1predres, echo = F, fig.cap="Model 1: Scatterplot Showing Predicted vs. Residuals", results = "asis", fig.width=5, fig.height=4}

# Create a data frame with predictions and residuals
df <- data.frame(
  Predicted = predict(m.1),
  Residuals = residuals(m.1)
)

# Generate the ggplot
ggplot(df, aes(x = Predicted, y = Residuals)) +
  geom_point() +  # Scatter plot
  geom_hline(yintercept = 0, linetype = "dashed", color = "#4A9FD8", size = 0.5) +  # Horizontal line at 0
  ylim(-30,30)+
  labs(x = "Predicted Values", y = "Residuals")# +
  #theme_minimal()
```

```{r model1residualhistograms, fig.cap= "Model 1: Histogram of Residuals", fig.width=5, fig.height=4, echo =F, fig.pos="H"}
m.1_residuals <- data.frame(residuals = m.1$residuals)

ggplot(m.1_residuals, aes(x = residuals)) +
  geom_histogram(bins = 50, fill = "#4A9FD8", alpha = 0.6) +
  labs(x = "Residuals", y = "Count") +
 # theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )


```

\FloatBarrier

### Model 2: Linear Regression Transformations

This subsection presents the results of Model 2. The linear regression of the Yeo-Johnson transformed quantitative input variables is seen in this section. Table \@ref(tab:model2-presentation-coefficients) shows the coefficient estimates of the model. It indicates that the proxy for currency stability, savings, sins and sovereign default risk have a statistically significant positive estimate at the 10% level. The proxies for wealth and remittances are negatively related to adoption and also statistically significant at the 10% level. The estimate for the CC proxy is statistically insignificant.

\FloatBarrier

```{r, echo = F}
m.2 <- lm(Adoption~as.factor(Year)+Inflation+GDS+GDP+Corruption+RR+CC+ED, data = d.panel_YJ)
```

```{r model2-presentation-coefficients, echo = F, warning=F}

# Format the model summary
s.2 <- tidy(m.2) %>%
  mutate(
    term = gsub("_", "\\\\_", term),  # Escape underscores for LaTeX
    estimate = sprintf("%.4f", estimate),  # 2 decimal places
    std.error = sprintf("%.4f", std.error),  # 2 decimal places
    statistic = sprintf("%.4f", statistic),  # 2 decimal places
    p.value = sprintf("%.4f", p.value),  # 4 decimal places
    signif = case_when(  # Significance stars
      as.numeric(p.value) < 0.001 ~ "***",
      as.numeric(p.value) < 0.01 ~ "**",
      as.numeric(p.value) < 0.05 ~ "*",
      as.numeric(p.value) < 0.1 ~ ".",
      TRUE ~ ""
    )
  ) %>% 
  rename(coefficient = term) %>% 
  rename(t.statistic = statistic)

#Clean Factor Term
s.2 <- clean_factor_terms_in_table(s.2)

colnames(s.2) <- c("Term","Coefficient Estimate","Standard-Error","T-Statistic","P-Value","Significance")

# Create LaTeX table
kable(s.2, caption = "Model 2 Coefficients", format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs")) %>%
  column_spec(2, width = "3cm")  # Adjust column width for alignment


res2var(s.2)
```

Table \@ref(tab:model2-presentation-summary) shows the model's summary statistics. The model has an adjusted $R^2$ of 0.46, slightly lower than Model 1. Figure \@ref(fig:model2predres) indicates heteroscedasticity due to the diverging residuals as the predicted value increases and therefore issues in the model quality. The distribution of the residuals, as seen in Figure \@ref(fig:model2residualhistograms) is fairly normal, with slightly more residuals at the positive end. Overall, the model quality markers are very similar to Model 1, although Model 1 outperforms Model 2 due to the slightly higher adjusted $R^2$ value.

```{r model2-presentation-summary, echo = F}
summary_stats <- summary(m.2)

# Extract residuals
residuals_summary <- summary(m.2$residuals)

# Create a dataframe for model fit statistics
model_summary <- data.frame(
  Metric = c("Residual Standard Error", 
             "Multiple R-squared", 
             "Adjusted R-squared", 
             "F-statistic", 
             "Degrees of Freedom (Model)", 
             "Degrees of Freedom (Residuals)",
             "P-Value",
             "Residual Min",
             "Residual Q1",
             "Residual Median",
             "Residual Q3",
             "Residual Max"),
  Value = c(sprintf("%.2f", summary_stats$sigma),
            sprintf("%.4f", summary_stats$r.squared),
            sprintf("%.4f", summary_stats$adj.r.squared),
            sprintf("%.2f", summary_stats$fstatistic[1]),
            summary_stats$df[1],
            summary_stats$df[2],
            sprintf("%.4f", pf(summary_stats$fstatistic[1], 
                               summary_stats$fstatistic[2], 
                               summary_stats$fstatistic[3], 
                               lower.tail = FALSE)),
            sprintf("%.2f", residuals_summary[1]),  # Min
            sprintf("%.2f", residuals_summary[2]),  # Q1
            sprintf("%.2f", residuals_summary[3]),  # Median
            sprintf("%.2f", residuals_summary[5]),  # Q3
            sprintf("%.2f", residuals_summary[6]))  # Max
)

# Create a formatted LaTeX table using kable
kable(model_summary, caption = "Model 2 Fit Summary", format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs"))
```

```{r model2predres, echo = F, fig.cap="Model 2: Scatterplot Showing Predicted vs. Residuals", results = "asis", fig.width=5, fig.height=4, fig.pos="H"}

# Create a data frame with predictions and residuals
df <- data.frame(
  Predicted = predict(m.2),
  Residuals = residuals(m.2)
)

# Generate the ggplot
ggplot(df, aes(x = Predicted, y = Residuals)) +
  geom_point() +  # Scatter plot
  geom_hline(yintercept = 0, linetype = "dashed", color = "#4A9FD8", size = 0.5) +  # Horizontal line at 0
  ylim(-15,25)+
  labs(x = "Predicted Values", y = "Residuals")# +
  #theme_minimal()
```

```{r model2residualhistograms, fig.cap= "Model 2: Histogram of Residuals", fig.width=5, fig.height=4, echo =F, fig.pos="H"}
m.2_residuals <- data.frame(residuals = m.2$residuals)

ggplot(m.2_residuals, aes(x = residuals)) +
  geom_histogram(bins = 50, fill = "#4A9FD8", alpha = 0.6) +
  labs(x = "Residuals", y = "Count") +
  #theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )

```

\FloatBarrier

### Model 3: Fixed Effects

The fixed effects (Model 3) are presented in this subsection. This model controls for country specific time invariant characteristics by giving each country a linear offset [@dougherty2011]. This linear offset for each country present in the data can be seen in Table \@ref(tab:coefficients-alpha).

Table \@ref(tab:model3-presentation-coefficients) shows the coefficients of the model. It indicates that the proxies for currency stability and wealth have a statistically significant positive estimate at the 10% level. No other proxies were statistically significant. Although statistically significant, the magnitudes of those estimates are small for both proxies, considering the scale of the predictor variables. Inflation usually fluctuates only by a couple percentage points between years for most countries. Therefore, an estimate of 0.3 for the currency stability proxy means that inflation would have to increase by more than 3 percentage points to increase the percentage points of respondents using cryptocurrency in the @statista_adoption by 1. Similarly, the GDP per capita would have to increase by over USD 2000 to be associated with a single percentage point increase in cryptocurrency adoption in the @statista_adoption survey.

\FloatBarrier

```{r model3-presentation-coefficients, echo = F, warning=F}

# Format the model summary
s.3 <- tidy(m3.fixed) %>%
  mutate(
    term = gsub("_", "\\\\_", term),  # Escape underscores for LaTeX
    estimate = sprintf("%.4f", estimate),  # 2 decimal places
    std.error = sprintf("%.4f", std.error),  # 2 decimal places
    statistic = sprintf("%.4f", statistic),  # 2 decimal places
    p.value = sprintf("%.4f", p.value),  # 4 decimal places
    signif = case_when(  # Significance stars
      as.numeric(p.value) < 0.001 ~ "***",
      as.numeric(p.value) < 0.01 ~ "**",
      as.numeric(p.value) < 0.05 ~ "*",
      as.numeric(p.value) < 0.1 ~ ".",
      TRUE ~ ""
    )
  ) %>%
  rename(coefficient = term) %>%
  rename(t.statistic = statistic)

#Clean Factor Term - not needed (no factors for years)

colnames(s.3) <- c("Term","Coefficient Estimate","Standard-Error","T-Statistic","P-Value","Significance")

# Create LaTeX table
kable(s.3, caption = "Model 3 Coefficients", format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs")) %>%
  column_spec(2, width = "3cm")  # Adjust column width for alignment

```

```{r model3-presentation-summary, echo = F}
summary_stats <- summary(m3.fixed)

# Extract residuals
residuals_summary <- summary(m3.fixed$residuals)

# Create a dataframe for model fit statistics
model_summary <- data.frame(
  Metric = c(#"Residual Standard Error", 
             "Multiple R-squared", 
             "Adjusted R-squared", 
             "F-statistic", 
             "Degrees of Freedom (Model)", 
             "Degrees of Freedom (Residuals)",
             "P-Value",
             "Residual Sum of Squares",
             "Between Entities",
             "Between Time"),

  Value = c(#sprintf("%.2f", summary_stats$sigma), #1
            sprintf("%.4f", summary_stats$r.squared[1]), #2
            sprintf("%.4f", summary_stats$r.squared[2]), #3
            sprintf("%.2f", summary_stats$fstatistic$statistic), #4
            summary_stats$df[1], #5
            summary_stats$df[2], #6
            sprintf("%.4f", summary_stats$fstatistic$p.value), #7
            sprintf("%.2f", residuals_summary[1]),  # Sum of Sq #8
            sprintf("%.2f", residuals_summary[2]),  # In between id #9
            sprintf("%.2f", residuals_summary[3])))

# Create a formatted LaTeX table using kable
kable(model_summary, caption = "Model 3 Fit Summary", format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs"))
```

```{r model3predres, echo = F, fig.cap="Model 3: Scatterplot Showing Predicted vs. Residuals", results = "asis", fig.width=5, fig.height=4, fig.pos="H"}

# Create a data frame with predictions and residuals
df <- data.frame(
  Predicted = as.numeric(predict(m3.fixed)),
  Residuals = as.numeric(residuals(m3.fixed))
)

# Generate the ggplot
ggplot(df, aes(x = Predicted, y = Residuals)) +
  geom_point() +  # Scatter plot
  geom_hline(yintercept = 0, linetype = "dashed", color = "#4A9FD8", size = 0.5) +  # Horizontal line at 0
  ylim(-20,20)+
  labs(x = "Predicted Values", y = "Residuals") #+
  #theme_minimal()
```

```{r model3residualhistograms, fig.cap= "Model 3: Histogram of Residuals", fig.width=5, fig.height=4, echo =F, fig.pos="H"}
m.3_residuals <- data.frame(residuals = m3.fixed$residuals)

ggplot(m.3_residuals, aes(x = residuals)) +
  geom_histogram(bins = 50, fill = "#4A9FD8", alpha = 0.6) +
  labs(x = "Residuals", y = "Count") +
  #theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )

```

```{r coefficients-alpha, echo = F}
m3_alpha <- base::as.data.frame(fixef(m3.fixed))
colnames(m3_alpha) = c("Country Alpha")
m3_alpha$Country <- rownames(m3_alpha)

# Step 2: Reorder columns (optional, just for neatness)
m3_alpha <- m3_alpha[, c("Country", "Country Alpha")]

# Step 3: Format for display: "ARG: -3.03"
m3_alpha$Label <- paste0(m3_alpha$Country, ": ", round(m3_alpha$`Country Alpha`, 2))

# Step 4: Set number of columns you want per row (e.g., 8)
cols_per_row <- 5

# Step 5: Reshape into a matrix (fewer rows, more columns)
alpha_matrix <- matrix(m3_alpha$Label, ncol = cols_per_row, byrow = TRUE)

# Step 6: Convert to data frame and show nicely
alpha_wide <- as.data.frame(alpha_matrix)

#kable(m3_alpha, caption = "Model 3 Fit Summary", format = "latex", booktabs = TRUE, escape = FALSE) %>%
 # kable_styling(latex_options = c("hold_position", "booktabs"))
colnames(alpha_wide) <- NULL
kable(alpha_wide, caption = "Model 3: Country Fixed Effects (Alpha Coefficients)", align = "l", row.names = F, booktabs = TRUE) %>% 
  kable_styling(latex_options = c("hold_position"))
```

```{r, include = F}
m.1.plm <- plm(Adoption ~ as.factor(Year) + Inflation + GDS + GDP + Corruption + RR + CC + ED,
      data = d.panel,
      index = c("Country", "Year"),
      model = "pooling")

p_val_pFtest<- pFtest(m3.fixed,m.1.plm)$p.value

```

Table \@ref(tab:model3-presentation-summary) shows the model's summary statistics. The fixed effect model cannot be compared directly to linear regressions (Model 1 and 2) using adjusted $R^2$. Therefore, an F test for individual and/or time effects is used [@qin2023]. The test is statistically significant, with a p-value of `r p_val_pFtest`. This means that the fixed effect model is preferred to Model 1 (and by extension, Model 2, since Model 1 has a larger $R^2$ than model 2).

Figure \@ref(fig:model3predres) indicates heteroscedasticity due to diverging residuals at the top end of the range and therefore issues with the model assumptions. The distribution of the residuals, as seen in Figure \@ref(fig:model3residualhistograms) indicates worse heteroscedasticity when compared to Model 1 and Model 2 due to the bimodal distribution. However, since the peaks in the distribution are close together and still centered around 0, this is not a large issue.

\FloatBarrier

### Model 4: Robustness Check Using Chainalysis Data

\FloatBarrier

This subsection performs the same statistical tests as Model 3, which was identified as the best due to the statistically significant F test for individual and/or time effects. The key difference in Model 4 is the use of a different dependent variable - the ranking of countries on the annually published Chainalysis Geography of Cryptocurrency Report [@chainalysis2024].

#### Data Source

Chainalysis is a blockchain data and market research company. They have published their Global Cryptocurrency Adoption Report every year since 2020. It contains a ranking of country's cryptocurrency adoption. Their methodology is to estimate cryptocurrency adoption by evaluating relevant web traffic for services enabling cryptocurrency transactions. The results are normalized by population and purchasing power [@chainalysis2024].

#### **Technical Data Acquisition**

The data is sourced directly from the reports, as it was not possible to gain access to any web service that could automate the acquisition process. The data was loaded into an Excel sheet by pasting screenshots into OpenAI's GPT-4o and having the generative model return an Excel file [@chainalysis2020; @chainalysis2021; @chainalysis2022; @chainalysis2023; @chainalysis2024]. Manual spot checks were performed. While the data that was present was always correct on the spot checks, the AI model struggled to match countries that were not always consistently named between reports or not consistently available. These errors were sought out and corrected where neccesary. However, given the tedious and repetitive nature of this manual task, it is possible that not all errors of this type were found and corrected.

#### **Data Cleaning and Imputation**

There were 162 distinct countries present in at least one year for the Chainalysis data. The data imputation was done more crudely than for the data used in Model 1,2 and 3. Data was imputed using country means, even if only one data point was available for a country / indicator. If for any indicator and any country for a given year, no data point was available, this country was removed from the dataset. This left 128 countries in the final cleaned dataset for the robustness check. Readers interested in the summary statistics for the underlying data used in the robustness check should visit Table \@ref(tab:summary-stats-4) in Appendix 2. The summary statistics will also be different for the independent variables because the countries evaluated were not the same. Several additional details should be noted:

-   The same manual data extensions were performed as for the previous data analysis (see section \@ref(manually-adding-missing-data)).

-   The data for 2020 presents some countries without a ranking, labeling their adoption as "among lowest" [@chainalysis2020, p. 129]. These countries were retained by giving them the rank of 143, since 142 was the lowest ranked country in that year.

-   The ranking was preferred over the index score since the company stopped giving index in their reports in 2022, providing only a ranking [@chainalysis2022; @chainalysis2023; @chainalysis2024]. While an index could give a more granular overview of the differences in cryptocurrency adoption between countries, the trade off of excluding the years 2022 and 2023 would be too severe on data quantity to justify this choice.

#### **Model**

The final model is akin to \@ref(model-3-fixed-effects-1) with the difference that the proxy for wealth, GDP per capita, was excluded as this was already considered by Chainalysis in their creation of the index by the decision to normalize the data based on the purchasing power of the country [@chainalysis2024]. The interpretation guide \@ref(interpretation-guide-tables-and-figures-for-results-section) can still be consulted, keeping in mind that the response variable is now no longer the same. Crucially, **the scale of the response variable is conceptually inverted** when compared to the @statista_adoption data. A higher value in the Chainalysis data means a lower rank of cryptocurrency adoption and therefore a lower measure of cryptocurrency adoption. The mathematical model can be seen below. Notice the lack of inclusion of the GDP variable and associated coefficient. The rest is analogous to what was described in \@ref(model-3-fixed-effects-1).

```{=tex}
\begin{align*}  
Adoption_{it} = \beta_1 \cdot \text{Currency Stability}_{it} + \beta_2 \cdot Investment_{it} + \beta_3 \cdot Sins_{it} \\ + \beta_4 \cdot Remittances_{it} + \beta_5 \cdot Capital Controls_{it} + \beta_6 \cdot  \text{Sovereign Default Risk}_{it} + \alpha_i + \varepsilon_{it}
\end{align*}
```
#### **Results Model 4**

The results of Model 4 are now shown and discussed. Please note that the $\alpha$ values, country fixed effects are not shown. Table \@ref(tab:model4-presentation-coefficients) shows the coefficients of the robustness check model, a fixed effect model using the Chainalysis data as an adoption of cryptocurrency proxy. It indicates that the proxies for currency stability and sovereign default risk are statistically significant at the 10% level. The coefficient associated with currency stability is 0.13; this is the size of the within country response of the dependent variable to a one unit change in inflation rate, according to the model. Since a higher value on the response variable (rank of adoption) means a lower adoption of cryptocurrency, conceptually the variable is negatively related - higher inflation means a lower adoption of cryptocurrency. The coefficient associated with the proxy for sovereign default rate is -0.20. This is the size of the within country response in the rank of cryptocurrency adoption in response to a 1 percentage point change in the sovereign default risk variable. Conceptually this means the concept of sovereign default risk and cryptocurrency adoption are positively related. A higher risk of sovereign default as measured by the ED as a percentage of GDP will be associated with a larger cryptocurrency adoption. For both the currency stability and sovereign default proxies the effect size is small. Several percentage points increases in inflation and ED as a percentage of GDP would be required to see just a single rank change in cryptocurrency adoption according to this model.

The proxies for wealth, sins, remittances and capital controls were statistically insignificant at the 10% level - there is insufficient evidence to reject the null hypothesis that the coefficients for these values are different from 0.

```{r importing-sanity-check-data, include = F}
path <- "Data/d.Chainalysis/d.Chainalysis.xlsx"
d.Chainalysis <- read.xlsx(path)

replacement2020 <- 143 # choose what goes to among lowest fo

d.Chainalysis <- d.Chainalysis %>%
  select(-Country) %>%
  rename(Country = Country.Code) %>%
  mutate(X2020 = if_else(as.character(X2020) == "Among lowest",
                         as.character(replacement2020),
                         as.character(X2020))) %>% 
  mutate(X2020 = as.numeric(X2020))

impute_row_mean <- function(df) {
  numeric_cols <- sapply(df, is.numeric)
  total_imputes <- 0
  possible_imputes <- sum(is.na(df[ , numeric_cols]))

  for (i in 1:nrow(df)) {
    row <- df[i, ]
    numeric_row <- row[ , numeric_cols]
    
    na_cols <- names(numeric_row)[is.na(numeric_row)]
    
    if (length(na_cols) > 0 && !all(is.na(numeric_row))) {
      row_mean <- mean(unlist(numeric_row), na.rm = TRUE)
      df[i, na_cols] <- row_mean
      cat("Imputed", length(na_cols), "missing value(s) for Country:", row$Country, 
          "| Columns:", paste(na_cols, collapse = ", "), "\n")
      total_imputes <- total_imputes + length(na_cols)
    }
  }

  total_possible <- nrow(df) * sum(numeric_cols)
  
  cat("Total missing values imputed:", total_imputes, "\n")
  cat("Total possible imputes (if all numeric values were missing):", total_possible, "\n")
  
  return(df)
}

d.Chainalysis <- impute_row_mean(d.Chainalysis)

d_Chainalysis_long <- d.Chainalysis %>%
  pivot_longer(
    cols = starts_with("X"),         # All year columns like X2020, X2021,
    names_to = "Year",               # New column name for years
    names_prefix = "X",              # Remove the 'X' prefix
    values_to = "Chainalysis_Adoption" # New column for the actual values
  )

v.sanity_country_codes <- unique(d.Chainalysis$Country)
```

```{r reloading-data-IV-wide, include = F}
#Currency Stability
path <- "Data/d.Inflation/API_FP.CPI.TOTL.ZG_DS2_en_csv_v2_3401965.csv"
d.Inflation_s <- read.csv(path, header = T, skip = 4) 

# Cleaning Data d.Inflation
d.Inflation_s <- d.Inflation_s %>%
  filter(Country.Code %in% v.sanity_country_codes) %>%
  select(Country.Code, X2019:X2023) 

# Rename first column to "Country"
colnames(d.Inflation_s)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.Inflation_s) <- gsub("^X", "", colnames(d.Inflation_s))

#Investment
path <- "Data/d.Savings/API_NY.GDS.TOTL.ZS_DS2_en_csv_v2_1988.csv"
d.GDS_s <- read.csv(path, header = T, skip = 4) 

# Cleaning Data d.GDS
d.GDS_s <- d.GDS_s %>%
  filter(Country.Code %in% v.sanity_country_codes) %>%
  select(Country.Code, X2019:X2023)  # Removed Indicator.Code

# Rename first column to "Country"
colnames(d.GDS_s)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.GDS_s) <- gsub("^X", "", colnames(d.GDS_s))

# Wealth

path <- "Data/d.GDP/API_NY.GDP.PCAP.CD_DS2_en_csv_v2_3401556.csv"
d.GDP_s <- read.csv(path, header = T, skip = 4) 

# Cleaning Data d.GDP
d.GDP_s <- d.GDP_s %>%
  filter(Country.Code %in% v.sanity_country_codes) %>%
  select(Country.Code, X2019:X2023)  # Removed Indicator.Code

# Rename first column to "Country"
colnames(d.GDP_s)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.GDP_s) <- gsub("^X", "", colnames(d.GDP_s))



#Remittances
path <- "Data/d.RemittancesGDP/API_BX.TRF.PWKR.DT.GD.ZS_DS2_en_csv_v2_3426.csv"
d.RR_s <- read.csv(path, header = T, skip = 4) 

# Cleaning Data d.RR
d.RR_s <- d.RR_s %>%
  filter(Country.Code %in% v.sanity_country_codes) %>%
  select(Country.Code, X2019:X2023)  # Removed Indicator.Code

# Rename first column to "Country"
colnames(d.RR_s)[1] <- "Country"

# Remove 'X' prefix from year columns
colnames(d.RR_s) <- gsub("^X", "", colnames(d.RR_s))


```

```{r, include = F}
devtools::install_github("vdeminstitute/vdemdata")
library(vdemdata)
d.Corruption_s <- vdem[, c("country_name", "year", "v2x_corr")] # relevant variables
d.Corruption_s <- d.Corruption_s %>%
  filter(year %in% c(2019: 2024)) # relevant years
d.Corruption_s$Country <- countrycode(d.Corruption_s$country_name, "country.name", "iso3c")

d.Corruption_s <- d.Corruption_s %>% 
  filter(!is.na(Country)) %>%
  select(-country_name) %>% 
  rename(
    Corruption = v2x_corr,
    Year = year
  ) %>%
  select(Country, Year, Corruption) %>% 
  filter(Country %in% v.sanity_country_codes)

d.Corruption_s <- d.Corruption_s %>%
  pivot_wider(names_from = Year, values_from = Corruption) %>% 
  select(-'2024')
  
  
```

```{r, include = F}
path <- "Data/d.CC/IMF (2024).xlsx"
d.CC_s <- read.xlsx(path)

colnames(d.CC_s)[(ncol(d.CC_s)-4):ncol(d.CC_s)] <- c("A", "B", "C", "D", "E")

# Compute Index dynamically based on available (non-NA) values
d.CC_s$IndexCC <- rowSums(d.CC_s[, c("A", "B", "C", "D", "E")] == d.CC_s[11,4], na.rm = TRUE) / 
                 rowSums(!is.na(d.CC_s[, c("A", "B", "C", "D", "E")]), na.rm = TRUE)

d.CC_s$IndexCC[is.nan(d.CC_s$IndexCC)] <- NA # #converting 0 data point to NA

d.CC_s$Country <- countrycode(d.CC_s$Country, "country.name", "iso3c")

d.CC_s <- na.omit(d.CC_s, cols = "Country")
# Above Warnings Countries are not found in the Adoption set, can be safely removed

d.CC_s <- d.CC_s %>% select(Country, Year, IndexCC) # rearrannging and removing rows


d.CC_s <- d.CC_s %>%
  pivot_wider(names_from = Year, values_from = IndexCC) %>%  # make wide format
  mutate(`2023` = NA) %>%
  filter(Country %in% v.sanity_country_codes)



```

```{r, include = F}
# Working with External Debt (% of GDP) -> 
# Source: https://www.focus-economics.com/economic-indicator/external-debt/ 

path <- "Data/d.External_Debt_GDP/d.External_Debt_GDP_s.xlsx"

# Loading Raw Data
d.ED_s <- read.xlsx(path)

# Adding World Bank Codes

d.ED_s$Country <- countrycode(d.ED_s$Country, "country.name", "iso3c")
# warning about unconnected code can be safely ignored since the dataset d.Adoption does not contain the two unmatched countries (Ivory Coast, Kosovo) anyways.

#for some reason, column 2,3 did not save as numeric
d.ED_s$'2019' <- as.numeric(d.ED_s$'2019')
d.ED_s$'2020' <- as.numeric(d.ED_s$'2020')




```

```{r adding missing data, include = F}
NGA_GDS <- c("2019" = 19.83, "2020" = 27.38, "2021" = 32.73, "2022" = NA, "2023" = NA)#, "2024" = NA)

NGA_row <- which(d.GDS_s$Country == "NGA")
d.GDS_s[NGA_row, 2:ncol(d.GDS_s)] <- NGA_GDS  # Assuming the first column is "Country"

Arg_Inf <- c("2019" = 53.55, "2020" = 42.02, "2021" = 48.41, 
             "2022" = 72.43, "2023" = 133.49)#, "2024" = NA)

arg_row <- which(d.Inflation_s$Country == "ARG")
d.Inflation_s[arg_row, 2:ncol(d.Inflation_s)] <- Arg_Inf  # Assuming the first column is "Country"



new_countries_External_Debt <- tibble(
  Country = c("BEL", "CAN", "FRA", "IRL", "ESP"),
  `2019` = c(257.579, 134.234, 235.061, 742.138, 169.725),
  `2020` = c(268.416, 149.077, 265.191, 702.699, 200.181),
  `2021` = c(260.193, 143.214, 258.592, 677.751, 193.562),
  `2022` = c(237.91, 134.904, 244.258, 577.158, 172.805),
  `2023` = c(237.68, 143.661, 245.047, 563.897, 165.481)#,
#  #`2024` = c(NA, NA, NA, NA, NA)
)

# Add only missing countries
existing_countries <- d.ED_s$Country
missing_countries <- new_countries_External_Debt %>% filter(!Country %in% existing_countries)

# Append missing countries to d.GDS
d.ED_s <- bind_rows(d.ED_s, missing_countries)
```

```{r 163, include = F }
v.Chainalysis_country <- d.Chainalysis$Country

# Inflation (1)
d.Inflation_s_162 <- tibble(Country = v.Chainalysis_country) %>% 
  left_join(d.Inflation_s, by = "Country")

# Investment (2)
d.GDS_s_162 <- tibble(Country = v.Chainalysis_country) %>% 
  left_join(d.GDS_s, by = "Country")
# Wealth (3)
d.GDP_s_162 <- tibble(Country = v.Chainalysis_country) %>% 
  left_join(d.GDP_s, by = "Country")

#Corruption (4)
d.Corruption_s_162 <- tibble(Country = v.Chainalysis_country) %>% 
  left_join(d.Corruption_s, by = "Country")

#Remittances (5)
d.RR_s_162 <- tibble(Country = v.Chainalysis_country) %>% 
  left_join(d.RR_s, by = "Country")

#Capital Controls (6)
d.CC_s_162 <- tibble(Country = v.Chainalysis_country) %>% 
  left_join(d.CC_s, by = "Country")

# External Deficit (7)
d.ED_s_162<- tibble(Country = v.Chainalysis_country) %>% 
  left_join(d.ED_s, by = "Country")

```

```{r, include = F}
dfs <- list(
  d.Inflation_s_162 = d.Inflation_s_162,
  d.GDS_s_162 = d.GDS_s_162,
  d.GDP_s_162 = d.GDP_s_162,
  d.Corruption_s_162 = d.Corruption_s_162,
  d.RR_s_162 = d.RR_s_162,
  d.CC_s_162 = d.CC_s_162,
  d.ED_s_162= d.ED_s_162
)

# Function to get countries fully missing in a dataset
get_fully_missing_countries <- function(df, dataset_name) {
  df %>%
    filter(if_all(2:6, is.na)) %>%
    pull(Country)
}

# Get a named list of missing countries from each dataset
missing_lists <- Map(get_fully_missing_countries, dfs, names(dfs))

# Combine into one vector
all_missing <- unlist(missing_lists)

# Count how many times each country is missing fully
country_missing_counts <- as.data.frame(table(all_missing))
colnames(country_missing_counts) <- c("Country", "Missing_Count")

# Show the result sorted by count
country_missing_counts <- country_missing_counts %>%
  arrange(desc(Missing_Count))

#print(country_missing_counts)
v.unique_missing_countries162 <- unique(all_missing)
print(v.unique_missing_countries162)
```

```{r, include = F}
v.imputable_c <- setdiff(v.Chainalysis_country, v.unique_missing_countries162)

d.Inflation_s_128  <- d.Inflation_s_162  %>% filter(Country %in% v.imputable_c)
d.GDS_s_128        <- d.GDS_s_162        %>% filter(Country %in% v.imputable_c)
d.GDP_s_128        <- d.GDP_s_162        %>% filter(Country %in% v.imputable_c)
d.Corruption_s_128 <- d.Corruption_s_162 %>% filter(Country %in% v.imputable_c)
d.RR_s_128         <- d.RR_s_162         %>% filter(Country %in% v.imputable_c)
d.CC_s_128         <- d.CC_s_162         %>% filter(Country %in% v.imputable_c)
d.ED_s_128         <- d.ED_s_162         %>% filter(Country %in% v.imputable_c)
d.Chainalysis      <- d.Chainalysis       %>% filter(Country %in% v.imputable_c)

```

```{r, include = F}
#change all NA coltype
d.CC_s_128$"2023" <- d.CC_s_128$`2022Â `

print("Inflation")
d.Inflation_s_128  <- impute_row_mean(d.Inflation_s_128)
print("GDS")
d.GDS_s_128        <- impute_row_mean(d.GDS_s_128)
print("GDP")
d.GDP_s_128        <- impute_row_mean(d.GDP_s_128)
print("Corrupption")
d.Corruption_s_128 <- impute_row_mean(d.Corruption_s_128)
print("RR")
d.RR_s_128         <- impute_row_mean(d.RR_s_128)
print("CC")
d.CC_s_128         <- impute_row_mean(d.CC_s_128)
print("ED")
d.ED_s_128         <- impute_row_mean(d.ED_s_128)
```

```{r, include = F}
# List your datasets (adjust names if needed)
datasets <- list(
  d.Inflation_s_128,
  d.GDS_s_128,
  d.GDP_s_128,
  d.Corruption_s_128,
  d.RR_s_128,
  d.CC_s_128,
  d.ED_s_128
)

names(datasets) <- c("Inflation", "GDS", "GDP", "Corruption", "RR", "CC", "ED")

# 1. Check for NAs in each dataset
na_check <- sapply(datasets, function(df) any(is.na(df)))
print("Datasets containing NAs:")
print(na_check)

# 2. Check that Country columns are identical across all datasets
# Use the first dataset as the reference
ref_countries <- d.Chainalysis$Country

country_check <- sapply(datasets, function(df) identical(df$Country, ref_countries))
print("Country columns identical to reference:")
print(country_check)

```

```{r, include = F}


colnames(d.Chainalysis) <- c("Country","2020","2021","2022","2023","2024")
colnames(d.CC_s_128) <- c("Country","2019","2020","2021","2022","2023")

#as.numeric(d.CC$'2023')

# List of indicator datasets (excluding Chainalysis)
datasets <- list(
  Chainalysis = d.Chainalysis,
  Inflation  = d.Inflation_s_128,
  GDS        = d.GDS_s_128,
  GDP        = d.GDP_s_128,
  Corruption = d.Corruption_s_128,
  RR         = d.RR_s_128,
  CC         = d.CC_s_128,
  ED         = d.ED_s_128
)

# Pivot each dataset to long format: Country, Year, Indicator_Value
long_indicators <- lapply(names(datasets), function(name) {
  datasets[[name]] %>%
    pivot_longer(-Country, names_to = "Year", values_to = name)
})

# Join them all together on Country and Year
df_long <- reduce(long_indicators, full_join, by = c("Country", "Year"))

# Make sure Year is numeric
d.panel_sanity <- df_long %>% mutate(Year = as.numeric(Year))


#Removing Year 2024, no Data for any DV, and 2019, no Data for IV

d.panel_sanity <- d.panel_sanity %>% 
  filter(Year != 2024) %>% 
  filter(Year != 2019)

# View result
head(d.panel_sanity)

```

```{r sanitycheck-flip-scale, echo = F}
# here could flip the scale if so inclined
```

```{r, include=F}
#m.4<- lm(Chainalysis ~as.factor(Year)+Inflation+GDS+Corruption+RR+CC+ED, data = d.panel_sanity)

m.4 <- plm(
  Chainalysis ~ Inflation + GDS + Corruption + RR + CC + ED,
  data = d.panel_sanity,
  index = c("Country", "Year"),
  model = "within"
)
# deliberatley take out GDP as this is already controlled for in the adoption data
```

```{r model4-presentation-coefficients, echo=F, warning = F}
# Format the model summary

s.4 <- tidy(m.4) %>%
  mutate(
    term = gsub("_", "\\\\_", term),  # Escape underscores for LaTeX
    estimate = sprintf("%.4f", estimate),  # 2 decimal places
    std.error = sprintf("%.4f", std.error),  # 2 decimal places
    statistic = sprintf("%.4f", statistic),  # 2 decimal places
    p.value = sprintf("%.4f", p.value),  # 4 decimal places
    signif = case_when(  # Significance stars
      as.numeric(p.value) < 0.001 ~ "***",
      as.numeric(p.value) < 0.01 ~ "**",
      as.numeric(p.value) < 0.05 ~ "*",
      as.numeric(p.value) < 0.1 ~ ".",
      TRUE ~ ""
    )
  ) %>%
  rename(coefficient = term) %>%
  rename(t.statistic = statistic)


#Clean Factor Term
s.4 <- clean_factor_terms_in_table(s.4)

colnames(s.4) <- c("Term","Coefficient Estimate","Standard-Error","T-Statistic","P-Value","Significance")

# Create LaTeX table
kable(s.4, 
      caption = "Model 4 (Robustness Check) Coefficients", 
      format = "latex", 
      booktabs = TRUE, 
      escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs")) %>%
  column_spec(2, width = "3cm")  # Adjust column width if needed

```

```{r model4-presentation-summary, echo = F}
summary_stats <- summary(m.4)
#helloback
# Extract residuals
residuals_summary <- summary(m.4$residuals)

# Create a dataframe for model fit statistics

model_summary <- data.frame(
  Metric = c(#"Residual Standard Error", 
             "Multiple R-squared", 
             "Adjusted R-squared", 
             "F-statistic", 
             "Degrees of Freedom (Model)", 
             "Degrees of Freedom (Residuals)",
             "P-Value",
             "Residual Sum of Squares",
             "Between Entities",
             "Between Time"),

  Value = c(#sprintf("%.2f", summary_stats$sigma), #1
            sprintf("%.4f", summary_stats$r.squared[1]), #2
            sprintf("%.4f", summary_stats$r.squared[2]), #3
            sprintf("%.2f", summary_stats$fstatistic$statistic), #4
            summary_stats$df[1], #5
            summary_stats$df[2], #6
            sprintf("%.4f", summary_stats$fstatistic$p.value), #7
            sprintf("%.2f", residuals_summary[1]),  # Sum of Sq #8
            sprintf("%.2f", residuals_summary[2]),  # In between id #9
            sprintf("%.2f", residuals_summary[3]))) 

# Create a formatted LaTeX table using kable
kable(model_summary, caption = "Model 4 (Robustness Check) Fit Summary", format = "latex", booktabs = TRUE, escape = FALSE) %>%
  kable_styling(latex_options = c("hold_position", "booktabs"))
```

Table \@ref(tab:model4-presentation-summary) shows the model's summary statistics. The model has an adjusted $R^2$ of -0.26. This indicates that the [[**what does it indicate!!**]{.underline}].

Figure \@ref(fig:model4predres) shows the predicted versus residual plot of the robustness check model. The increase in spread of the residuals in the middle of the range of predicted values indicate heteroscedasticity. The size of the residuals is larger than in Model 1, 2 and 3. This alone does not indicate a worse model quality due to the different measurement in of cryptocurrency adoption in Model 4. Figure \@ref(fig:model4residualhistograms) shows the histogram of the residuals for the robustness check model. It indicates an acceptable distribution; with the exceptions of outliers at the positive and negative end of the residual range, the distribution is quasi-normal.

```{r model4predres, echo = F, fig.cap="Model 4 (Robustness Check): Scatterplot Showing Predicted vs. Residuals", results = "asis", fig.width=5, fig.height=4}

# Create a data frame with predictions and residuals
df <- data.frame(
  Predicted = predict(m.4),
  Residuals = residuals(m.4)
)

# Generate the ggplot
ggplot(df, aes(x = Predicted, y = Residuals)) +
  geom_point() +  # Scatter plot
  geom_hline(yintercept = 0, linetype = "dashed", color = "#4A9FD8", size = 0.5) +  # Horizontal line at 0
  ylim(-95,95)+
  labs(x = "Predicted Values", y = "Residuals")# +
  #theme_minimal()
```

```{r model4residualhistograms, fig.cap= "Model 4 (Robustness Check): Histogram of Residuals", fig.width=5, fig.height=4, echo =F, fig.pos="H"}
m.4_residuals <- data.frame(residuals = m.4$residuals)

ggplot(m.4_residuals, aes(x = residuals)) +
  geom_histogram(bins = 50, fill = "#4A9FD8", alpha = 0.6) +
  labs(x = "Residuals", y = "Count") +
  #theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )

```

\FloatBarrier

### Interpretation Guide Tables and Figures for Results Section

The subsection \@ref(results) presented 2 types of tables (coefficient table, fit summary table) and 2 types of figures (predicted vs. residual plot, histogram of residual). Here, a guide to their interpretation will be given.

#### Coefficient Table {.unnumbered .unnumbered .unlisted}

Tables \@ref(tab:model1-presentation-coefficients), \@ref(tab:model2-presentation-coefficients), \@ref(tab:model3-presentation-coefficients) and \@ref(tab:model4-presentation-coefficients) present model results in terms of the coefficients of independent variables. The coefficient estimates of the categorical year values (only in Model 1 and Model 2) represent linear offsets in the predicted value for the dependent variable for the different years, relative to the reference year, holding other predictors constant. For Model 1 and 2, the coefficient estimates for continuous values represent the expected change in the dependent variable as a result of a one unit change in the respective variable, while holding other variables constant. Note that in the case of Model 2, this refers to a one unit change in the transformed scale, not the original. For Model 3 and 4, the coefficient estimates for continuous variables (all input variables, since there are no categorical inputs), represent the change in response variable as a result of a one unit change in the independent variable while controlling for unobserved, time invariant characteristics of the country and holding independent variables constant, this is also known as a *within-country* effect[@torres-reyna2007; @utts; @vandervaart2019]. The meanings of the column Significance can be seen in Table \@ref(tab:sig-tbl). It is worth noting that at the selected significance level of 10%, even a p-value below 0.1 is sufficient to reject the null hypothesis for a particular variable. In this paper, when interpreting results no difference is made between different levels of statistical significance as long as the p-value is below 0.1. The coefficient tables present results to 4 decimal places.

```{r sig-tbl,echo =F}
significance_legend <- data.frame(
  Symbol = c("***", "**", "*", ".", " "),
`P-value Threshold` = c(
  "$\\mathrm{p} < 0.001$",
  "$0.001 \\leq \\mathrm{p} < 0.01$",
  "$0.01 \\leq \\mathrm{p} < 0.05$",
  "$0.05 \\leq \\mathrm{p} < 0.1$",
  "$\\mathrm{p} \\geq 0.1$"
)
,
  Interpretation = c(
    "Very strong evidence against $H_0$",
    "Strong evidence against $H_0$",
    "Moderate evidence against $H_0$",
    "Weak evidence against $H_0$",
    "Not statistically significant"
  )
)

# Generate table for PDF output
kable(significance_legend, booktabs = TRUE, escape = FALSE, align = "l", format = "latex",
      col.names = c("Symbol", "P-value Threshold", "Interpretation"),
      caption = "Significance Legend for Model Coefficients Tables") %>%
  kable_styling(latex_options = c( "hold_position", "scale_down"))

```

It is important to interpret the coefficient estimates while considering the scale of the predictor variable both within a single model's different independent variables but also between models when looking at the same variable, if the scale is different. In the first case, a different coefficient estimate for one independent variable over another does not mean that proxy has a stronger effect. This is because, for example, it is "easier" for a country to have a one unit (single USD) change in the GDP per capita than a one unit change in the capital controls' proxy (this would imply moving between the maximum and minimum value for the index). In the second case, comparing the same proxy's estimates across models with a different scale, gives no indication of relative strength of the proxy in the model due to the different scales of the proxies resulting from different transformations being applied. This second point is also true when a different response variable is used between models rather than a transformation [@barbanti2024].

The standard error is an approximation of the deviation of the coefficient from its estimate. Combined with the estimate, it can be useful to get confidence intervals for coefficients, and more importantly check that the direction of effect does not make the estimate change direction within a certain confidence interval. For example if the 95% confidence interval for an estimate is $2\pm (1.96*3)$ then it cannot even be said which direction the adoption of cryptocurrencies moves in response to a one unit change in (transformed) independent variable, as this estimate includes a zero and both positive and negative numbers. The t-statistic quantifies this idea by dividing the coefficient estimate by the standard error ($\frac{Coefficient\ Estimate}{Standard\ Error}$ ) giving a value where a higher number represents greater confidence in the estimate and vice-versa. The p-value is the result of a hypothesis test and represents the probability of obtaining a results at least as extreme as the one observed, assuming the null hypothesis is true. It is used to accept or reject the null hypothesis relating to the coefficient of the predictor variables. At the 10% level chosen for this paper, any p-value below 0.1 indicates the rejection of the null hypothesis that the coefficient of a given variable is different from 0[@barbanti2024; @thieme2021; @w3schools].

#### Fit Summary Table {.unnumbered .unnumbered .unlisted}

Tables \@ref(tab:model1-presentation-summary), \@ref(tab:model2-presentation-summary), \@ref(tab:model3-presentation-summary) and \@ref(tab:model4-presentation-summary) show the model's summary statistics. Residuals are the difference between the actual values and the values predicted by the model. Residual standard error represents the standard deviation of all the residuals. The value for multiple R-squared represents the proportion of variation in the dependent variable explained by the model's independent values.

Adjusted R-squared is similar, but it adjusts the proportion explained for the amount of independent variables used, penalizing models with a larger number of predictors. Please note that in the case of the fixed effect models (3,4), the variation refers only to the within country variation explained by the model [@torres-reyna2007]. As such, the (adjusted) R-Squared cannot be used to compare model quality meaningfully between linear regressions and fixed effect models

The f-statistic and p-value do not provide an informative additional output in the context of a multiple regression, when anyway looking at the coefficients of the independent variables, as it is used to determine whether any of the predictors have an impact on the dependent variables. The P-values from coefficient estimates are far more valuable to do this [@greenwood2022; @thieme2021].

The degrees of freedom (model) represent the number of $\beta$ coefficients, excluding the global intercept $\beta_0$ (Models 1,2) or country specific offsets $\alpha_i$ (Model 3,4). The degrees of freedom represent the number of observations minus all $\beta$ coefficients and $\alpha_i$ in the case of of Models 3 and 4. The summary statistics residual minimm, residual quartile 1, residual median, residual quartile 3 and residual maximum describe the associated summary statistics of all the residuals for individual observations across years [@thieme2021].

#### Predicted versus Residuals Plot {.unnumbered .unnumbered .unlisted}

Figures \@ref(fig:model1predres), \@ref(fig:model2predres), \@ref(fig:model3predres) and \@ref(fig:model4predres) show a scatterplot demonstrating the value of the response variable that the model predicts a certain country in a certain time would have based on the data (x-axis) and the residual associated with that prediction (y-axis). Recall that the residual is the difference between a prediction and the true value. This means a large residual implies the model did not predict well for this observation. Such a plotis often used to understand the presence of heteroscedasticity. This is a situation where the model is not equally good at predicting the true value across the range of the independent variables. Ideally, the model is equally good across all ranges. This is indicated by the absence of a discernible pattern in the predicted vs. residual plot [@utts; @vandervaart2019].

#### Histogram of Residuals {.unnumbered .unnumbered .unlisted}

Figures \@ref(fig:model1residualhistograms), \@ref(fig:model2residualhistograms), \@ref(fig:model3residualhistograms) and \@ref(fig:model4residualhistograms) show histograms of the residuals. Histograms visually show the frequency at which values appear in certain ranges. One of the assumptions of the types of models used in this paper is the normal distribution of error terms around 0. This means ideally most residuals are close to 0 with less residuals in frequency brackets further away from 0 in both positive and negative directions [@utts; @vandervaart2019; @zicha2020].

\newpage

# Discussion

The results of the statistical models are largely inconsistent between each other. Table \@ref(tab:all-model-coeff) shows an overview of the statistically significant coefficients in the four models. Model coefficients are shown with their associated statistical significance using the symbols presented in Table \@ref(tab:sig-tbl). A dash ("-") for a coefficient means it was not statistically significant. It is important to note that a higher number in the robustness check means that the adoption is lower. For a variable to have the same direction of effect, the robustness check model's estimate must have the opposite sign (+/-).

The results for the coefficients can be divided into four groups:

1.  Statistically significant effects consistent across two different measures of cryptocurrency adoption (ED).
2.  Totally statistically insignificant (CC).
3.  Inconsistent direction of statistically significant effects (GDP, inflation).
4.  Statistically significant effects consistent across one measure of cryptocurrency adoption only (Corruption, GDS, RR).

```{r all-model-coeff, echo = F}
library(broom)
library(dplyr)
library(tidyr)
library(purrr)
# List of models
models <- list(LinReg = m.1, LinRegYJ = m.2, FixedEffect = m3.fixed, SanityCheck = m.4)

# Tidy and tag model summaries
model_summaries <- imap_dfr(models, ~ tidy(.x) %>%
                              mutate(model = .y), .id = "id")

# Create summary: coefficient (3 sig digits) + significance stars
model_summaries <- model_summaries %>%
  mutate(
    significance = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01  ~ "**",
      p.value < 0.05  ~ "*",
      p.value < 0.1   ~ ".",
      TRUE            ~ ""
    ),
    summary = case_when(
      p.value < 0.1 ~ paste0(signif(estimate, 3), significance),
      TRUE          ~ ""
    )
  ) %>%
  select(term, model, summary)

# Get full set of all terms and all models
all_terms <- unique(model_summaries$term)
all_models <- names(models)
full_grid <- expand.grid(term = all_terms, model = all_models, stringsAsFactors = FALSE)

# Merge and fill missing/empty values with "NA"
summary_table <- full_grid %>%
  left_join(model_summaries, by = c("term", "model")) %>%
  mutate(summary = ifelse(summary == "" | is.na(summary), "-", summary)) %>%
  pivot_wider(names_from = model, values_from = summary) %>%
  arrange(term)

# Clean column names for LaTeX (escape underscores)
colnames(summary_table) <- gsub("_", "\\\\_", colnames(summary_table))

summary_table[5,5]<-"variable not included" # GDP was not included as a predictor variable in the Robustness Check

summary_table[1,4] <- "intercept dropped" # no intercept in FE model
summary_table[1,5] <- "intercept dropped"

summary_table[9,4] <- "not in data"
summary_table[10,4] <- "not estimated"
summary_table[11,4] <- "not estimated"
summary_table[12,4] <- "not estimated"

summary_table[9,5] <- "not in data"
summary_table[10,5] <- "not estimated"
summary_table[11,5] <- "not estimated"
summary_table[12,5] <- "not estimated"


colnames(summary_table) <- c(
  "Term", 
  "\\makecell{Model 1:\\\\Linear Regression}", 
  "\\makecell{Model 2:\\\\Linear Regression\\\\Yeo-Johnson}",
  "\\makecell{Model 3:\\\\Fixed Effect}",
  "\\makecell{Model 4:\\\\Robustness Check\\\\(Fixed\\\\Effects)}"
)

#Clean Factor Term
summary_table <- clean_factor_terms_in_table(summary_table,"Term")

# LaTeX table with styling
kable(summary_table, 
      caption = "Model Comparison: Significant Coefficients", 
      format = "latex", 
      booktabs = TRUE, 
      escape = FALSE, 
      align = "lllll") %>%
  kable_styling(latex_options = c("hold_position", "booktabs")) %>%
  column_spec(1, bold = FALSE, width = "2cm")# %>%

  
  
  #row_spec(0, bold = TRUE)

```

The first group are predictor variables which had a consistent direction of effect across two measures of cryptocurrency adoption, containing only ED. The proxy for sovereign default risk, ED, shows up as statistically significant in two of the four models: Model 2 and 4. The direction of effect is positive in both - the same as originally theorized. Nevertheless, this finding should be taken with caution as the other two models (Model 1,3) do not find a statistically significant correlation and the strength of the effect in Model 4 is low. An increase of 1 percentage point in the ED is associated only with a country moving up (decreasing the rank) in the Chainalysis ranking by around 0.2 ranks. Evidence for a true underlying relationship here is stronger than for the variables in group 4, as is it consistent across two measures of cryptocurrency adoption.

The second group is those predictor variables that were not statistically significant at the 10% level for any model. This includes only the variable for CC. This means that at the chosen significance level, the hypothesis that the coefficient is different from zero is not rejected for all models - the models do not indicate a relationship.

The third group includes predictor variables that did not exhibit a consistent direction of effect across the models. This includes the variables for GDP and inflation. For GDP, this result is contrary to the literature, which confidently identifies wealth as a reason for adoption of cryptocurrency. When comparing the results of this paper to previous studies on GDP as a predictor of cryptocurrency usage, it could be that in this paper no consistent direction of effect was found due to using a global dataset. Previous studies usually focus on subsets of the global population. @lammer2019 focus on German bank account data. @ricci2020 studies only the 70 most developed economies. @gemini2021 focus on wealthy Americans. For currency stability, this paper adds to the mixed literature relating to cryptocurrency adoption where papers like @choi2022, @conlon2021 and @gaies2024 find a positive correlation and others such as @parino and @ricci2020 find a negative correlation. At the data level this means this paper falls into the same category as @phochanachan2022 which find correlations with inflation under certain conditions only, the conditions in the case of this paper being the different dependent variable used.

The fourth group is those predictors that had a consistent direction of effect but only across one dependent variable. This means evidence for a true relationship is weaker compared to those predictors in group one. These predictors are GDS, corruption and RR. For GDS, the proxy for using cryptocurrency as an investment vehicle, these results are unexpected due to not only cryptocurrency's popularity as an investment vehicle but also because the available literature does confidently identify investment as a use case. The dataset by @glaser2014 covers a large amount of early global Bitcoin trades, as they evaluated the Mt. Gox exchange, which facilitated over 60% of trades taking place during the time period studied by [@glaser2014; @feder2017]. Nevertheless, other studies such as @voskobojnikov2020 have the same narrow focus as papers discussed in the section on GDP, as they focus only on North American respondents and their use for cryptocurrency. In terms of corruption, the results are also weaker than would be expected given the literature. Previous quantitative studies have identified sinful uses as related to cryptocurrency usage and the anecdotal evidence supports the conclusion [@alnasaa2022; @macfarlane2021; @marmora2021]. For both GDS and corruption, while the paper does support previous studies showing a relationship to the adoption of cryptocurrencies, the fact that they were only found statistically significant against one dependent variable is contrary to expectations given the strength with which these underlying factors appear in the literature.

The final coefficient in the fourth group is RR. Here, the findings in this paper provide limited quantitative evidence against the idea that remittances are a major driver of cryptocurrency adoption. The variable RR is statistically significant and negatively correlated in two out of four models tested, both using the same dependent variable. The negative correlation is unexpected considering the findings in the literature review showing the potential of cryptocurrency based remittances. However, this finding should be interpreted cautiously. It could reflect a genuine lack of widespread use of cryptocurrencies for receiving remittances, or it could stem from limitations in how adoption is measured, with current data sources potentially missing key forms of usage. This distinction is important because most existing studies focus on the potential for cryptocurrencies to facilitate remittance flows, rather than providing empirical evidence that they are actually used in practice. As discussed in the literature review section \@ref(remittances), much of the evidence remains anecdotal or theoretical. A few exceptions, such as @rodima-taylor2019, @metzger2019 and @robins2024 provide more grounded insights into current practices. These studies find that while cryptocurrencies (including stablecoins) do play a limited role in remittance ecosystems, the notion of pure crypto-based transactions - where both the sender and receiver use non-custodial wallets - is exceedingly rare. Instead, cryptocurrencies often function as one link in a broader chain involving multiple intermediaries and traditional financial actors on both ends of the remittance transfer.

Further complicating the measurement of cryptocurrency use in remittances is the issue of user awareness and transaction visibility. As highlighted by @robins2024, many individuals engaged in cross-border transfers may not even realize that cryptocurrency is involved. This is especially true when funds are sent entirely within centralized exchanges. These transactions are recorded internally and do not necessarily appear on a public blockchain. As a result, they are effectively invisible to blockchain analysis tools like those used by Chainalysis. Similarly, the lack of user understanding of the fact cryptocurrencies may be involved in a step of the transaction, hinders any survey's ability to capture the adoption. If users do not associate their activity with cryptocurrency use, or are unaware that crypto is involved, they will not report it - leading to systematic underestimation of adoption in remittance-receiving populations. In the case of Chainalysis specifically another issue in the measurement of remittances comes into play. Their adoption metrics is based on blockchain value **received** by centralized services in each country [@chainalysis2024]. In the situation where an individual gets a remittance transfer paid out to them, the centralized cryptocurrency service provider would not receive any value and therefore this would not show up in the adoption metric of Chainalysis. Due to the non-inclusion of remittances as predictor variables in quantitative analysis of the topic, such as by @parino, @ricci2020 and @viglione2015, this paper has still provided a contribution by formally testing the relationship. The only known paper including remittances as a predicting variable is @alnasaa2022 in a cross-country regression. However, they did not find it to be statistically significant at the 10% level.

This paper will now evaluate strengths and weaknesses of the paper before suggesting future research and making recommendations to policymakers based on the findings.

## Strengths

Two key strengths of this study were the use of panel data and the wide range of countries included in the dataset. Firstly, the panel data setup allows for a more in-depth analysis across both time and geography. By including multiple years for each country, the study can capture how changes within a country relate to changes in cryptocurrency adoption. It also helps control for country-specific factors that don't vary over time but could still influence outcomes - such as legal systems or cultural attitudes toward financial innovation. This improves the reliability of the results and gives the model more explanatory power than a cross-sectional analysis would have.

The second strength is the inclusion of a wide range of countries in the study. Rather than focusing only on high-income economies or one region, this study looks at adoption patterns across many different types of countries - from emerging markets with unstable currencies to more developed economies with established financial systems. This diversity improves the generalizability of the results and makes the findings more relevant for a variety of settings, especially as crypto adoption continues to grow in places that have not traditionally been the focus of this kind of research. While this is a choice made possible by data availability, this sets the study apart from previous ones such @ricci2020 focusing only on developed countries.

## Limitations

This paper had several weaknesses. Firstly, as often mentioned already the small data size in the main models using the Statista data as a dependent variable limited not only statistical power, but also the amount of predictor variables that could be included before statistical power would become too low. Additional predictors (such as a marker for technology), or more granular predictions of the existing proxies (such as splitting crime and corruption) could have been useful, but not included due to the adverse effect this would have had on statistical power. The data size was improved in the model using the Chainalysis data as a dependent variable. However, as discussed previously, the Chainalysis data brought with it its own challenges as it is a ranking and says nothing about the size of the differences between countries. Furthermore the technical challenges of obtaining this data and resulting skepticism around the accuracy of the manual translation means using this as a main dependent variable is unlikely to become a standard in research in its current form. Another weakness was related to the variable for capital controls. These were sourced from @imf2024 and turned into an index, bringing challenges. Since only 5 binary components made up the data that would become the index (described in section \@ref(predictors-independent-variables), the index did not have a normal distribution. The gravity of this issue was attempted to be alleviated using the Yeo-Johnson transformation (see Figure \@ref(fig:hist-CC)). However, random perturbations had to be added to the data to increase variability and use the Yeo-Johnson tranformationo, limiting the accuracy of the underlying data entering the models. On the Yeo-Johnson transformation, despite this being applied, normality of the data was not achieved and the adjusted $R^2$ was not improved in Model 2 relative to Model 1. Nevertheless, the distribution was improved as can be seen by the visual changes in section \@ref(distribution-histograms).

Another limitation is that while multiple modeling strategies were employed to identify the drivers of cryptocurrency adoption, none of them demonstrated particularly strong explanatory power. The linear regressions demonstrated a maximum adjusted $R^2$ value of 48%. This is acceptable given that this paper falls within social science research which oftentimes has lower values of this metric compared to papers modelling other processes and there were statistically significant independent variables [@ozili2023]. Despite an acceptable adjusted $R^2$ for the linear regressions, the F test for individual and / or time effects did show the fixed effects model superior to the linear regressions. The fixed effects model showed small effect sizes of the coefficient estimates relating to the predictors and less statistically significant predictors than the linear regressions indicating most of the power was carried by the country fixed effects and not the independent variables. This indicates that factors specific to countries not captured in the data used for this paper play an important role - a clear limitation when attempting to explain the adoption of cryptocurrencies.

The final weakness, as with all studies evaluating correlations between variables, the existence of a correlation does not imply one variable causes the other and it should not be interpreted as such.

## Future Research

The production of high quality and ideally open data around the adoption of cryptocurrency is an area where this research field is improving. Previous studies had to use either cross sectional data in a single year as was done by @alnasaa2022 or use technically challenging indicators such as those used by @ricci2020 and @parino. The regular production of data by both Chainalysis and Statista Global Consumer Survey (through including questions around cryptocurrency use) is a step in the right direction. However Chainalysis is limited by it's discontinuation of publishing the index (at least in the open source versions, it is unclear whether the paid service includes the index rather than just the ranking) and Statista is limited by the limited number of countries (56) included in its survey. When looking at underlying economic factors influencing the use of cryptocurrency, the production of data on the independent variable's side is satisfactory. With the exception of capital controls, crime and regulations around cryptocurrency most factors which appear as relevant in the literature have a reliable proxy variable available from either the World Bank or the IMF, even if these are not available for all countries at all points in time and oftentimes it is the countries most interesting for the field of Dollarization 2.0 which do not not have reliable data produced. The same instability which encourages currency substitution or Dollarization 2.0 hinders the production of reliable data.

The findings in relation to remittances encourage further research in the area of cryptocurrency's use in remittances. The existing research clearly argues the potential for remittances and a limited number of studies have looked at the actual use of remittances. However, the results presented here indicate that being a country which receives remittances may dampen adoption of cryptocurrencies. Is this a result of genuine lack of usage or measurement issues? Future research could attempt to answer this questions by including more granular predictors for country's remittance markets and financial inclusion such as: number of bank accounts, internet access or regulation around remittances. This would open the door for effective regulation from policymakers and potentially entrance into the market by new players looking to provide remittances services with the supposed benefits of cryptocurrency.

As discussed in the limitations section, the small number of statistically significant independent variables in the fixed effects mean that there are likely unaccounted factors that this paper, and the broader literature has missed. Future research, particularily qualitative could attempt to identify additional factors that may be relevant to the adoption of cryptocurrencies. Quantitative models could then test these factors.

Research around cryptocurrency being used for currency substitution should be cautiously encouraged by the results of this paper, suggesting that there might be a link.

## Dollarization 2.0 and Recommendations for Policymakers

A central theme in relation to this paper findings for policymakers is that macroeconomic factors should not be viewed as a policy lever to stimulated cryptocurrency adoption. Rather, changes in cryptocurrency adoption can be the result of underlying changes and policymakers should be aware that this potential is there.

For countries that are opposed to the spread of cryptocurrency, the results suggest that maintaining a low risk of sovereign default through fiscal discipline and preserving credibility with foreign creditors can help limit adoption. These are not new goals; fiscal discipline has been a core objective in many countries, despite recent challenges from economists like @kelton2020, promoting an agnostic view on the size of domestic currency denominated debts [@kumar2007; @rodrik2006]. In this context, the findings highlight an additional reason to maintain prudent fiscal policy - reducing conditions that are associated with increased cryptocurrency use. In contrast, countries that support cryptocurrency adoption should focus on building strong regulatory frameworks and supportive infrastructure. Attempting to drive adoption by increasing sovereign risk is unlikely to yield positive results and comes with significant dangers. Even economists who question conventional views on public debt do not argue that a sovereign default is a desirable. Rather they argue that domestic currency denominated debts do not increase the risk of a sovereign default in the first place [@kelton2020; @mitchell2019]. The findings related to sins follow a similar logic. Although the data show a positive relationship between sins and cryptocurrency adoption, this should not be interpreted as an endorsement of using sins like corruption and criminality as a means to drive cryptocurrency adoption in a country. Instead, countries facing rising sins should recognize that such conditions may lead to greater cryptocurrency use.

On the other hand, countries with increasing levels of GDS as a share of GDP may experience greater adoption, but the trends in the adoption of cryptocurrencies are unlikely to take precedence over the broader macroeconomic goal of increasing funds available for investment. Policymakers should be aware of the potential that cryptocurrencies may be used more extensively as GDS increases, but should view changes in GDS as a goal in itself not as a means to promote cryptocurrency.

\newpage

# Conclusion

This study has conducted an econometric analysis of underlying factors predicting the adoption of cryptocurrency at the country level. Underlying factors found as relevant in current research (currency stability, investment, wealth, sins, remittances and capital controls) were augmented with a proxy for the risk of sovereign default. The choice of this additional predictor was informed by the idea that the new technology of cryptocurrency could serve as currency substitution for two main reasons. Firstly due to the relative ease of transferring funds when compared to using traditional financial institutions or cash. Secondly due to the possibility of cryptocurrencies being more stable than fiat currencies depending on the inflationary context. Currency substitution's only predictor not already considered by the cryptocurrency adoption research is the sovereign default risk - which is why this was included in this paper.

The statistical analysis covered four models with two different measures of cryptocurrency adoption. Model 1,2 and 3 used data by @statista_adoption while Model 4, used as a robustness of check of the results used data by Chainalysis [@chainalysis2020; @chainalysis2021; @chainalysis2022; @chainalysis2023]. The results uncovered a relationship in two (Model 2 and 4) out of four models between the proxy for sovereign default risk and cryptocurrency adoption. The idea that there may be a true underlying relationship is supported by the fact that the ED predictor was the only one with a statistically significant effect in the same direction in two models using a different proxy of cryptocurrency adoption. However, two other models (Model 1 and 3) did not find a statistically significant relationship, which requires these results to be taken with caution. Proxies for sins, investment and remittances were also found to be statistically significant in two models, however these were only consistent across one measure of cryptocurrency adoption, weakening the evidence for a true underlying relationship. The proxy for remittances was negatively correlated to measures of adoption in two models with no relationship uncovered in the other models. This contradicts much of the available research into remittances as a driver of adoption. It is possible this was due to measurement issues or a genuine lack of application for cryptocurrencies in the remittance industry.

This paper has attempted to contribute to the literature on cryptocurrency adoption and currency substitution. The former field through expanding underlying predictors via the risk of sovereign default in an attempt to explain more of the global variation seen in the adoption of cryptocurrencies. The latter by expanding the currency substitution literature by providing a corresponding analysis of cryptocurrencies. Both of these approaches were novel, although the inclusion of a predictor for sovereign default risk did not yield conclusive results.

\newpage

# Bibliography (APA 7\textsuperscript{th}) {.unnumbered}

::: {#refs}
:::

\newpage

# Appendix 1: Structured List of Literature {.unnumbered}

This Appendix gives a visual overview of the two main important fields of academic literature for this paper.

## Literature Area 1: Drivers of Currency Substitution {.unnumbered}

Table \@ref(tab:litreviewCS) below shows the overview of the key literature on currency substitution and in relation to this research. It is a visual representation of the text in section \@ref(currency-substitution-1). Please note while not explicitly included in the literature review, the adoption of new technology as a driver of currency substitution is discussed in section \@ref(decentralized-alternatives).

\FloatBarrier

```{r tab:litreviewCS, echo=FALSE, results='asis', fig.pos="H"}
cat("
\\begin{table}[ht]
\\centering
\\caption{Visual Summary Currency Substitution Literature}
\\includegraphics[width=0.9\\linewidth]{Knit_Files/review_CS.png}
\\label{tab:litreviewCS}
\\end{table}
")
```

\FloatBarrier

\newpage

## Literature Area 2: Drivers of Cryptocurrency Adoption {.unnumbered}

Table \@ref(tab:litreviewCA) below shows the overview of the key literature on the adoption of cryptocurrencies in relation to this research. It is a graphical representation of the text in section \@ref(adoption-of-cryptocurrency).

\FloatBarrier

```{r tab:litreviewCA, echo=FALSE, results='asis', fig.pos="H"}
cat("
\\begin{table}[ht]
\\centering
\\caption{Visual Summary Cryptocurrency Adoption Literature}
\\includegraphics[width=0.9\\linewidth]{Knit_Files/review_Adoption.png}
\\label{tab:litreviewCA}
\\end{table}
")
```

\FloatBarrier

\newpage

# Appendix 2: Missing Data Patterns {.unnumbered}

This section shows the missing patterns for the pre-imputation data of all variables with the exception of the capital controls index, as this was already presented in the section \@ref(missing-data-structure). Please see \@ref(interpretation-of-missing-data-pattern-figure) for a guide on how to interpret the figure.

\FloatBarrier

```{r md-Adoption, echo = F, fig.cap="Missing Pattern for Adoption of Cryptocurrencies Measured by Statista (2024b)", message= F,  results="hide", fig.width=5, fig.height=3}
md.pattern(d.Adoption_UNimp[,-1])
```

```{r md-GDS, echo = F, fig.cap="Missing Pattern for GDS (% of GDP)", fig.width=5, fig.height=3, message= F,  results="hide"}
md.pattern(d.GDS_UNimp[,-1])
```

```{r md-GDP, echo = F, fig.cap="Missing Pattern for GDP (Current USD, per Capita)", fig.width=5, fig.height=1.5, message= F,  results="hide"}
md.pattern(d.GDP_UNimp[,-1])
```

```{r md-Corruption, echo = F, fig.width=5, fig.height=1.5, fig.cap="Missing Pattern for Political Corruption Index", message= F,  results="hide"}
md.pattern(d.Corruption_UNimp[,-1])
```

```{r md-RR, echo = F, fig.cap="Missing Pattern for RR (Personal, % of GDP)", fig.width=5, fig.height=1.8, message= F,  results="hide"}
md.pattern(d.RR_UNimp[,-1])
```

```{r md-ED-GDP, echo=F, fig.cap="Missing Pattern for ED (% of GDP)", fig.width=5, fig.height=2, message = F, results = "hide"}
md.pattern(d.ED_imp[,-1])
```

\FloatBarrier

\clearpage

\newpage

# Appendix 3: Summary Statistics {.unnumbered}

\FloatBarrier

Table \@ref(tab:summary-stats-m123) shows the summary statistics for the data of the 55 countries used in the model considering the Statista data as the dependent variable.

```{r summary-stats-m123, echo = F, warning=F }
# Summary statistics excluding 'Year' and 'Country'
summary_stats <- d.panel %>%
  select(-Year, -Country) %>%
  summarise(across(where(is.numeric), list(
    Mean = mean,
    Median = median,
    SD = sd,
    Min = min,
    Max = max
  ), na.rm = TRUE)) %>%
  pivot_longer(cols = everything(),
               names_to = c("Variable", "Statistic"),
               names_sep = "_") %>%
  pivot_wider(names_from = Statistic, values_from = value)

# Display summary in a nice table
kable(summary_stats, caption = "Summary Statistics for Data Used With Statista Set", booktabs = TRUE)%>%
  kable_styling(latex_options = "HOLD_position")

```

Table \@ref(tab:summary-stats-4) shows the summary statistics for the data of the 128 countries used in the model considering the Statista data as the dependent variable. The reason that the maximum value, 152, for the Chainalysis value (the ranking of the country in terms of adoption of cryptocurrencies) is higher than the number of countries is that some countries were removed due to insufficient data.

```{r summary-stats-4, echo = F, warning = F}
# Summary statistics excluding 'Year' and 'Country'
summary_stats <- d.panel_sanity %>%
  select(-Year, -Country) %>%
  summarise(across(where(is.numeric), list(
    Mean = mean,
    Median = median,
    SD = sd,
    Min = min,
    Max = max
  ), na.rm = TRUE)) %>%
  pivot_longer(cols = everything(),
               names_to = c("Variable", "Statistic"),
               names_sep = "_") %>%
  pivot_wider(names_from = Statistic, values_from = value)

# Display summary in a nice table
kable(summary_stats, caption = "Summary Statistics for Data Used With Chainalysis Set", booktabs = TRUE)%>%
  kable_styling(latex_options = "HOLD_position")

```

\FloatBarrier

\newpage

# Appendix 4: GitHub Access {.unnumbered}

This project and associated data can be found on the following hyper-linked public [**GitHub Repository**](https://github.com/AAV77/Master-Thesis). If there are any issues with the access, please contact the author via the following e-mail: "vayloyanalec49\@gmail.com".

\newpage

# Appendix 5: Reflecting on the Use of Artificial Intelligence {.unnumbered}

This project heavily leveraged AI. The single largest and most suitable use case was for generating code and solving coding issues. Being able to generate a working solution from only the input structure and desired output saved considerable time and effort. Unlike previous projects, I did not attempt to write code from memory or use non-AI sources. Partly, this was due to time constraints, but also because I felt confident in my ability to verify that the code did what I intended by evaluating the output or performing smaller intermediate steps to (hopefully) ensure mistakes did not carry forward.

For the creation of the cover image, OpenAI's GPT-4o was used.

I also used AI to draft some sections or provide inspiration to get started. While the generated passages were not satisfactory on their own, I found it much easier to revise the provided sections into what I wanted, rather than starting from scratch. In that sense, the AI was successful. For certain sections I also wrote a section and then gave it to the AI to improve flow and clarity. In this use case an issue was that when pasting back into the markdown documents, dynamic objects like headings, references and formulas oftentimes were not recognized by the markdown as such. This limited the practical use of this approach.

I used various spellcheckers: the built-in ones in RStudio and MS Word (after converting the knitted .pdf to .doc). I did not find that pasting the PDF into an AI chatbot reliably caught spelling, let alone grammar, errors. Dedicated spell-checking software in writing tools definitely outperformed AI in this aspect. LanguageTool.org was used for smaller sections. What did work was for smaller sections not requiring formatting and latex / markdown references, to paste a whole section, and having a Generative AI (so not dedicated spelling software) correct the spelling - this was done since it is much faster than knitting and converting to a .doc.

I attempted to use AI for research as well; however, this did not work well. The models frequently invented studies that I was never able to verify on common research platforms. Blindly relying on such information would have been disastrous. Since academic work requires citations, such mistakes are unlikely to go unnoticed by the author.

In the preliminary study, when I was unsure of the data available for capital controls, I proposed another use case, which ultimately was not needed. It is still unlikely that it would have worked to a satisfactory degree. The idea was to fill out an empty table consisting of country rows and year columns with socioeconomic data. By running a loop over the rows and columns, the relevant country and year could be extracted and used in a web service call with a prompt to an AI model. The prompt would then look something like: "Give me an estimate of the severity of capital controls from 1 ( least severe) to 10 (most severe) in [Switzerland] in [2023], use a global comparison for the rating and return only the number, no comments." This worked from a technical standpoint during testing for the preliminary study. However, the results were inconsistent (when run multiple times) and often did not provide the most recent data. This made that data collection approach impractical, beyond the fact that Generative AI cannot be referenced or reproduced in the first place and is therefore incompatible with academic standards. At a larger scale, it would also have been costly. I made roughly 500 calls to the web service, which resulted in a cost of around CHF 5. For big data applications with millions of rows, costs would likely become prohibitive.

The generative models used were the most recent versions by OpenAI and less frequently, Gemini.
